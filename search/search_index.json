{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"A Pluggable Interoperability Toolkit for Blockchain and DLT Networks","text":"<p>Cacti is a multi-faceted pluggable interoperability framework to link networks built on heterogeneous distributed ledger and blockchain technologies and to run transactions spanning multiple networks. It offers a collection of vendor-neutral and DLT-specific modules, libraries, and SDKs for popular DLTs, and templates to help you configure your networks and adapt your DApps to interoperate with other networks and their DApps for the purposes of carrying out atomic asset swaps, asset transfers, sharing ledger state, and other use cases. Cacti does not require deployment of, or dependence on, separate chains, and therefore is uniquely suited to help private (or permissioned) DLT networks be interoperable while keeping control of their governance and maintaining security and privacy.</p> <p>Cacti is the product of a merger between the pre-existing Cactus and Weaver Lab projects, bringing together two code bases with overlapping as well as complementary feature sets under a common umbrella repository. The core (and shared) design philosophy of Cacti is the enablement of interoperability in a manner that preserves the self-sovereignty of existing networks while providing consensus-driven control over cross-network interactions, does not require modifications to existing DLT stacks, and eschews reliance on third-party chains. Cacti covers the spectrum of generic interoperability modes required to fulfil cross-network transactions, namely asset exchanges, asset transfers, and ledger data sharing.</p> <p>Cacti is built on a modular architecture and supports extensions through the plugin model. It maintains certain core components that are independent of DLTs, and also packages (called connectors or drivers) and libraries for specific DLTs. The following blockchains and DLTs are presently supported to varying extents within the repository:</p> <ul> <li>Hyperledger Besu</li> <li>Hyperledger Fabric</li> <li>Hyperledger Indy</li> <li>Hyperledger Iroha</li> <li>Hyperledger Sawtooth</li> <li>R3 Corda</li> <li>Go-Ethereum</li> <li>Xdai</li> </ul> <p>Client libraries and examples are provided in the following languages: JavaScript/TypeScript, Golang, Java/Kotlin, Solidity.</p>"},{"location":"#useful-links","title":"Useful links","text":"<ul> <li>Vision</li> <li>Architecture</li> <li>Cactus whitepaper</li> <li>Weaver RFCs</li> <li>Running pipelines with Cactus packages</li> <li>Running pipelines with Weaver packages</li> <li>Open API Specifications</li> </ul> <p>Note</p> <p>If you have questions not addressed by this documentation, or run into issues with any of the tutorials, please reach out to the Cacti maintainers (and community).</p>"},{"location":"architecture/","title":"Architecture","text":"<p>The Cacti integrated architecture is illustrated below.</p> <p></p> <p>This consists of a set of modules, services (offering standard APIs), and libraries that offer a selection of cross-network transaction pipelines, which can be constructed by picking and choosing from the collection.</p> <p>The integrated architecture was generated by fusing the pre-existing Cactus and Weaver architectures, identifying and re-labeling common (or overlapping) components and calling out unique components separately.</p> <p>For reference, here is the Cactus architecture.</p> <p></p> <p>And here is the Weaver architecture.</p> <p></p>"},{"location":"contact-us/","title":"Contact Us","text":"<p>You can contact us or seek help through the following channels:</p> <ul> <li>Mailing list: cacti@lists.hyperledger.org</li> <li>Discord channels:</li> <li>Cacti users: https://discord.com/channels/905194001349627914/908379366650703943</li> <li>Cacti contributors: https://discord.com/channels/905194001349627914/908379338716631050</li> <li>Hyperledger: https://discord.com/invite/hyperledger</li> </ul> <p>The maintainers are listed in the GitHub repository.</p>"},{"location":"faqs/","title":"Frequently Asked Questions","text":""},{"location":"faqs/#history","title":"History","text":""},{"location":"faqs/#when-and-how-was-cacti-created","title":"When and how was Cacti created?","text":"<p>Cacti was created as the merer of two pre-existing Hyperledger projects in late 2022. See the announcement blog post for details.</p>"},{"location":"faqs/#who-is-involved-in-maintaining-cacti","title":"Who is involved in maintaining Cacti?","text":"<p>The project is maintained jointly by members of Accenture, Fujitsu, and IBM, with contributions from a diverse community of open-source developers and researchers.</p>"},{"location":"faqs/#usage-and-logistics","title":"Usage and Logistics","text":""},{"location":"faqs/#how-do-i-contribute-to-the-project","title":"How do I contribute to the project?","text":"<p>Here is how you can contribute to Cacti. For specific help or troubleshooting, visit the project's Discord channels.</p>"},{"location":"glossary/","title":"Glossary","text":"interoperability <p>capabilities that enable a given blockchain or DLT network to share and exchange ledger state information and assets with each other, and thereby to seamlessly fulfil transactions that advance the states of multiple chains simultaneously.</p> asset exchange <p>to be filled in</p> asset transfer <p>to be filled in</p> data sharing <p>to be filled in</p> node server <p>to be filled in</p> relay <p>to be filled in</p> connector <p>to be filled in</p> driver <p>(synonymous with \"connector\")</p>"},{"location":"use-cases/","title":"Use Cases and Applications for Cacti","text":"<p>This page is under construction. While we are working on it, you can find compelling examples and sample code here, here, here, and here.</p>"},{"location":"vision/","title":"Vision","text":""},{"location":"vision/#mission-and-objectives","title":"Mission and Objectives","text":"<p>Cacti aims to make the process of interoperation, interconnection, and integration of systems built on blockchain or DLT with each other (or with centralized systems) easy, controllable, trustworthy, and decentralized. It will allow networks to remain self-sovereign and evolve independently without losing the ability to link with other networks and manage digital assets across networks when required. In effect, it enables a network-of-networks, or a global scale decentrantralized system of networks (akin to the Internet) without forcing all networks to coalesce, or subscribe to, a single canonical chain.</p>"},{"location":"vision/#project-scope","title":"Project Scope","text":"<p>The existence of several blockchain and distributed ledger technologies of different flavors in the market as well as networks of varying scopes and sizes built on them necessitates the need for interoperability and integration, lest we end up with a fragmented ecosystem where digital assets and the workfows (often contracts) governing them remain isolated in silos. The solution to this is not to force all chains to coalesce (i.e., \"a single chain to rule them all\") but rather enable the networks to orchestrate transactions spanning their boundaries without sacrificing security, privacy, or governance autonomy (i.e., self-sovereignty). Hyperledger Cacti offers a family of protocols, modules, libraries, and SDKs, that can enable one network to be interoperable with, and carry out transactions directly with, another while eschewing the need for a central or common settlement chain. Cacti will allow networks to share ledger data, and exchange and transfer assets atomically, and manage identities, across their boundaries, as illustrated in the figure below.</p> <p></p> <p>As a fusion of two earlier systems (Cactus and Weaver) that have similar philosophies and goals, yet offer distinct mechanisms backed by differemt design and trust assumptions, Cacti offers a spectrum of selectable and configurable features for cross-network transaction orchestrations. An example illustrated below shows how distributed applications running on Fabric and Besu ledgers respectively can carry out the same set of cross-network transactions using the Node Server (Cactus legacy) or through Relays (Weaver legacy).</p> <p></p> <p>The present (initial) version of the Cacti code base is simply an aggregation of the legacy Cactus and Weaver code bases with their original folder structures. Until merge and integration (see further below), users should examine, test, and use them separately as follows: - Cactus code and documentation lies within this (root) folder, excluding the <code>weaver</code> folder. See Cactus documentation to test and use Cactus. - Weaver code and documentation lies within the weaver folder. See Weaver documentation to test and use Weaver.</p>"},{"location":"vision/#project-roadmap","title":"Project Roadmap","text":"<p>You can find the project roadmap in the GitHub repository.</p>"},{"location":"blog/2021-01-21-cross-chain-asset/","title":"Enabling Cross-Chain Asset Exchange On Permissioned Blockchains","text":"<p>Authors: Yining Hu, Ermyas Abebe, Dileban Karunamoorthy, Venkatraman Ramakrishna</p> <p>Tags: [enterprise, interoperability, asset-exchange]</p>"},{"location":"blog/2021-01-21-cross-chain-asset/#introduction","title":"Introduction","text":"<p>Recent years have witnessed a growing demand for enabling interoperability across independent blockchains. Cross-chain asset exchange is a significant step towards blockchain interoperability. For public blockchains, the most popular application for asset exchange is cryptocurrency exchange. For permissioned blockchains, cross-chain asset exchange can be useful in Delivery Versus Payment (DvP) and cross-border payment scenarios. There exist various protocols designed for asset exchange on public blockchains. However, a widely adopted standard for designing such protocols for permissioned blockchains still does not exist. Moreover, most existing protocols are designed for public blockchains and their suitability to be applied to permissioned blockchains is unclear.</p> <p>In this article, we aim to lay out a set of requirements for designing cross-chain asset exchange protocols between permissioned blockchains. First we present a canonical motivating use case and then list the various patterns that such cases will follow in real-life scenarios. We then present a short survey of existing cross-chain exchange protocols for public blockchains, following which we summarise the building blocks, core mechanisms and security properties commonly involved in the protocol designs. We then analyse the requirements imposed by permissioned blockchains in comparison to public blockchains, and discuss the additional properties with respect to these restrictions.</p>"},{"location":"blog/2021-01-21-cross-chain-asset/#motivation-and-use-case","title":"Motivation and Use-case","text":"<p>In traditional financial markets parties trade assets such as securities and derivatives for cash or other assets. To reduce risk, various clearing and settlement processes and intermediaries are often involved. One form of settlement is a DvP where the transfer of securities is performed only in the event of a corresponding payment. This arrangement reduces principal risk by ensuring that both parties receive their end of the exchange. However, settlement in financial markets are slow and time consuming. It also involves counterparty risks and requires intermediaries.</p> <p>Over the past few years, we have been seeing significant efforts in digitising and tokenising both currencies and securities on Distributed Ledger Technology (DLT) infrastructures. On the one hand we have seen concerted efforts around Central Bank Digital Currencies (CBDC) being added to the landscape of other blockchain based payment networks. On the other hand, we have also seen efforts such as that from the Australian Stock Exchange (ASX) to replace its current settlement system--Clearing House Electronic Subregister System (CHESS) with a DLT based platform by 2021.</p> <p>Against this backdrop, a number of central banks have been exploring the potential of performing DvP settlement across a currency ledger and a securities ledger. In this article, we use this as a motivating use-case for our discussions. The scenario involves two decentralised ledgers, namely, a currency ledger and a securities ledger, based on different DLT protocols performing a coordinated transfer of assets in their respective ledgers. Figure 1 depicts this scenario in the context of two organisations--Bank A and Bank B--in which Bank B wants to purchase some securities owned by Bank A and both organisations have accounts on both ledgers. To effect this exchange the following two transactions will have to happen atomically across both networks: i) transfer of payment from Bank B's currency account to Bank A while at the same time ii) the entitlements of the designated securities is transferred from Bank A to Bank B. The scenario would need to guarantee that after the transaction execution, either both parties have their end of the exchange or neither does and that this exchange is performed in a timely manner. </p> <p></p> <p>Figure 1. A typical DvP use-case.</p> <p>Cross-chain transactions involving the movement of assets can generally take the form of either an asset exchange between parties or of value transfer from one network to another. The latter involves a scenario in which an asset in one network is locked or burned and a corresponding asset of similar value is issued in a corresponding network. This process generally involves validators or asset issuers in either or both ends of the network. While there are numerous use cases for this model in permissionless context, in this post we primarily focus on asset exchange scenarios, which are more broadly applicable in enterprise use-cases. Asset exchange scenarios generally involve two users swapping corresponding assets managed by the different networks, as in the example illustrated earlier. In asset exchange scenarios involving only two parties, both parties have accounts on both networks, although this might not be the case for exchanges involving more than two parties or networks.</p>"},{"location":"blog/2021-01-21-cross-chain-asset/#cross-chain-asset-exchange-on-public-blockchains","title":"Cross-Chain Asset Exchange on Public Blockchains","text":"<p>Similar scenarios that involve a pair of transactions being coordinated across distinct blockchains have been studied for public blockchains. One main application area is to enable decentralised exchange across crypto-currency networks. To achieve this, a number of cross-chain asset exchange protocols have been proposed. The original atomic swap protocol was proposed by TierNolan in the Bitcoin Forum. The protocol leverages trusted escrow services on both blockchains and relies on the asset owners for execution. Prestwich later improved the protocol by removing the trusted escrow services and using a smart contract to automatically execute the swap. Both protocols, however, are asymmetric and hence enforce a particular sequence of events. More recently, a group of researchers developed Arwen, which guarantees the symmetricality of the protocol and further eases the asset owners' responsibilities in the protocol execution. </p> <p>We below first discuss the common patterns involved in the protocol design. More specifically, we present the main building blocks, core mechanisms, and security properties achieved by these protocols. </p>"},{"location":"blog/2021-01-21-cross-chain-asset/#building-blocks","title":"Building blocks","text":"<p>The design of a cross-chain asset exchange protocol in general contain the following building blocks: 1) the infrastructure for cross-chain state verification, and 2) the asset exchange protocol that specifies parties and sequences involved in the protocol execution. Cross-chain state verification can be performed by the exchanging parties themselves or by an external party.</p>"},{"location":"blog/2021-01-21-cross-chain-asset/#core-mechanisms","title":"Core Mechanisms","text":"<ul> <li> <p>Fund locking: To initialise an asset exchange, it is common for one or both parties to first lock up funds with a fund-withholding party on his or her own blockchain. Temporary fund locking ensures the locked fund cannot be used for other purposes while the exchange is being executed. This scheme is often used with a specified timeout to provide flexibility for reclaiming locked funds if the exchange does not take place.</p> </li> <li> <p>Fund redeeming: In general, the execution requires a pair of transactions to occur on both blockchains, e.g., from User A to User B on Chain A and from User B to User A on Chain B. When certain conditions are met, the locked funds can be redeemed by, or paid to the respective users. The execution of the exchange can be carried out by users themselves, or through other trusted third parties. These trusted third parties can be stand-alone parties that are not otherwise involved in both blockchains, or part of either blockchain. </p> </li> <li> <p>Refund: For protocols that are initialised with a temporary fund-locking, the locked funds can usually be reclaimed by the initial owner after a specified timeout. </p> </li> </ul>"},{"location":"blog/2021-01-21-cross-chain-asset/#security-properties","title":"Security Properties","text":"<ul> <li> <p>Atomicity: Atomicity is also sometimes referred to as safety. In general, atomicity implies indivisibility and irreducibility, namely, an atomic operation must be performed entirely or not performed at all. In the case of cross-chain asset exchange, when User A sends a payment to User B on Chain A, User B should also send corresponding delivery to User A on Chain B.</p> </li> <li> <p>Liveness: Specifies the design of an asset exchange protocol should ensure no party can be tricked into locking up funds forever or for a very long time.</p> </li> </ul>"},{"location":"blog/2021-01-21-cross-chain-asset/#extending-protocol-design-to-permissioned-blockchains","title":"Extending Protocol Design To Permissioned Blockchains","text":"<p>Requirements of Permissioned Blockchains As public blockchains offer decentralisation and transparency, existing cross-chain asset exchange protocols on public blockchains are often designed for users to voluntarily participant and execute. To ensure secure execution of these protocols, their designs usually incorporate economic incentives, together with on-chain punishment schemes. To ensure liveness, these protocols usually leverage group consensus and fault-tolerance.</p> <p>Permissioned blockchains on the other hand require privacy. Additional economic incentives and punishments are often not required besides the existing business relationships and established legal jurisdictions. Therefore, compared to public blockchains, the design of cross-chain asset exchange protocols on permissioned blockchains allows a higher level of centralisation and requires auditability and individual or group accountability for off-chain dispute resolution rather than economic incentives and on-chain punishments. Moreover, as permissioned blockchains themselves offer a higher throughput and faster transaction processing than public blockchains, the asset exchange protocol ideally should not introduce significant processing overheads that limit the transaction processing capability.</p> <p>Therefore, the challenges in designing cross-chain asset exchange protocols for permissioned networks can be summarised as follow: * Permissioned networks are usually confidential by design, thus restricting access for its internal members and external clients. State verification is hard to achieve across distinct permissioned blockchains. Cross-chain asset exchange protocols must therefore incorporate additional mechanisms to overcome these challenges. * Unlike public blockchains, permissioned blockchains derive their security from and the ability to hold parties accountable for their actions. Any party acting maliciously should be identified and penalized during an off-chain dispute resolution process. Thus we can relax some of the constraints of the exchange protocol. For example, we can leverage trusted third-parties instead of having to financially incentivise regular users to participate in running the protocol.</p>"},{"location":"blog/2021-01-21-cross-chain-asset/#additional-properties","title":"Additional Properties","text":"<p>In addition to following the same set of building blocks, core mechanisms and security properties as public protocols, we also identify an additional set of desired properties for permissioned blockchains.</p> <ul> <li> <p>Scalability: Scalability is often restricted by two factors. Firstly, the transaction processing capability of the underlying infrastructures. When a protocol relies on public blockchains, the throughput is consequently limited by the transaction processing of the blockchains themselves. In contrast, some protocols are off-chain, which usually allow faster transaction processing. Secondly, for protocols that involve third parties for fund-locking, such as Xclaim and Dogethereum, the amount of money owned by these third parties limits the number of transaction requests they can process. As permissioned blockchains in general have a higher throughput compared to public blockchains, the protocol design should not trade off scalability.</p> </li> <li> <p>Auditability: Auditability for public blockchains specifies that any party with read right should be able to detect protocol failure. On permissioned blockchains, however, as parties have limited visibility over the ledger state, who can detect protocol failure will most-likely depend on the use-case. In addition, financial regulatory requirements such as AML and CTF might require cross-chain traceability and auditability of exchange transactions (i.e. it should be easy to trace why Alice just transferred Bob $1M on a CBDC network).</p> </li> <li> <p>Accountability: Accountability says faulty parties should be held accountable. This can refer to individual accountability or group accountability. As it is hard to enforce on-chain punishments on permissioned blockchains, the protocol design should at least allow adversaries to be held accountable.</p> </li> <li> <p>Compatibility: Compatibility specifies how easy it is to implement the protocol on other blockchain platforms. The protocol design should be generic and not to be limited to particular blockchain platforms.</p> </li> <li> <p>Extensibility: Extensibility specifies how easy it is to extend the protocol to other use cases, for instance, from two parties to multiple parties, or from one particular transaction pattern to other transaction patterns. </p> </li> <li> <p>Privacy: Privacy is usually not automatically guaranteed by public blockchains. For sensitive use-cases, extra mechanisms such as a trusted execution environment (TEE) can be used. Privacy is also of vital importance when it comes to permissioned blockchains. Most existing cross-chain protocols are designed for public blockchains. As the execution of these protocols may require asset owners or third-parties to access states on either blockchain ledger, executing a cross-chain asset exchange can put user privacy at risk.</p> </li> <li> <p>Low Cost: As many of the cross-chain exchange protocols involve sending on-chain transactions, the concern over number of transactions and transaction fees arises when the protocol design involves a public blockchain.</p> </li> </ul>"},{"location":"blog/2021-01-21-cross-chain-asset/#conclusion","title":"Conclusion","text":"<p>To summarise, in this article we tackle the problem of enabling cross-chain asset exchange on permissioned blockchains and evaluate the different requirements imposed by public blockchains and permissioned blockchains. We also articulate a set of desired properties to guide the design of cross-chain asset exchange protocols.</p> <p>For general-purpose interoperability of enterprise blockchains, we have developed the Weaver tool that incorporates a cross-chain state verification engine to enable cross-chain state sharing and verification. Please check out our documentation for implementation details and example applications.</p>"},{"location":"blog/2021-01-21-emergence-enterprise-interoperability/","title":"Emergence of Enterprise DLT Interoperability","text":"<p>Author: Venkatraman Ramakrishna</p> <p>Tags: [enterprise, interoperability]</p> <p>It is instructive to know the course taken by blockchain technology and its applications over the past few years, as this will allow us to understand where we are, where are headed, and thereby motivate the necessity of interoperability.</p>"},{"location":"blog/2021-01-21-emergence-enterprise-interoperability/#the-grand-vision","title":"The Grand Vision","text":"<p>The original vision of blockchain technology called for a global decentralized network of peers and clients that could conduct transactions at scale without requiring intermediation by trusted third parties. The Bitcoin network was the first example of this, and it was purposely left open for anyone to join precisely because its initiators hoped for a single global network somewhat akin to the internet.</p> <p>But the limitations of Bitcoin as a transaction processing system soon became apparent, and the Ethereum network emerged to fill this gap, retaining the openness and scalability of Bitcoin while supporting arbitrary smart contracts over a shared ledger. But Ethereum too was not destined to be the single canonical global blockchain network that everyone would use.</p> <p>Sub-groups within the Bitcoin and Ethereum communities dissented from the rest, thereby creating forks, or separate networks with separate chains of blocks. Others found limitations in the usability of the existing networks or their consensus mechanisms (Proof of Work) and decided to build their own networks to which like-minded people could subscribe and in which they could conduct their transactions.</p> <p>Therefore, the original Bitcoin (or even Ethereum) vision of a single global network was not to be, and networks with different clientele and different consensus protocols proliferated.</p> <p>And then came private (or permissioned) networks......</p>"},{"location":"blog/2021-01-21-emergence-enterprise-interoperability/#evolution-of-private-networks","title":"Evolution of Private Networks","text":"<p>Sometime in the first half of the previous decade, it was recognized that networks like Bitcoin and Ethereum were not suitable for much of the business that involves private enterprises, governmental institutions, and ordinary clients. Private networks then emerged as a means to retain the trustworthiness and consensus-based decision-making properties of blockchains (and distributed ledgers in general) while ensuring that: - Transactions and ledger state are privy only to a selected set of entities, - Transactions can be audited by trusted authorities when required for dispute resolutions, and - Higher performance and assurance can be gained using consensus protocols other than proof-of-work.</p> <p>Since companies and consortia were wary of this new and unproven technology, the trend in industry these past few years has been to build minimum viable ecosystems, i.e., networks of limited operational scope and participation. The goal being to evaluate the potential of blockchain, these networks were created to manage selected few assets and records. Needless to say, interoperation with other networks was not high on the priority list when such networks were designed and launched.</p> <p>Many of these networks have been successfully validated and put into production. But a consequence of the decision to build limited-scope networks is that the processes they run (through smart contracts) and the assets and records they maintain on their ledgers are stuck in siloes, inaccessible to external entitites and networks. Yet, as we are discovering, processes and assets in such networks are inextricably linked in the real enterprise world. With all of the investment (in time and money) made in existing networks, reeingeneering or merging them will generally be hardsells. Also, some networks may wish to restrict operational control and ledger visibility to its current set of administrators and clientele. The only viable solution is to allow networks to interoperate, thereby breaking up the siloes, while retaining operational control.</p>"},{"location":"blog/2021-01-21-emergence-enterprise-interoperability/#diverse-platforms","title":"Diverse Platforms","text":"<p>Our present blockchain landscape (or ecosystem) is characterized not just by a plethora of networks, a mix of open and private, but also by the existence of several distinct blockchain technologies, each with a different storage technology, a different model for contracts and client applications, a different consensus protocol, and a different way of managing identity. Examples include Fabric, Iroha, Sawtooth, and Besu, all in the Hyperledger family, and Ethereum, Multichain, Cardano, and Komodo, outside it. There are also smart contract distributed ledger platforms that serve a similar set of business applications that are not blockchains at all, like R3's Corda.</p> <p>Since there is no single blockchain, or distributed ledger, technology, the world agrees on, and because each offers a different set of advantages and disadvantages, the networks that exist today are built on a diverse set of such platforms.</p>"},{"location":"blog/2021-01-21-emergence-enterprise-interoperability/#blockchain-landscape","title":"Blockchain Landscape","text":"<p>Our present is, and our near future will be, characterized by the existence of independent networks, some of which offer open membership whereas others are restricted, built on diverse platforms that are mutually incompatible. Asking everyone to converge to a single global network running on a single canonical platform is almost impossible. So unless we wish entities and assets to remain trapped within siloes, it should be evident that interoperability amoong different networks and platforms is crucial to the success of blockchain.</p>"},{"location":"blog/2021-01-21-emergence-enterprise-interoperability/#challenges","title":"Challenges","text":"<p>Interlinking processes distributed across different networks or transferring or sharing assets and data may sound like a straightforward task, but the traditional method of service and API integration will not work in scenarios that involve permissioned networks.</p> <p>This is because, as you will see in the user stories, entities that are interested in the asset or data record being shared may not be members of both networks. And even if a particular entity happens to be a member of both networks, it may be in its interest to present a false view of one network's ledger state to another.</p> <p>Therefore, interoperation cannot be allowed to hinge on the trustworthiness of a particular network member, or by extension, a third party. In the stories we will encounter, it will be apparent how such situations may occur. This will make the unreliability of API integration across private networks clear and also motivate the need for consensus-based interoperation protocols.</p>"},{"location":"blog/2022-11-07-introducing-hyperledger-cacti/","title":"Introducing Hyperledger Cacti, a multi-faceted pluggable interoperability framework","text":"<p>See the original Hyperledger Foundation blog article.</p>"},{"location":"blog/2023-10-03-hyperledger-cacti-graduation/","title":"Hyperledger Cacti, A General-Purpose Modular Interoperability Framework, Moves to Graduated Status","text":"<p>See the original Hyperledger Foundation blog article.</p>"},{"location":"cactus/build/","title":"Hyperledger Cactus Build Instructions","text":"<p>This is the place to start if you want to give Cactus a spin on your local machine or if you are planning on contributing.</p> <p>This is not a guide for <code>using</code> Cactus for your projects that have business logic but rather a guide for people who want to make changes to the code of Cactus. If you are just planning on using Cactus as an npm dependency for your project, then you might not need this guide at all.</p> <p>The project uses Typescript for both back-end and front-end components.</p>"},{"location":"cactus/build/#developers-guide","title":"Developers guide","text":"<p>This is a video guide to setup Hyperledger Cactus on your local machine.</p>"},{"location":"cactus/build/#installing-git","title":"Installing git","text":""},{"location":"cactus/build/#installing-and-configuring-docker","title":"Installing and configuring docker","text":""},{"location":"cactus/build/#installing-npm-and-node","title":"Installing npm and node","text":""},{"location":"cactus/build/#installing-jdk-8","title":"Installing jdk 8","text":""},{"location":"cactus/build/#installing-vscode-and-plugins","title":"Installing VSCode and plugins","text":""},{"location":"cactus/build/#clone-the-repository","title":"Clone the repository","text":""},{"location":"cactus/build/#compiling-all-packages","title":"Compiling all packages","text":""},{"location":"cactus/build/#testing-all-packages","title":"Testing all packages","text":""},{"location":"cactus/build/#compiling-a-specific-packages","title":"Compiling a specific packages","text":""},{"location":"cactus/build/#testing-a-specific-package","title":"Testing a specific package","text":""},{"location":"cactus/build/#package-structure-openapi","title":"Package structure - OpenAPI","text":""},{"location":"cactus/build/#package-structure-web-services","title":"Package structure - Web Services","text":""},{"location":"cactus/build/#package-structure-main-and-factory-plugin-class","title":"Package structure - Main and Factory Plugin class","text":""},{"location":"cactus/build/#package-structure-test-class","title":"Package structure - Test class","text":""},{"location":"cactus/build/#fast-developer-flow-code-iterations","title":"Fast Developer Flow / Code Iterations","text":"<p>We put a lot of thought and effort into making sure that fast developer iterations can be achieved (please file a bug if you feel otherwise) while working on the framework.</p> <p>If you find yourself waiting too much for builds to finish, most of the time that can be helped by using the <code>npm run watch</code> script which can automatically recompile packages as you modify them (and only the packages that you have modified, not everything).</p> <p>It also supports re-running the OpenAPI generator when you update any <code>openapi.json</code> spec files that we use to describe our endpoints.</p> <p>The <code>npm run watch</code> script in action:</p> <p></p>"},{"location":"cactus/build/#getting-started","title":"Getting Started","text":"<ul> <li> <p>Use preset environment:</p> <ul> <li>VSCode docker container</li> </ul> </li> <li> <p>\u2026 or install OS level dependencies manually:</p> <ul> <li> <p>Windows Only</p> <ul> <li>WSL2 or any virtual machine running Ubuntu 20.04 LTS</li> </ul> </li> <li> <p>Git</p> </li> <li> <p>NodeJS v16.14.2, npm v8.5.0 (we recommend using the Node Version Manager (nvm) if available for your OS)</p> <p>nvm install 16.14.2 nvm use 16.14.2</p> </li> <li> <p>Yarn</p> <ul> <li><code>npm run install-yarn</code> (from within the project directory)</li> </ul> </li> <li> <p>Docker Engine. Make sure that Docker is working and running, for example, running <code>docker ps -aq</code></p> </li> <li> <p>Docker Compose</p> </li> <li> <p>OpenJDK (Corda support Java 8 JDK but do not currently support Java 9 or higher)</p> <ul> <li><code>sudo apt install openjdk-8-jdk-headless</code></li> </ul> </li> <li> <p>Indy SDK (optional)</p> <ul> <li> <p>Installing the SDK</p> </li> <li> <p>Build the SDK from source</p> </li> </ul> </li> </ul> </li> <li> <p>Clone the repository</p> </li> </ul> <p>git clone https://github.com/hyperledger/cactus.git</p> <p>Windows specific gotcha: <code>File paths too long</code> error when cloning. To fix: Open PowerShell with administrative rights and then run the following:</p> <p>git config --system core.longpaths true</p> <ul> <li>Change directories to the project root</li> </ul> <p>cd cactus</p> <ul> <li>Run this command to enable corepack (Corepack is included by default with all Node.js installs, but is currently opt-in.)</li> </ul> <p>npm run enable-corepack</p> <ul> <li>Run the initial configuration script (can take a long time, 10+ minutes on a low-spec laptop)</li> </ul> <p>yarn run configure</p> <p>At this point you should have all packages built for development.</p> <p>You can start making your changes (use your own fork and a feature branch) or just run existing tests and debug them to see how things fit together.</p> <p>For example you can run a ledger single status endpoint test via the REST API with this command:</p> <p>npx tap --ts --timeout=600 packages/cactus-test-plugin-htlc-eth-besu/src/test/typescript/integration/plugin-htlc-eth-besu/get-single-status-endpoint.test.ts</p> <p>You can also start the API server and verify more complex scenarios with an arbitrary list of plugins loaded into Cactus. This is useful for when you intend to develop your plugin either as a Cactus maintained plugin or one on your own.</p> <p>npm run generate-api-server-config</p> <p>Notice how this task created a .config.json file in the project root with an example configuration that can be used a good starting point for you to make changes to it specific to your needs or wants.</p> <p>The most interesting part of the <code>.config.json</code> file is the plugins array which takes a list of plugin package names and their options (which can be anything that you can fit into a generic JSON object).</p> <p>Notice that to include a plugin, all you need is specify it\u2019s npm package name. This is important since it allows you to have your own plugins in their respective, independent Github repositories and npm packages where you do not have to seek explicit approval from the Cactus maintainers to create/maintain your plugin at all.</p> <p>Once you are satisfied with the <code>.config.json</code> file\u2019s contents you can just:</p> <p>npm run start:api-server</p> <p>After starting the API server, you will see in the logs that plugins were loaded and that the API is reachable on the port you specified (4000 by default). The Web UI (Cockpit) is disabled by default but can be enabled by changing the property value \u2018cockpitEnabled\u2019 to true and it is reachable through port on the port your config specified (3000 by default).</p> <p>You may need to enable manually the CORS patterns in the configuration file. This may be slightly inconvenient, but something we are unable to compromise on despite valuing developer experience very much. We have decided that the software should be <code>secure by default</code> above all else and allow for customization/degradation of security as an opt-in feature rather than starting from that state.</p> <p>At this point, with the running API server, you can</p> <ul> <li> <p>Test the REST API directly with tools like cURL or Postman</p> </li> <li> <p>Develop your own applications against it with the <code>Cactus API Client(s)</code></p> </li> <li> <p>Create and test your own plugins</p> </li> </ul>"},{"location":"cactus/build/#random-windows-specific-issues-not-covered-here","title":"Random Windows specific issues not covered here","text":"<p>We recommend that you use WSL2 or any Linux VM (or bare metal). We test most frequently on Ubuntu 20.04 LTS</p>"},{"location":"cactus/build/#build-script-decision-tree","title":"Build Script Decision Tree","text":"<p>The <code>npm run watch</code> script should cover 99% of the cases when it comes to working on Cactus code and having it recompile, but for that last 1% you\u2019ll need to get your hands dirty with the rest of the build scripts. Usually this is only needed when you are adding new dependencies (npm packages) as part of something that you are implementing.</p> <p>There are a lot of different build scripts in Cactus in order to provide contributors fine\u00ae grained control over what parts of the framework they wish build.</p> <p>Q: Why the complexity of so many build scripts?</p> <p>A: We could just keep it simple with a single build script that builds everything always, but that would be a nightmare to wait for after having changed a single line of code for example.</p> <p>To figure out which script could work for rebuilding Cactus, please follow the following decision tree (and keep in mind that we have <code>npm run watch</code> too)</p> <p></p>"},{"location":"cactus/build/#configuring-ssh-to-use-upterm","title":"Configuring SSH to use upterm","text":"<p>Upload your public key onto github if not done so already. A public key is necessary to join the ssh connection to use upterm. For a comprehensive guide, see the Generating a new SSH key and adding it to the ssh-agent.</p> <p>Locate the <code>ci.yml</code> within <code>.github/workflows</code> and add to the <code>ci.yml</code> code listed below:</p> <ul> <li>name: Setup upterm session uses: lhotari/action-upterm@v1 with: repo-token: ${{ secrets.GITHUB_TOKEN }}</li> </ul> <p>Keep in mind that the SSH upterm session should come after the checkout step (uses: actions/checkout@v4.1.1) to ensure that the CI doesn\u2019t hang without before the debugging step occurs. Editing the <code>ci.yml</code> will create a new upterm session within <code>.github/workflows</code> by adding a new build step. For more details, see the Debug your GitHub Actions by using ssh.</p> <p>By creating a PR for the edited <code>ci.yml</code> file, this will the CI to run their tests. There are two ways to navigate to CIs.</p> <ol> <li> <p>Go to the PR and click the <code>checks</code> tab</p> </li> <li> <p>Go to the <code>Actions</code> tab within the main Hyperledger Cactus Repository</p> </li> </ol> <p>Click on the <code>CI Cactus workflow</code>. There should be a new job you\u2019ve created be listed underneath the <code>build (ubuntu-22.04)</code> jobs. Click on the the new job (what\u2019s you\u2019ve named your build) and locate the SSH Session within the <code>Setup Upterm Session</code> dropdown. Copy the SSH command that start with <code>ssh</code> and ends in <code>.dev</code> (ex. ssh **********:***********@uptermd.upterm.dev). Open your OS and paste the SSH command script in order to begin an upterm session.</p> <p>Previous Next</p>"},{"location":"cactus/code-of-conduct/","title":"Code of Conduct Guidelines","text":"<p>Please review the Hyperledger Code of Conduct before participating and abide by these community standards.</p> <p>Previous Next</p>"},{"location":"cactus/contributing/","title":"Contributing","text":"<p>Thank you for your interest to contribute to Hyperledger Cactus! </p> <p>First things first, please review the Hyperledger Code of Conduct before participating.</p> <p>There are many ways to contribute to Hyperledger Cactus, both as a user and as a developer.</p> <p>As a user, this can include:</p> <ul> <li> <p>Making Feature/Enhancement Proposals</p> </li> <li> <p>Reporting bugs</p> </li> </ul> <p>As a developer:</p> <ul> <li> <p>if you only have a little time, consider picking up a \u201chelp-wanted\u201d or \u201cgood-first-issue\u201d task</p> </li> <li> <p>If you can commit to full-time development, then please contact us on our Rocketchat channel to work through logistics!</p> </li> </ul>"},{"location":"cactus/contributing/#git-know-how-reading-list","title":"Git Know How / Reading List","text":"<p>This section is for you if you do not know your way around advanced git concepts such as</p> <ul> <li> <p>rebasing (interactive or otherwise)</p> </li> <li> <p>splitting commits/PRs</p> </li> <li> <p>when to use and not to use force push</p> </li> </ul> <p>A word on the controversial topic of force pushes: In many git guides you will read that force push is basically forbidden. This is true 99% of the time, BUT if you are the only person working on a branch (which is most of time true for a feature/fix branch of yours that you are planning to submit as a PR) then force pushing is not just allowed but necessary to avoid messy git commit logs. The question you need to ask yourself before force pushing is this: Am I going to destroy someone else\u2019s work on the remote branch? If nobody else is working on the branch then the answer is of course no and force push can be used safely. If others are working with you on the branch on the other hand, it is considered polite to ask and warn them in advance prior to force pushing so that they can take the necessary precautions on their side as well.</p> <p>A handy tool to avoid destroying other\u2019s work accidentally is the new(ish) git feature called <code>--force-with-lease</code>: Using <code>git push --force-with-lease</code> instead of vanilla <code>--force</code> is highly recommended: https://softwareengineering.stackexchange.com/a/312710</p> <p>The rustlang documentation has an excellent write-up and additional links on pretty much everything you need to know. The only difference between their PR requirements and Cactus\u2019 is that we do encourage people referencing github issues in commit messages. Quoting the most relevant parts below (and thanks to the Rust maintainers for this).</p> <p>Pull requests are the primary mechanism we use to change Rust. GitHub itself has some great documentation on using the Pull Request feature. We use the \u201cfork and pull\u201d model described here, where contributors push changes to their personal fork and create pull requests to bring those changes into the source repository.</p> <p>Please make pull requests against the main branch.</p> <p>Rust follows a no merge policy, meaning, when you encounter merge conflicts you are expected to always rebase instead of merge. E.g. always use rebase when bringing the latest changes from the main branch to your feature branch. Also, please make sure that fixup commits are squashed into other related commits with meaningful commit messages.</p> <p>GitHub allows closing issues using keywords. This feature should be used to keep the issue tracker tidy.</p> <p>Source: https://github.com/rust-lang/rust/blob/53702a67e2ae8a404169a0329f6a38d73bf7494d/CONTRIBUTING.md#pull-requests</p> <p>Further reading:</p> <ul> <li> <p>https://help.github.com/en/github/collaborating-with-issues-and-pull-requests/about-collaborative-development-models</p> </li> <li> <p>https://help.github.com/en/github/collaborating-with-issues-and-pull-requests/about-pull-requests</p> </li> </ul>"},{"location":"cactus/contributing/#pr-checklist-contributordeveloper","title":"PR Checklist - Contributor/Developer","text":"<p>To avoid issues in the future, do not install dependencies globally. Ensure all dependencies are kept self-contained.</p> <ol> <li> <p>Fork hyperledger/cactus via Github UI</p> <ul> <li> <p>If you are using the Git client on the Windows operating system, you will need to enable long paths for git which you can do in PowerShell by executing the command below. To clarify, this may also apply if you are using any Git GUI application on Windows such as <code>Github Desktop</code> or others.</p> <p>git config --global core.longpaths true</p> </li> </ul> </li> <li> <p>Clone the fork to your local machine</p> </li> <li> <p>(Optional) Create local branch for minimizing code conflicts when you want to contribute multiple changes regarding different issues in parallel.</p> </li> <li> <p>Complete the desired changes and where possible test locally</p> <ol> <li> <p>You can run the full CI suite on Mac/Linux/WSL by running the script at <code>./tools/ci.sh</code></p> </li> <li> <p>If you do not have your environment set up for running bash scripts, do not worry, all pull requests will automatically have the same script executed for it when opened. The only downside is the slower feedback loop.</p> </li> </ol> </li> <li> <p>Make sure you have set up your git signatures</p> <ol> <li> <p>Note: Always sign your commits using the <code>git commit -S</code></p> </li> <li> <p>For more information see here</p> </li> </ol> </li> <li> <p>Think about/decide on what your commit message will be.</p> <ol> <li> <p>The commit message syntax might be hard to remember at first so you we invite you to use the <code>npm run commit</code> command which upon execution presents you with a series of prompts that you can fill out and have your input validated in realtime, making it impossible (or at least much harder) to produce an invalid commit message that the commit lint bot on Github will flag with an error.</p> <ol> <li> <p>The use of this tool described above is entirely optional in case you need a crutch.</p> </li> <li> <p>Note that running the <code>npm run commit</code> command will also attempt to perform the actual commit at the end unless you kill the process with <code>Ctrl + C</code> or whatever is your terminal\u2019s shortcut for the same action.</p> </li> <li> <p>The <code>npm run commit</code> command will also attempt to sign the produced commit so make sure that it is set up properly prior to using it.</p> </li> </ol> </li> </ol> </li> <li> <p>Commit your changes</p> <ol> <li> <p>Make sure your commit message follows the formatting requirements (details above) and here: Conventional Commits syntax; this aids in release notes generation which we intend to automate</p> </li> <li> <p>Be aware that we are using git commit hooks for the automation of certain mundane tasks such as applying the required code style and formatting so your code will be wrapped at 80 characters each line automatically. If you wish to see how your changes will be altered by the formatter you can run the <code>npm run prettier</code> command from a terminal or install an IDE extension for the <code>Prettier</code> tool that can do the same (VSCode has one that is known to work).</p> </li> </ol> </li> <li> <p>Ensure your branch is rebased onto the <code>upstream</code> main branch where <code>upstream</code> is fancy git talk for the main Cactus repo on Github (the one you created your fork from).</p> <ol> <li> <p>Do not duplicate your pull request after it has been reviewed. Duplication here means closing the existing PR and then opening a brand new one which does not contain the review history anymore. If you encounter issues with version control that you do not know how to solve the maintainers will be happy to assist to ensure that you do not need to open a new pull request from scratch.</p> <ol> <li>The only exception from the rule above is if you mistakenly named your branch to contain special characters and somehow ended up in a state where it has become impossible to push changes to the remote due to this (which has happened before with branch names like <code>refactor(core-api): x</code> that had to be renamed to <code>refactor-core-api-x</code> and then a new PR had to be created in that case because GitHub does not let you rename the remote branch that your pull request is tied to)</li> </ol> </li> <li> <p>If you are having trouble, there are many great resources out there (so we will not write another here).</p> <ol> <li> <p>If you are having trouble locating a suitable guide specifically on the mechanics of rebasing, we can recommend this one. Thanks to Rafael for the link!</p> </li> <li> <p>If you went through that tutorial and still not quite sure what\u2019s up, give this one a shot as well: https://about.gitlab.com/blog/2020/11/23/keep-git-history-clean-with-interactive-rebase/</p> </li> </ol> </li> <li> <p>If merge conflicts arise, you must fix these at rebase time since omitting this step does not magically make the conflicts go away, just pushes it over the fence to the maintainer who will attempt to merge your pull request at a later point in time.</p> </li> <li> <p>If the above happens, at that point said maintainer will most likely ask you (if not already) to perform the rebase anyway since as the author of a change you are best positioned to resolve any conflicts on the code level. Occassionally maintainers may do the merge/conflict resolution themselves, but do not count on this nor try to make a habit out of relying on the potential kindness.</p> </li> <li> <p>After successful rebasing, take another look at your commit(s). Ideally there should be just one in each pull request, but also on the other hand each commit should be as small, simple and self contained as possible, so there can be cases where it makes sense to submit a PR with multiple commits if for example you also had to change something in the test tooling while implementing a feature (in which case there could be a commit for the feature itself and another for the necessary changes to the test tooling package). What we respectfully ask though is that you try to avoid these situations and submit most of your PRs with a single, self contained commit that does not touch multiple things. This significantly reduces the cognitive load required to review the changes which in turn makes everyone happier: the maintainers will have an easier job reviewing, which means they\u2019ll be doing it faster which will (probably) cause you joy in turn.</p> </li> </ol> </li> <li> <p>Push your changes to your main (or whatever you named your feature branch, that is entirely up to you at the end of the day)</p> </li> <li> <p>Initiate a pull request from your fork to the base repository</p> </li> <li> <p>Remember: Opening a pull request is like saying \u201cHey maintainers, I have this change finalized and ready for you to spend time on reviewing it.\u201d The word <code>finalized</code> here is understood to imply that you are not planning on doing any more changes on the branch apart from when being asked to by the reviewers.</p> </li> <li> <p>It is perfectly acceptable to open a pull request and mark it as <code>draft</code> (a GitHub feature) which then signals to the maintainers that if they have time, they are welcome to look at the change, but it may or may not be in its final form yet so you are not responsible for potential loss of time on their end if the review has to be performed multiple times on account of changes. Once you promote your draft PR to a real one, the comments from the point above apply however.</p> </li> <li> <p>If your pull request contains a significant change, we recommend that you apply the similarly named github label on in it as well. It is okay if you do not do this, if we detect that the change is indeed significant, we will apply the label. If you do it in advance however, it will probably speed up the proceedings by removing one communication roundtrip from the review process of your pull request.</p> </li> <li> <p>Await CI, DCO &amp; linting quality checks, as well as any feedback from reviewers</p> </li> <li> <p>If you need to update your pull request either because you discovered an issue or because you were asked to do so we ask that you:</p> </li> <li> <p>try to add the change in a way that does not produce additional commits on the PR but instead do an <code>git commit --amend --signoff</code> on your local branch and then a force push to the remote branch of yours (the PR essentially). Again, if the change you are doing does not fit within any one of the existing commits of your PR, then it is justified to add a new commit and this is up to your discretion (maintainers may respectfully ask you to squash if they see otherwise)</p> </li> <li> <p>The rule of thumb for any and all things in git/Cactus is to maintain a clean, tidy commit log/history that enables everyone to easily look up changes and find accurate answers to the basic questions of <code>Who? / What? / When / Why?</code>. If you have ever been in a situation when you tried to figure out the original point a bug was introduced (and tried to figure out why the offending change was made in the first place) and the git blame just lead you to a 10 megabyte large patch with the message \u2018merge xyz\u2019, then you know exactly what it is we are trying to avoid here. :-)</p> </li> </ol>"},{"location":"cactus/contributing/#pr-checklist-maintainerreviewer","title":"PR Checklist - Maintainer/Reviewer","text":"<p>Ensure all the following conditions are met (on top of you agreeing with the change itself)</p> <ol> <li> <p>All automated checks that are not explicitly called out here are also passing/green.</p> </li> <li> <p>Branch is rebased onto main and there are no dangling/duplicate commits.</p> </li> <li> <p>Commits appear simple and self contained. Simple is always relative to the mangitude of the change itself of course. A 1k line change can still be simple if all it does is rename some commonly used variable in each place its being used.</p> </li> <li> <p>If the contributors are having trouble with git basic functionality such as rebasing / force pushing, DCO, do your best to help them out, when in doubt feel free to reach out to Peter (who is the one insisting an all these git rules so he deserves to be the primary contact for all git related issues).</p> <ol> <li>Remember that we want to foster a welcoming community so if someone is new to git try to be extra patient with them on this front.</li> </ol> </li> <li> <p>Ensure the commit messages are according to the standard format.</p> <ol> <li> <p>Remember that if you select \u2018squash\u2019 on the Github UI when accepting the pull request, Github will (by default) offer up the title of the pull request as the new commit message for your squash commit. This is not good unless the title happens to be a valid commit message, but in the likely event of it not being as such, you must take special care to type in a valid commit message right there and then on the Github UI.</p> </li> <li> <p>To avoid the hassle/potential issues with the above, it is recommended that you always use \u2018rebase\u2019 when accepting a pull request even if there are multiple commits that you\u2019d otherwise like to see squashed.</p> </li> <li> <p>If you are adamant that you do not want to merge a PR with multiple commits, that is completely understandable and fair game. The recommended approach there is to ask the contributor to break the pull request up to multiple pull requests by doing an interactive rebase on their branch and cherry picking/re-ordering things accordingly. This is a fairly advanced git use case so you might want to help them out with it (or ask Peter who is the one constantly nagging everyone about these git rules\u2026)</p> </li> </ol> </li> </ol> <p>To protect the Hyperledger Cactus source code, GitHub pull requests are accepted from forked repositories only. There are also quality standards identified and documented here that will be enhanced over time.</p>"},{"location":"cactus/contributing/#create-local-branch","title":"Create local branch","text":"<p>Whenever you begin work on a new feature or bugfix, it\u2019s important that you create a new branch.</p> <ol> <li> <p>Clone your fork to your local machine</p> </li> <li> <p>Setup your local fork to keep up-to-date (optional)</p> <p># Add 'upstream' repo to list of remotes git remote add upstream https://github.com/hyperledger/cactus.git</p> <p># Verify the new remote named 'upstream' git remote -v</p> <p># Checkout your main branch and rebase to upstream. # Run those commands whenever you want to synchronize with main branch git fetch upstream git checkout main git rebase upstream/main</p> </li> <li> <p>Create your branch.</p> <p># Checkout the main branch - you want your new branch to come from main git checkout main</p> <p># Create a new branch named `` (give simple informative name) git branch &lt;newfeature&gt; <li> <p>Checkout your branch and add/modify files.</p> <p>git checkout &lt;newfeature&gt; git rebase main # Happy coding !</p> </li> <li> <p>Commit changes to your branch.</p> <p># Commit and push your changes to your fork git add -A git commit -s -m \"[optional scope]: \" git push origin &lt;newfeature&gt; <li> <p>Once you\u2019ve committed and pushed all of your changes to GitHub, go to the page for your fork on GitHub, select your development branch, and click the pull request button.</p> </li> <li> <p>Repeat step 3 to 6 when you need to prepare posting new pull request.</p> </li> <p>NOTE: Once you submitted pull request to Cactus repository, step 6 is not necessary when you made further changes with <code>git commit --amend</code> since your amends will be sent automatically.</p> <p>NOTE: You can refer original tutorial \u2018GitHub Standard Fork &amp; Pull Request Workflow\u2019</p>"},{"location":"cactus/contributing/#directory-structure","title":"Directory structure","text":"<p>Whenever you begin to use your codes on Hyperledger Cactus, you should follow the directory strecture on Hyperledger Cactus. The current directory structure is described as the following:</p> <ul> <li> <p>contrib/ : Contributions from each participants, which are not directly dependent on Cactus code.</p> <ul> <li> <p>Fujitsu-ConnectionChain/</p> </li> <li> <p>Accenture-BIF/</p> </li> </ul> </li> <li> <p>docs/</p> <ul> <li> <p>API/</p> <ul> <li> <p>business-logic-plugin.md</p> </li> <li> <p>ledger-plugin.md</p> </li> <li> <p>routing-interface.md</p> </li> </ul> </li> </ul> </li> <li> <p>examples/</p> <ul> <li> <p>example01-car-trade/</p> <ul> <li>src/</li> </ul> </li> </ul> </li> <li> <p>plugins/</p> <ul> <li> <p>business-logic-plugin/</p> <ul> <li>lib/ : libraries for building Business Logic Plugin</li> </ul> </li> <li> <p>ledger-plugin/ : Codes of Ledger Plugin</p> <ul> <li> <p>(ledger-name)/ : Including the ledger name (e.g. Ethereum, Fabric, \u2026)</p> <ul> <li> <p>verifier/</p> <ul> <li> <p>src/ : Source codes of Verifier on Ledger Plugin</p> </li> <li> <p>unit-test/ : Unit test codes of Verifier on Ledger Plugin (single driver / driver and docker env / \u2026)</p> </li> </ul> </li> <li> <p>validator/</p> <ul> <li> <p>src/ : Source codes of Validator on Ledger Plugin</p> </li> <li> <p>unit-test/ : Unit test codes of Validator on Ledger Plugin (single driver / driver and docker env / \u2026)</p> </li> </ul> </li> </ul> </li> </ul> </li> <li> <p>routing-interface/</p> </li> </ul> </li> <li> <p>whitepaper/</p> </li> <li> <p>test/</p> <ul> <li> <p>docker-env/</p> </li> <li> <p>kubernetes-env/ </p> </li> </ul> </li> </ul>"},{"location":"cactus/contributing/#test-automation","title":"Test Automation","text":"<p>Mantra: Testable code is maintainable code</p>"},{"location":"cactus/contributing/#summary","title":"Summary","text":"<p>We are all about automating the developer flow wherever possible and a big part of this is automated testing of course.</p> <p>Whenever contributing a change it is important to have test coverage for the specific change that you are making. This is especially important for bugs and absolutely essential for security related changes/fixes.</p> <p>Writing testable code is very important to us as not doing so can (and will) snowball into an avalanche of technical debt that will eventually destroy code quality and drive people away who would otherwise be happy to contribute and use the software. So, we want to make sure that does not happen with all this.</p> <p>This also means that occassionally, when making a change that looks simple on the surface you may find that the reviewer of your pull request asks you to do additional, seemingly unrelated changes that have nothing to do with the actual feature/bug that you just implemented/fixed, but instead are designed to ensure that tests can be written for it or for related code.</p> <p>This can feel like a chore (because it is) but we respectfully ask everyone to try their best in accomodating this because it really helps steering the ship on the long run.</p> <p>One of the simplest examples for the above is when you have a class that does something, anything, and it depends on some shared resource to achieve it. The shared resource can be the file system or a network port that is open for TCP connections for example. You can implement your class hardcoding the port number and functionally it will be correct (if you did that part right) BUT if your class does not allow for the customization of said port through the constructor or a setter method, then one of our more obsessive maintainers (like Peter) will immediately be onto you asking for a change so that the port can be customized at runtime, allowing test cases to pass in port 0 that makes the test executable in parallel with other tests without being flaky.</p> <p>If you oppose this idea, said maintainers will happily refer you to this writing or conjure up an entirely new essay right there on the pull request.</p>"},{"location":"cactus/contributing/#test-case-core-principles","title":"Test Case Core Principles","text":"<p>There are other principles specific per unit and integration tests, but the list below applies to all tests regardless of their nature.</p> <p><code>All test cases must be...</code></p> <ul> <li> <p>Self contained programs that can be executed on their own if necessary</p> <ul> <li>This ensures that if you are iterating on a single test case while trying to make it pass, you will always have the freedom to run just that one test instead of running the full suite of which the execution time will grow rapidly as we add test coverage, so, better nip that in the bud with this principle.</li> </ul> </li> <li> <p>Excluded from the public API surface of the package they are in by ensuring that the test classes/types/interfaces are NOT exported through the <code>public-api.ts</code> file of that particular package.</p> <ul> <li>The only exception from this is if a package is itself designed for tests for which a delightful example is the <code>test-tooling</code> package which as the name suggests is entirely designated for providing utilities for writing tests and therefore in the case of this package it is allowed and even expected that it will expose test related classes/types in it\u2019s public API surface. Do note however that indirectly the principle still applies, meaning that any package must not depend on the <code>test-tooling</code> package as an npm <code>dependency</code> but rather it must declare it as a <code>devDependency</code> in the relevant section of the <code>package.json</code> file.</li> </ul> </li> <li> <p>Compatible with the TestAnythingProtocol</p> <ul> <li> <p>The NodeJS implementation of said protocol is in the <code>node-tap</code> npm package:</p> </li> <li> <p>Assertions API of Node TAP</p> </li> <li> <p>Simplest possible test case:</p> <p>const test, { Test } = require(\"tape\"); import * as publicApi from \"../../../main/typescript/public-api\";</p> <p>test(\"Module can be loaded\", (t: Test) =&gt; {    t.ok(publicApi);    t.end(); // yaay, test coverage });</p> </li> <li> <p>An end to end test case showcasing everything in action that is being preached in this document about test automation</p> </li> </ul> </li> <li> <p>Focus/verify a single bug-fix/feature/etc.</p> </li> <li> <p>Clearly separated from non-test (aka <code>main</code>) source code. This means in practice that we ask that your test cases are either in the</p> <ol> <li> <p><code>./src/test/...</code> tree of the package that you are testing OR</p> </li> <li> <p>your test cases are in the <code>./src/test/...</code> tree (yes same name) BUT in an entirely separate package if the dependencies necessitate so. An example to when you would need a separate testing package is if you are developing a ledger plugin that has REST API endpoints shipping with it and you wish to verify in a test that the plugin can be loaded to the <code>ApiServer</code> and then called via the web service/SDK. In this case, you cannot place your test case in the ledger plugin\u2019s package because you want to avoid having to pull in the API server as a dependency of your ledger plugin package (to ensure that there will be no circular dependencies).</p> </li> </ol> </li> <li> <p>Executable with unlimited parallelism (so if I have a 128 test cases and run all of them in parallel on my new 128 CPU core computer, then every single test case runs at the same time)</p> <ul> <li> <p>This is important because it weeds out flakyness and hardcoded references to shared resources (Remember the rant about network ports in the previous section?)</p> </li> <li> <p>BUT it is also very important because we (as in humanity) spent the last decade making the average CPUs ship with more and more cores as increasing frequency failed in the late 2000s as a performance increasing strategy.</p> <p>What this means is that to utilize the average consumer laptop that most people will have for development, you will need your test cases to run in parallel which will save time for everyone working on the code and faster turnaround times make for a better developer experience which makes for a happier community around our open source project. It\u2019s all connected. ;-)</p> </li> </ul> </li> <li> <p>Test cases don\u2019t depend on code outside of the <code>./src/*</code> directory trees of the packages.</p> <ul> <li> <p>Do not depend on any of the example code in your test cases.</p> </li> <li> <p>If you need to import code that is not JS/JSON/TS you can still do so via the Typescript compiler\u2019s relevant feature that allows importing arbitrary files.</p> </li> </ul> </li> </ul>"},{"location":"cactus/contributing/#working-with-the-code","title":"Working with the Code","text":"<p>There are additional details about this in the BUILD.md file in the project root as well.</p> <p>We use Lerna for managing the monorepo that is Cactus.</p> <p>We heavily rely on Docker for testing the ledger plugins.</p>"},{"location":"cactus/contributing/#runningdebugging-the-tests","title":"Running/Debugging the tests","text":"<p>Make sure to have the build succeed prior to attempting to run the tests. If you just checked out the project, it is best to just to just run the CI script which will do a full build and run all tests for you. If it fails you can open a bug in the issue tracker.</p> <p>Assuming you have built the sources, below are the different methods to run the tests:</p>"},{"location":"cactus/contributing/#running-a-single-test-case","title":"Running a single test case","text":"<p>You execute unit and integration tests in the same way, but here are examples for both them separately anyway:</p> <ul> <li> <p>An integration test:</p> <p>yarn jest packages/cactus-test-plugin-consortium-manual/src/test/typescript/integration/plugin-consortium-manual/get-consortium-jws-endpoint.test.ts</p> </li> <li> <p>A unit test:</p> <p>npx jest packages/cactus-common/src/test/typescript/unit/objects/get-all-method-names.test.ts</p> <p>You can also run tests via the VS Code user interface. To do so, make sure you rename <code>template.launch.json</code> to ``launch.json`. Under the \u201cRun and Debug\u201d window of VS Code, select \u201cJEST: Current TS file\u201d to test the currently opened file.</p> </li> </ul>"},{"location":"cactus/contributing/#running-all-test-cases-unitintegration","title":"Running all test cases (unit+integration)","text":"<p>npm run test:all</p>"},{"location":"cactus/contributing/#running-unit-tests-only","title":"Running unit tests only","text":"<p>npm run test:unit</p>"},{"location":"cactus/contributing/#running-integration-tests-only","title":"Running integration tests only","text":"<p>npm run test:integration</p>"},{"location":"cactus/contributing/#what-is-npx-used-for","title":"What is npx used for?","text":"<p><code>npx</code> is a standard top level binary placed on the path by NodeJS at installation time. We use it to avoid having to place every node module (project dependencies) on the OS path or to install them globally (<code>npm install some-pkg -g</code>)</p> <p>Read more about npx here: https://blog.npmjs.org/post/162869356040/introducing-npx-an-npm-package-runner</p>"},{"location":"cactus/contributing/#whats-the-equivalent-of-npx-for-yarn","title":"What\u2019s the equivalent of npx for Yarn?","text":"<p>Yarn itself. E.g. <code>npx lerna clean</code> becomes <code>yarn lerna clean</code>.</p>"},{"location":"cactus/contributing/#debugging-a-test-case","title":"Debugging a test case","text":"<p>Open the <code>.vscode/template.launch.json</code> file and either copy it with a name of <code>launch.json</code> (if you don\u2019t already have such a file) or just cherry pick the example Visual Studio Code debug tasks that you\u2019d like to use. For debugging a single test case, you need the debug task from the template launch.json file that is called <code>TAP: Current TS Test File</code>. Prior to running that debug task you must have your VSCode editor opened to the test file that you wish to run. Breakpoints will work as long as you are debugging code in the same package.</p> <p>Source map support is partial at this point but actively being worked on.</p>"},{"location":"cactus/contributing/#all-in-one-docker-images-for-ledger-connector-plugins","title":"All-In-One Docker Images for Ledger Connector Plugins","text":"<p>If you are working on a new ledger connector you\u2019ll need an <code>all-in-one</code> docker image as well, which will allow the expected level of test automation. If your chosen ledger\u2019s maintainers provide an adequate docker image, then you might not need to develop this yourself, but this is rarely the case so YMMV.</p> <p>To see an existing set of examples for <code>besu</code> and <code>corda</code> images take a peek at the <code>tools/docker/besu-all-in-one</code> and <code>tools/docker/corda-all-in-one</code> folders. These produce the <code>ghcr.io/hyperledger/cactus-besu-all-in-one</code> and <code>ghcr.io/hyperledger/cactus-corda-all-in-one</code> images respectively. Both of these are used in the test cases that are written for the specific ledger connector plugins at:</p> <ul> <li><code>packages/cactus-plugin-ledger-connector-besu/src/test/typescript/integration/plugin-ledger-connector-besu/deploy-contract/deploy-contract-from-json.test.ts</code></li> </ul> <p>The specific classes that utilize the <code>all-in-one</code> images can be found in the <code>test-tooling</code> package under these paths:</p> <ul> <li><code>packages/cactus-test-tooling/src/main/typescript/besu/besu-test-ledger.ts</code></li> </ul>"},{"location":"cactus/contributing/#test-automation-of-ledger-plugins","title":"Test Automation of Ledger Plugins","text":"<p>Ledger plugin tests are written the same way as any other test (which is difficult to achieve, but we thrive to get it done).</p> <p>The only difference between a ledger connector plugin test case and any unit test is that the ledger connector plugin\u2019s test case will pull up a docker container from one of the <code>all-in-one</code> images that we maintain as part of Cactus and then use that <code>all-in-one-*</code> container to verify things such as the ability of the ledger connector plugin to deploy a contract to said ledger.</p> <p>As a generic best practice, the test cases should never re-use any <code>all-in-one</code> ledger container for the execution of multiple test cases because that will almost surely lead to flaky/unstable test cases over the long run and needless complexity, ordering dependencies and so on. It is recommended that if you have two test cases for a ledger connector plugin, they both pull up a newly created container from scratch, execute the test scenario and then tear down and delete the container completely.</p> <p>An example for a ledger connector plugin and it\u2019s test automation implemented the way it is explained above: <code>packages/cactus-test-plugin-ledger-connector-besu/src/test/typescript/integration/grpc-services/connector-besu-grpc-services.test.ts</code></p> <p>This test case is also an example of how to run an ApiServer independently with a single ledger plugin which is how the test case is set up to begin with.</p> <p>Another option if you want to perform some tests manually is to run the API server with a configuration of your choice:</p> <p># Starting from the project root directory</p> <p>chmod +x ./packages/cactus-cmd-api-server/dist/lib/main/typescript/cmd/cactus-api.js</p> <p>./packages/cactus-cmd-api-server/dist/lib/main/typescript/cmd/cactus-api.js --config-file=.config.json</p> <p>You can run this test case the same way you would run any other test case (which is also a requirement in itself for each test case):</p> <pre><code>yarn jest packages/cactus-test-plugin-ledger-connector-besu/src/test/typescript/integration/grpc-services/connector-besu-grpc-services.test.ts\n</code></pre> <p>You can specify an arbitrary set of test cases to run in a single execution via glob patterns. Examples of these glob patterns can be observed in the root directory\u2019s <code>package.json</code> file which has npm scripts for executing all tests with a single command (the CI script uses these):</p>"},{"location":"cactus/contributing/#building-the-api-clients","title":"Building the API Client(S)","text":"<p>You do not need to do anything special to have the API Client sources generated and compiled. It is all part of the <code>npm run build:dev:backend</code> task which you can run yourself or as part of the CI script (<code>./tools/ci.sh</code>).</p> <p>The API client code is automatically generated from the respective <code>openapi.json</code> file of each package that exposes ay web serices (REST/SocketIO/gRPC/etc.) and can be dependend on by other packages where applicable. There\u2019s a dedicated <code>@hyperledger/cactus-api-client</code> package that is meant to contain common functionality among the rest of API clients. The concept here is similar to abstract classes and their sub-class implementations.</p> <p>Each <code>openapi.json</code> produces its own API client via the code generator that also contains relevant model definitions, such as interfaces describing the request/response bodies of all possible operations and validation constraints as well.</p> <p>The API clients are designed to be a universal components, meaning that it runs just fine in browser and also NodeJS environments. This is very important as we do not wish to maintain two (or more) separate API client codebases for the various platforms and we also want as much of it being generated automatically as possible (currently this is close to 100%).</p>"},{"location":"cactus/contributing/#adding-new-dependencies","title":"Adding new dependencies","text":"<p>Example:</p> <p># Adds \"got\" as a dependency to the cactus common package # Note that you must specify the fully qualified package name as present in # the package.json file yarn workspace hyperledger/cactus-common add got --save-exact</p> <p>You need to know which package of the monorepo will be using the package and then run the <code>yarn workspace</code> command with an additional parameters specifying the package name and the dependency name. See Yarn Workspaces Documentation for the official Yarn documentation for further details and examples.</p> <p>After adding new dependencies, you might need to Reload VSCode Window After Adding Dependencies</p> <p>Always specify the <code>--save-exact</code> when installing new dependencies to ensure reproducible builds</p>"},{"location":"cactus/contributing/#reload-vscode-window-after-adding-dependencies","title":"Reload VSCode Window After Adding Dependencies","text":"<p>If you added a new dependency and VSCode is showing an error when you try to import it, then sometimes the issue is just a matter of nudging VSCode to reload the Typescript definitions from scratch so that it \u201cnotices\u201d the new dependency you just added.</p> <p>The recommended way of doing this is by hitting the <code>F1</code> key (or whatever you have bound the command menu to) and then searching and selecting <code>Developer: Reload Window</code> As a simpler alternative you can also just quit and relaunch the VSCode application of course.</p>"},{"location":"cactus/contributing/#on-reproducible-builds","title":"On Reproducible Builds","text":"<p>As a best practice, any given revision (commit hash) stored in version control should produce the exact same build artifacts regardless of when or where the build was performed. This can only be achieved if npm dependency versions are locked down instead of being automatically upgraded by npm (which makes the build time and machine dependent).</p> <p>Bottom line: Do not use the the <code>^</code>, <code>~</code> and <code>*</code> syntax elements while declaring your npm dependencies.</p> <p>Further details:</p> <ul> <li> <p>https://reproducible-builds.org/</p> </li> <li> <p>https://spin.atomicobject.com/2016/12/16/reproducible-builds-npm-yarn/</p> </li> </ul> <p>Previous Next</p>"},{"location":"cactus/examples/","title":"Examples","text":"<p>This section shows the sample applications that are provisioned by the Hyperledger Cactus.</p> <ul> <li>Supply Chain App</li> </ul> <p>Previous Next</p>"},{"location":"cactus/governance/","title":"Governance","text":"<p>Hyperledger Cactus is managed under an open governance model as described in the Hyperledger charter. Cactus is led by a set of maintainers, who can be found in the MAINTAINERS.md file.</p> <p>Maintainers</p> <p>Cactus is led by the project\u2019s maintainers. The maintainers are responsible for reviewing and merging all patches submitted for review, and they guide the overall technical direction of the project within the guidelines established by the Hyperledger Technical Steering Committee (TSC).</p> <p>Becoming a Maintainer</p> <p>The project\u2019s maintainers will, from time-to-time, consider adding or removing a maintainer. An existing maintainer can submit a change set to the MAINTAINERS.md file. A nominated contributor may become a maintainer by a three-quarters approval of the proposal by the existing maintainers. Once approved, the change set is then merged and the individual is added to (or alternatively, removed from) the maintainers group.</p> <p>Maintainers may be removed by explicit resignation, for prolonged inactivity (3 or more months), or for some infraction of the code of conduct or by consistently demonstrating poor judgement. A maintainer removed for inactivity should be restored following a sustained resumption of contributions and reviews (a month or more) demonstrating a renewed commitment to the project. We require that maintainers that will be temporarily inactive do so \u201cgracefully\u201d and update other maintainers on their status and time availability rather than appearing to \u201cfall off the face of the earth.\u201d</p> <p>Releases</p> <p>A majority of the maintainers may decide to create a release of Cactus. Any broader rules of Hyperledger pertaining to releases must be followed. Once the project is mature, there will be a stable LTS (long term support) release branch, as well as the main branch for upcoming new features.</p> <p>Making Feature/Enhancement Proposals</p> <p>Code changes that are either bug fixes, direct and small improvements, or things that are on the roadmap (see below) can be issued as PRs in a relatively quick time period, although we recommend creating a Github ticket to track even bugs and small improvements. For more substantial changes, however, a feature/enhancement proposal is required. These proceed through the approval process like typical PRs, and require the same \u201c2 + 1\u201d approval policy for acceptance.</p> <p>In particular, all contributors to the project should have enough time to voice an opinion on feature/enhancement proposals before they are accepted. So the maintainers will determine some \u201ccomment period\u201d between proposal submission and acceptance so that contributors have enough time to voice their opinions.</p> <p>Significant changes can be marked as such via the predefined label with the same name. This is a tool that helps maintainers identify the most important issues/discussions to be had at any given time through the GitHub web interface.</p> <p>To easily access the list of significant changes, navigate to the label: https://github.com/hyperledger/cactus/labels/Significant_Change</p> <p>We also recommend reading our CONTRIBUTING.md file (https://github.com/hyperledger/cactus/blob/main/CONTRIBUTING.md) for more information about contributing.</p> <p>Approving Pull Requests</p> <p>Maintainers designated for review are required to review PRs in a timely manner (all circumstances considered, of course). Any pull request must be reviewed by at least two maintainers, and if a PR is submitted by a maintainer, these two reviewers must be different from the original submitter.</p> <p>The technical requirements for submitting/approving/merging pull requests are further detailed in the CONTRIBUTING.md file where it is laid out in detail how to ensure git commit graph tidiness.</p> <p>Reviewing Pull Requests</p> <p>We are strongly committed to processing pull requests from everyone in a fair manner meaning that pull requests are to be reviewed in order of submission. Reviewing PRs in order of submission does not guarantee nor necessitate accepting/merging said PRs in order of submission since some PRs may require lengthy feedback loops while others may pass the muster without any change requests or feedback at all, depending on the nature of the change being proposed. Security related pull requests may be fast tracked even against the \u201cin order of submission\u201d principle if it appears that a vulnerability makes a pull request a time sensitive issue where the sooner we propagate a fix the better it is.</p> <p>Maintainers Meeting</p> <p>The maintainers hold regular maintainers meetings, which are open to everyone. The purpose of the maintainers meeting is to plan for and review the progress of releases, and to discuss the technical and operational direction of the project.</p> <p>Please see the wiki for maintainer meeting details.</p> <p>One point to mention about meetings is that new feature/enhancement proposals as described above should be presented to a maintainers meeting for consideration, feedback, and acceptance.</p> <p>Roadmap</p> <p>The Cactus maintainers are required to maintain a roadmap. There is a technical roadmap, with all of the issues as they directly relate to code, and a more public-friendly roadmap that anyone can digest. The required features to be implemented will be maintained as issues at the official github repository of Cactus with tag string \u2018for current release\u2019 or \u2018for future release\u2019. The task which is not volunteered to work, will be dispatched to specific contributors following consensus among the majority of maintainers.</p> <p>The technical roadmap is implicitly derived from the Github \u201cmilestones\u201d feature. To access the list of milestones for Cactus use this link: https://github.com/hyperledger/cactus/milestones</p> <p>Communications</p> <p>We use the Cactus email list for long-form communications and RocketChat for short, informal announcements and other communications. We encourage all communication, whenever possible, to be public and in the clear (i.e. rather than sending an email directly to a person or two, send it out to the whole list if it pertains to the project).</p> <p>Future Changes</p> <p>The governance of Cactus may change as the project evolves. In particular, if the project becomes large, we will incorporate tiered maintainership, with top-level maintainers, subprojects, subproject maintainers, release managers, and so forth. We emphasize that this document is intended to be \u201cliving\u201d and will be updated periodically.</p> <p>We require that changes to this document require a three-quarters approval of the existing maintainers. Note that this may also be changed in the future if deemed necessary.</p> <p>Attribution</p> <p>This document is based on the Hyperledger Fabric governance document, with some substantial changes.</p> <p>Previous Next</p>"},{"location":"cactus/introduction/","title":"Welcome to Hyperledger Cactus documentation!","text":"<p>Hyperledger Cactus aims to provide Decentralized, Secure and Adaptable Integration between Blockchain Networks. Hyperledger Cactus is currently undergoing a major refactoring effort to enable the desired to-be architecture which will enable plug-in based collaborative development to increase the breadth of use cases &amp; Ledgers supported.</p> <p>What is Cactus?</p> <p>A pluggable, enterprise-grade framework to transact on multiple distributed ledgers without introducing yet another competing blockchain.</p> <ul> <li> <p>Cactus allows developers to abstract the application layer from the DLT addressing protocol fragmentation, lowering coupling and reducing implementation risks\u200b</p> </li> <li> <p>Cactus allows different DLT networks to interact with each other, through atomic transactions and state commits, this eliminates information silos and increases network\u2019s value\u200b </p> </li> </ul> <p>Why use Cactus?</p> <ul> <li> <p>Maximize flexibility and future-proofing through plug-in architecture. \u200b</p> </li> <li> <p>Avoid needing explicit action from users to have a secure Cactus deployment. Policies such as vaults are built into the SDK\u200b</p> </li> <li> <p>Keys and other credentials are not stored in source, configuration files, or environment variables\u200b</p> </li> <li> <p>Preserving Ledger Features Horizontal Scalability.\u200b </p> </li> </ul> <p>Next</p>"},{"location":"cactus/packages/","title":"Cactus Components","text":"<p>This section contains the components to form Hyperledger Cactus.</p> <ul> <li>Api Client</li> <li>CMD Api Server</li> <li>Cactus Common</li> <li>Cactus Core</li> <li>Consortium Manual</li> <li>Keychain Vault</li> <li>Connector Besu</li> <li>Connector Corda</li> <li>Connector Fabric</li> <li>Test Api Client</li> <li>Test CMD Api Server</li> <li>Test Tooling</li> </ul> <p>Previous Next</p>"},{"location":"cactus/regulatory-and-industry-initiatives-reading-list/","title":"Regulatory and Industry Initiatives Reading List","text":"<p>A non-exhaustive list of industry standards and regulations/regulatory plans that one could read through if they are trying to get a comprehensive picture of what it takes from the non-technical standpoint to interoperate existing productive systems in finance, trade and more.</p> <p>While these documents are not dealing with technological problems, even just the awareness of their existence could still add tremendous value to someone who is looking to implement some sort of integration/interoperability between different DLTs or a DLT and any pre-existing centralized system.</p>"},{"location":"cactus/regulatory-and-industry-initiatives-reading-list/#mica-european-crypto-assets-regulation-coming-into-force-by-2023","title":"MICA European crypto assets regulation (coming into force by 2023)","text":"<p>https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A52020PC0593</p>"},{"location":"cactus/regulatory-and-industry-initiatives-reading-list/#pilot-regime-for-dlt-market-infrastructure","title":"Pilot Regime for DLT market infrastructure","text":"<p>https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:52020PC0594&amp;from=EN</p>"},{"location":"cactus/regulatory-and-industry-initiatives-reading-list/#paperless-trade-framework-un-unescap-more-on-apac-now-but-supposed-to-expand-in-eu-for-bilateral-cooperation","title":"Paperless trade framework (UN / UNESCAP more on APAC now but supposed to expand in EU) for bilateral cooperation","text":"<p>https://readiness.digitalizetrade.org/</p>"},{"location":"cactus/regulatory-and-industry-initiatives-reading-list/#icc-digital-standard-initiative-private-sector","title":"ICC Digital Standard Initiative (Private sector)","text":"<p>https://iccwbo.org/media-wall/news-speeches/digital-trade-standards-initiative-launches-under-the-umbrella-of-icc/</p>"},{"location":"cactus/regulatory-and-industry-initiatives-reading-list/#baft-digital-ledger-payment-commitment-technical-and-business-best-practices-private-sector-banking-industry","title":"BAFT Digital Ledger Payment Commitment - Technical and Business Best Practices (Private sector - Banking Industry)","text":"<p>https://www.baft.org/wp-content/uploads/2021/03/baft-dlpc-technical-bps-v1-1.pdf</p> <p>https://www.baft.org/wp-content/uploads/2021/03/baft-dlpc-business-bps-v1-1.pdf</p>"},{"location":"cactus/regulatory-and-industry-initiatives-reading-list/#dcsa-digital-container-shipping-association-private-sector-shipping-industry","title":"DCSA Digital Container Shipping Association (Private sector - shipping industry)","text":"<p>https://dcsa.org/dcsa-publishes-standards-for-the-bill-of-lading/</p>"},{"location":"cactus/regulatory-and-industry-initiatives-reading-list/#msb-networked-supervision","title":"MSB Networked Supervision","text":"<p>https://www.occ.gov/news-issuances/news-releases/2021/nr-occ-2021-2.html</p>"},{"location":"cactus/regulatory-and-industry-initiatives-reading-list/#occ-interpretative-letter-on-the-use-of-da-for-payments","title":"OCC Interpretative letter on the use of DA for payments","text":"<p>https://www.occ.gov/news-issuances/news-releases/2021/nr-occ-2021-2a.pdf</p>"},{"location":"cactus/regulatory-and-industry-initiatives-reading-list/#open-digital-asset-protocol-from-ietf-thanks-to-rafael-belchior-for-these","title":"Open Digital Asset Protocol from IETF (Thanks to Rafael Belchior for these)","text":"<p>https://datatracker.ietf.org/doc/draft-hargreaves-odap/ https://datatracker.ietf.org/doc/draft-belchior-gateway-recovery/</p> <p>There are some more standards in section 6.2 of https://deepai.org/publication/a-survey-on-blockchain-interoperability-past-present-and-future-trends</p> <p>Previous Next</p>"},{"location":"cactus/support/","title":"Ledger Support for Connectors","text":"<p>This section contains the ledger supported versions for connectors in Hyperledger Cactus.</p> <ul> <li>Besu</li> <li>Corda</li> <li>Fabric</li> <li>xDai</li> <li>Substrate</li> </ul> <p>Previous Next</p>"},{"location":"cactus/whitepaper/","title":"Hyperledger Cactus White Paper","text":"<p>The white paper is presently undergoing a revision. Please visit the repository for updates.</p> <p>Previous Next</p>"},{"location":"cactus/examples/supply-chain-app/","title":"Example - Supply Chain App","text":""},{"location":"cactus/examples/supply-chain-app/#usage","title":"Usage","text":"<ol> <li> <p>Execute the following from:</p> <p>docker run \\   --rm \\   --privileged \\   -p 3000:3000 \\   -p 3100:3100 \\   -p 3200:3200 \\   -p 4000:4000 \\   -p 4100:4100 \\   -p 4200:4200 \\   ghcr.io/hyperledger/cactus-example-supply-chain-app:2024-03-08--pr-3059-1</p> </li> <li> <p>Observe the example application pulling up in the logs</p> <ol> <li> <p>the test ledger containers,</p> </li> <li> <p>a test consortium with multiple members and their Cactus nodes</p> </li> </ol> </li> <li> <p>Wait for the output to show the message <code>INFO (api-server): Cactus Cockpit reachable http://127.0.0.1:3200</code></p> </li> <li> <p>Visit http://127.0.0.1:3200 in your web browser with Javascript enabled</p> </li> </ol>"},{"location":"cactus/examples/supply-chain-app/#building-and-running-the-container-locally","title":"Building and running the container locally","text":"<p># Change directories to the project root</p> <p># Build the docker image and tag it as \"scaeb\" for supply chain app example backend DOCKER_BUILDKIT=1 docker build -f ./examples/cactus-example-supply-chain-backend/Dockerfile . -t scaeb</p> <p># Run the built image with ports mapped to the host machine as you see fit # The --privileged flag is required because we use Docker-in-Docker for pulling # up ledger containers from within the container in order to have the example # be completely self-contained where you don't need to worry about running # multiple different ledgers jus this one container. docker run --rm -it --privileged -p 3000:3000 -p 3100:3100 -p 3200:3200 -p 4000:4000 -p 4100:4100 -p 4200:4200 scaeb</p> <p>Building the image with a specific npm package version:</p> <p>DOCKER_BUILDKIT=1 docker build \\   --build-arg NPM_PKG_VERSION=jwt-supply-chain \\   --file ./examples/cactus-example-supply-chain-backend/Dockerfile \\   --tag scaeb \\   ./</p>"},{"location":"cactus/examples/supply-chain-app/#running-the-example-application-locally","title":"Running the Example Application Locally","text":"<p>Make sure you have all the dependencies set up as explained in <code>BUILD.md</code></p> <p>On the terminal, issue the following commands:</p> <ol> <li> <p><code>npm run enable-corepack</code></p> </li> <li> <p><code>yarn run configure</code></p> </li> <li> <p><code>yarn start:example-supply-chain</code></p> </li> </ol>"},{"location":"cactus/examples/supply-chain-app/#debugging-the-example-application-locally","title":"Debugging the Example Application Locally","text":"<p>On the terminal, issue the following commands (steps 1 to 6) and then perform the rest of the steps manually.</p> <ol> <li> <p><code>npm run enable-corepack</code></p> </li> <li> <p><code>yarn configure</code></p> </li> <li> <p><code>yarn build:dev</code></p> </li> <li> <p>Locate the <code>.vscode/template.launch.json</code> file</p> </li> <li> <p>Within that file locate the entry named <code>\"Example: Supply Chain App\"</code></p> </li> <li> <p>Copy the VSCode debug definition object from 2) to your <code>.vscode/launch.json</code> file</p> </li> <li> <p>At this point the VSCode <code>Run and Debug</code> panel on the left should have an option also titled <code>\"Example: Supply Chain App\"</code> which starts the application</p> </li> <li> <p>When the application finishes loading, the JWT token generated is displayed on the terminal</p> </li> <li> <p>Visit http://localhost:3200 in a web browser with Javascript enabled and insert the token when prompted</p> </li> </ol>"},{"location":"cactus/examples/supply-chain-app/#live-reloading-the-gui-application","title":"Live Reloading the GUI Application","text":"<ol> <li> <p><code>npm run enable-corepack</code></p> </li> <li> <p><code>yarn configure</code></p> </li> <li> <p><code>yarn build:dev</code></p> </li> <li> <p>Locate the <code>.vscode/template.launch.json</code> file</p> </li> <li> <p>Within that file locate the entry named <code>\"Example: Supply Chain App\"</code></p> </li> <li> <p>Copy the VSCode debug definition object from 2) to your <code>.vscode/launch.json</code> file</p> </li> <li> <p>At this point the VSCode <code>Run and Debug</code> panel on the left should have an option also titled <code>\"Example: Supply Chain App\"</code> which starts the application</p> </li> <li> <p><code>cd ./examples/cactus-example-supply-chain-frontend/</code></p> </li> <li> <p><code>yarn serve:proxy</code></p> </li> <li> <p>When the application finishes loading, the JWT token generated is displayed on the terminal</p> </li> <li> <p>Visit http://localhost:8000 in a web browser with Javascript enabled and insert the token when prompted</p> </li> <li> <p>At this point if you modify the source code of the GUI application under the <code>./examples/cactus-example-supply-chain-frontend/</code> path it will automatically reload the browser window (you will need to paste in the JWT again when this happens)</p> </li> </ol> <p>Previous Next</p>"},{"location":"cactus/packages/cactus-api-client/","title":"<code>@hyperledger/cactus-api-client</code>","text":""},{"location":"cactus/packages/cactus-api-client/#summary","title":"Summary","text":"<p>The Hyperledger Cactus API Client package is designed to be a generic extension with convenience features wrapped around the [typescript-axios flavored API clients](https://github.com/OpenAPITools/openapi-generator/blob/v5.2.1/docs/generators/typescript-axios.md) that we auto-generate and ship with each web service-enabled plugin such as the API clients of the</p> <ul> <li> <p>Manual Consortium Plugin Typescript Axios API Client</p> </li> <li> <p>Besu Connector Typescript Axios API Client</p> </li> <li> <p>Corda Connector Typescript Axios API Client</p> </li> <li> <p>Fabric Connector Typescript Axios API Client</p> </li> <li> <p>API Server Typescript Axios API Client</p> </li> <li> <p>Vault Keychain Plugin Typescript Axios API Client</p> </li> </ul> <p>The code generation for the listed code folders above is done by the OpenAPI Generator tool that can convert OpenAPI V3 json specifications of ours straight into the program code of the API clients.</p> <p>The above means that the <code>ApiClient</code> class is not the one containing the implementation responsible for executing all the supported API calls by a Cactus node (which would make it a monolith, something that we try to avoid as it is the opposite of a flexible plugin architecture)</p> <p>For example you can use the <code>@hyperledger/cactus-api-client</code> node package to perform Cactus node discovery based on ledger IDs (that can be obtained from the <code>ConsortiumDatabase</code> as defined by the generated models of the <code>@hyperledger/cactus-core-api</code> package.</p> <p>While you can generate API Clients for the Cactus API specifications in any supported language of the OpenAPI Generator the features provided by this package will have to be developed separately (if not already done by the Cactus maintainers). Currently the only implementation of the abstract API Client and its features (node discovery) is in Typescript (e.g. the <code>@hyperledger/cactus-api-client</code> package).</p>"},{"location":"cactus/packages/cactus-api-client/#usage","title":"Usage","text":""},{"location":"cactus/packages/cactus-api-client/#routing-to-cactus-node-with-connector-to-specific-ledger","title":"Routing to Cactus Node with connector to specific ledger","text":"<p>Let\u2019s say you have a consortium with several members who all have their own ledgers deployed as well. The <code>ConsortiumDatabase</code> will therefore contain the entities pertaining to these entities (such as the ledgers or the members themselves) meaning that if you are developing an application that needs to perform operations on one of the ledgers in the consortium then you have a couple of different ways of obtaining an API client to do just that:</p>"},{"location":"cactus/packages/cactus-api-client/#leverage-the-consortiumdatabase-for-discovery","title":"Leverage the <code>ConsortiumDatabase</code> for discovery","text":"<p>import { ApiClient } from \"hyperledger/cactus-api-client\";</p> <p>import { ConsortiumDatabase, Ledger, LedgerType } from \"hyperledger/cactus-core-api\";</p> <p>import { PluginRegistry } from \"hyperledger/cactus-core\";</p> <p>import { DefaultApi as BesuApi } from \"hyperledger/cactus-plugin-ledger-connector-besu\";</p> <p>const mainFn = async () =&gt; {   const ledgerId = \"theIdOfYourLedgerInTheConsortiumDatabase\";</p> <p>// How you obtain a consortium provider is dependent on which consortium   // plugin you use and your exact deployment scenario   const consortiumProvider: IAsyncProvider&lt;ConsortiumDatabase&gt; = ...;   const consortiumDatabase: ConsortiumDatabase = await consortiumProvider.get();   const consortium = consortiumDatabase.consortium[0];</p> <p>const mainApiClient = new ApiClient({ basePath: consortium.mainApiHost });</p> <p>// This client is now configured to point to a node that has a connector to   // the ledger referenced by `ledgerId`   const apiClient = await mainApiClient.ofLedger(ledgerId, BesuApi);</p> <p>// Use the client to perform any supported operation on the ledger };</p> <p>mainFn();</p>"},{"location":"cactus/packages/cactus-api-client/#use-a-provided-mainapihost-and-ledgerid","title":"Use a provided <code>mainApiHost</code> and <code>ledgerId</code>","text":"<p>import { ApiClient } from \"hyperledger/cactus-api-client\";</p> <p>import { ConsortiumDatabase, Ledger, LedgerType } from \"hyperledger/cactus-core-api\";</p> <p>import { PluginRegistry } from \"hyperledger/cactus-core\";</p> <p>import { DefaultApi as BesuApi } from \"hyperledger/cactus-plugin-ledger-connector-besu\";</p> <p>const mainFn = async () =&gt; {   const ledgerId = \"theIdOfYourLedgerInTheConsortiumDatabase\";   const consortiumMainApiHost = \"https://cactus.example.com\";</p> <p>const mainApiClient = new ApiClient({ basePath: consortiumMainApiHost });</p> <p>// This client is now configured to point to a node that has a connector to   // the ledger referenced by `ledgerId`   const apiClient = await mainApiClient.ofLedger(ledgerId, BesuApi); }</p> <p>mainFn();</p>"},{"location":"cactus/packages/cactus-api-client/#use-the-api-host-of-a-node-directly","title":"Use the API host of a node directly","text":"<p>import { ApiClient } from \"hyperledger/cactus-api-client\";</p> <p>import { ConsortiumDatabase, Ledger, LedgerType } from \"hyperledger/cactus-core-api\";</p> <p>import { PluginRegistry } from \"hyperledger/cactus-core\";</p> <p>import { DefaultApi as BesuApi } from \"hyperledger/cactus-plugin-ledger-connector-besu\";</p> <p>const mainFn = async () =&gt; {   const nodeApiHost = \"https://my-node.cactus.example.com\";</p> <p>const mainApiClient = new ApiClient({ basePath: nodeApiHost });</p> <p>// This client is now configured to point to a node that has a connector to the ledger of your choice   const apiClient = await mainApiClient.extendWith(BesuApi); }</p> <p>mainFn();</p>"},{"location":"cactus/packages/cactus-api-client/#public-api-surface","title":"Public API Surface","text":""},{"location":"cactus/packages/cactus-api-client/#defaultconsortiumprovider","title":"<code>DefaultConsortiumProvider</code>","text":"<p>Builds the default Consortium provider that can be used by this object to retrieve the Cactus Consortium metadata object when necessary (one such case is when we need information about the consortium nodes to perform routing requests to a specific ledger via a connector plugin, but later other uses could be added as well).</p> <p>The DefaultConsortiumProvider class leverages the simplest consortium plugin that we have at the time of this writing: hyperledger/cactus-plugin-consortium-manual which holds the consortium metadata as pre-configured by the consortium operators.</p> <p>The pattern we use in the ApiClient class is that you can inject your own <code>IAsyncProvider&lt;Consortium&gt;</code> implementation which then will be used for routing information and in theory you can implement completely arbitrary consortium management in your own consortium plugins which then Cactus can use and leverage for the routing. This allows us to support any exotic consortium management algorithms that people may come up with such as storing the consortium definition in a multi-sig smart contract or have the list of consortium nodes be powered by some sort of automatic service discovery or anything else that people might think of.</p>"},{"location":"cactus/packages/cactus-api-client/#apiclient","title":"<code>ApiClient</code>","text":"<p>Class responsible for providing additional functionality to the DefaultApi classes of the generated clients (OpenAPI generator / typescript-axios).</p> <p>Each package (plugin) can define it\u2019s own OpenAPI spec which means that they all can ship with their own <code>DefaultApi</code> class that is generated directly from the respective OpenAPI spec of the package/plugin.</p> <p>The functionality provided by this class is meant to be common traints that can be useful for all of those different <code>DefaultApi</code> implementations.</p> <p>One such common trait is the client side component of the routing that decides which Cactus node to point the <code>ApiClient</code> towards (which is in itself ends up being the act of routing).</p> <p>@see \u2014 https ://github.com/OpenAPITools/openapi-generator/blob/v5.0.0-beta2/modules/openapi-generator/src/main/resources/typescript-axios/apiInner.mustache#L337</p> <p>@see \u2014 https ://github.com/OpenAPITools/openapi-generator/blob/v5.0.0/docs/generators/typescript-axios.md</p> <p>Previous Next</p>"},{"location":"cactus/packages/cactus-cmd-api-server/","title":"<code>@hyperledger/cactus-cmd-api-server</code>","text":"<ul> <li> <p>Summary</p> </li> <li> <p>Usage</p> <ul> <li> <p>Basic Example</p> </li> <li> <p>Remote Plugin Imports at Runtime Example</p> </li> <li> <p>Complete Example</p> </li> </ul> </li> <li> <p>Deployment Scenarios</p> <ul> <li> <p>Production Deployment Example</p> </li> <li> <p>Low Resource Deployment Example</p> </li> </ul> </li> <li> <p>Containerization</p> <ul> <li> <p>Building the container image locally</p> </li> <li> <p>Running the container image locally</p> </li> <li> <p>Testing API calls with the container</p> </li> </ul> </li> <li> <p>Prometheus Exporter</p> <ul> <li> <p>Usage Prometheus</p> </li> <li> <p>Prometheus Integration</p> </li> <li> <p>Shutdown Hook</p> </li> <li> <p>Helper code - response.type.ts - data-fetcher.ts - metrics.ts</p> </li> </ul> </li> <li> <p>FAQ</p> <ul> <li> <p>What is the difference between a Cactus Node and a Cactus API Server?</p> </li> <li> <p>Is the API server horizontally scalable?</p> </li> <li> <p>Does the API server automatically protect me from malicious plugins?</p> </li> <li> <p>Can I use the API server with plugins deployed as a service?</p> </li> </ul> </li> </ul>"},{"location":"cactus/packages/cactus-cmd-api-server/#summary","title":"Summary","text":"<p>This package is part of the Hyperledger Cactus blockchain integration framework and is used as a shell/container of sort for housing different Cactus plugins (which all live in their own npm packages as well).</p> <p>The API server gives you for free the following benefits, should you choose to use it:</p> <ol> <li> <p>Automatic wiring of API endpoints for Cactus plugins which implement the <code>IPluginWebService</code> Typescript interface</p> </li> <li> <p>Lightweight inversion of control container provided to plugins in the form of the <code>PluginRegistry</code> so that plugins can depend on each other in a way that each plugin instance can be uniquely identified and obtained by other plugins. A great example of this in action is ledger connector plugins frequently using the <code>PluginRegistry</code> to look up instances of keychain plugins to get access to secrets that are needed for the connector plugins to accomplish certain tasks such as cryptographically signing some information or SSH-ing into a server instance in order to upload and deploy binary (or otherwise) artifacts of smart contracts.</p> </li> </ol>"},{"location":"cactus/packages/cactus-cmd-api-server/#usage","title":"Usage","text":"<p>Like with most parts of the framework in Cactus, using the <code>ApiServer</code> is optional.</p> <p>To see the <code>ApiServer</code> in action, the end to end tests of the framework are a great place to start. A few excerpts that regularly occur in said tests can be seen below as well for the reader\u2019s convenience.</p> <p>One of our design principles for the framework is secure by default which means that the API servers</p> <ol> <li> <p>assumes TLS is enabled by default and</p> </li> <li> <p>cross-origin resource sharing is disabled completely</p> </li> </ol>"},{"location":"cactus/packages/cactus-cmd-api-server/#basic-example","title":"Basic Example","text":"<pre><code>#!/usr/bin/env node\n\nimport { ApiServer } from \"../api-server\";\nimport { ConfigService } from \"../config/config-service\";\nimport { Logger, LoggerProvider } from \"@hyperledger/cactus-common\";\n\nconst log: Logger \\= LoggerProvider.getOrCreate({\n  label: \"cactus-api\",\n  level: \"INFO\",\n});\n\nconst main \\= async () \\=&gt; {\n  const configService \\= new ConfigService();\n  const config \\= await configService.getOrCreate();\n  const serverOptions \\= config.getProperties();\n\n  LoggerProvider.setLogLevel(serverOptions.logLevel);\n\n  if (process.argv\\[2\\].includes(\"help\")) {\n    const helpText \\= ConfigService.getHelpText();\n    console.log(helpText);\n    log.info(\\`Effective Configuration:\\`);\n    log.info(JSON.stringify(serverOptions, null, 4));\n  } else {\n    const apiServer \\= new ApiServer({ config: serverOptions });\n    await apiServer.start();\n  }\n};\n\nexport async function launchApp(): Promise&lt;void\\&gt; {\n  try {\n    await main();\n    log.info(\\`Cactus API server launched OK \\`);\n  } catch (ex) {\n    log.error(\\`Cactus API server crashed: \\`, ex);\n    process.exit(1);\n  }\n}\n\nif (require.main \\=== module) {\n  launchApp();\n}\n</code></pre>"},{"location":"cactus/packages/cactus-cmd-api-server/#remote-plugin-imports-at-runtime-example","title":"Remote Plugin Imports at Runtime Example","text":"<pre><code>import { PluginImportType, PluginImportAction } from \"@hyperledger/cactus-core-api\";\nimport { ApiServer } from \"@hyperledger/cactus-cmd-api-server\";\nimport { ConfigService } from \"@hyperledger/cactus-cmd-api-server\";\nimport { Logger, LoggerProvider } from \"@hyperledger/cactus-common\";\n\nconst main \\= async () \\=&gt; {\n\n  const configService \\= new ConfigService();\n  const apiServerOptions \\= await configService.newExampleConfig();\n  // If there is no configuration file on the file system, just set it to empty string\n  apiServerOptions.configFile \\= \"\";\n  // Enable CORS for\n  apiServerOptions.apiCorsDomainCsv \\= \"your.domain.example.com\";\n  apiServerOptions.apiPort \\= 3000;\n  apiServerOptions.cockpitPort \\= 3100;\n  apiServerOptions.grpcPort \\= 5000;\n  // Disble TLS (or provide TLS certs for secure HTTP if you are deploying to production)\n  apiServerOptions.apiTlsEnabled \\= false;\n  apiServerOptions.plugins \\= \\[\n    {\n      // npm package name of the plugin you are installing\n      // Since this will be imported at runtime, you are responsible for\n      // installing the package yourself prior to launching the API server.\n      packageName: \"@hyperledger/cactus-plugin-keychain-vault\",\n      // The REMOTE value means that a different plugin factory will be imported and\n      // called to obtain the plugin instance. This way plugins can support them\n      // being imported by the API server regardless of the language the plugin\n      // was written in.\n      type: PluginImportType.REMOTE,\n      // The INSTALL value means that the plugin will be installed instead of\n      // only instantiate it\n      action: PluginImportAction.INSTALL,\n      // The options that will be passed in to the plugin factory\n      options: {\n        keychainId: \"\\_keychainId\\_\",\n        instanceId: \"\\_instanceId\\_\",\n        remoteConfig: configuration,\n      },\n    },\n  \\];\n  const config \\= await configService.newExampleConfigConvict(apiServerOptions);\n\n  const apiServer \\= new ApiServer({\n    config: config.getProperties(),\n  });\n\n  // start the API server here and you are ready to roll\n};\n\nexport async function launchApp(): Promise&lt;void\\&gt; {\n  try {\n    await main();\n    log.info(\\`Cactus API server launched OK \\`);\n  } catch (ex) {\n    log.error(\\`Cactus API server crashed: \\`, ex);\n    process.exit(1);\n  }\n}\n\nif (require.main \\=== module) {\n  launchApp();\n}\n</code></pre>"},{"location":"cactus/packages/cactus-cmd-api-server/#complete-example","title":"Complete Example","text":"<p>For a complete example of how to use the API server, read all the code of the supply chain example\u2019s backend package:</p> <p>https://github.com/hyperledger/cactus/tree/main/examples/cactus-example-supply-chain-backend/src/main/typescript</p>"},{"location":"cactus/packages/cactus-cmd-api-server/#deployment-scenarios","title":"Deployment Scenarios","text":"<p>There\u2019s a set of building blocks (members, nodes, API server processes, plugin instances) that you can use when defining (founding) a consortium and these building blocks relate to each other in a way that can be expressed with an entity relationship diagram which can be seen below. The composability rules can be deducted from how the diagram elements (entities) are connected (related) to each other, e.g. the API server process can have any number of plugin instances in it and a node can contain any number of API server processes, and so on until the top level construct is reached: the consortium.</p> <p>Consortium management does not relate to achieving consensus on data/transactions involving individual ledgers, merely about consensus on the metadata of a consortium.</p> <p></p> <p>Now, with these composability rules in mind, let us demonstrate a few different deployment scenarios (both expected and exotic ones) to showcase the framework\u2019s flexibility in this regard.</p>"},{"location":"cactus/packages/cactus-cmd-api-server/#production-deployment-example","title":"Production Deployment Example","text":"<p>Many different configurations are possible here as well. One way to have two members form a consortium and both of those members provide highly available, high throughput services is to have a deployment as shown on the below figure. What is important to note here is that this consortium has 2 nodes, 1 for each member and it is irrelevant how many API servers those nodes have internally because they all respond to requests through the network host/web domain that is tied to the node. One could say that API servers do not have a distinguishable identity relative to their peer API servers, only the higher-level nodes do.</p> <p></p>"},{"location":"cactus/packages/cactus-cmd-api-server/#low-resource-deployment-example","title":"Low Resource Deployment Example","text":"<p>This is an example to showcase how you can pull up a full consortium even from within a single operating system process (API server) with multiple members and their respective nodes. It is not something that\u2019s recommended for a production grade environment, ever, but it is great for demos and integration tests where you have to simulate a fully functioning consortium with as little hardware footprint as possible to save on time and cost.</p> <p>The individual nodes/API servers are isolated by listening on separate TCP ports of the machine they are hosted on:</p> <p></p>"},{"location":"cactus/packages/cactus-cmd-api-server/#containerization","title":"Containerization","text":""},{"location":"cactus/packages/cactus-cmd-api-server/#building-the-container-image-locally","title":"Building the container image locally","text":"<p>In the Cactus project root say:</p> <p>DOCKER_BUILDKIT=1 docker build -f ./packages/cactus-cmd-api-server/Dockerfile . -t cas -t cactus-api-server</p> <p>Build with a specific version of the npm package:</p> <p>DOCKER_BUILDKIT=1 docker build --build-arg NPM_PKG_VERSION=main -f ./packages/cactus-cmd-api-server/Dockerfile . -t cas -t cactus-api-server</p>"},{"location":"cactus/packages/cactus-cmd-api-server/#running-the-container-image-locally","title":"Running the container image locally","text":"<p>Before running the examples here you need to build the image locally. See section Building the container image locally for details on how to do that.</p> <p>Once you\u2019ve built the container, the following commands should work:</p> <ul> <li> <p>Launch container - no plugins, default configuration</p> <p>docker run \\   --rm \\   --publish 3000:3000 \\   --publish 4000:4000 \\   --env AUTHORIZATION_PROTOCOL='NONE' \\   --env AUTHORIZATION_CONFIG_JSON='{}' \\   --env GRPC_TLS_ENABLED=false \\   cas</p> </li> <li> <p>Launch container with plugins of your choice (keychain, consortium connector, etc.)</p> <p>docker run \\   --rm \\   --publish 3000:3000 \\   --publish 4000:4000 \\   --env AUTHORIZATION_PROTOCOL='NONE' \\   --env AUTHORIZATION_CONFIG_JSON='{}' \\   --env GRPC_TLS_ENABLED=false \\   cas \\     ./node_modules/.bin/cactusapi \\     --plugins='[{\"packageName\": \"hyperledger/cactus-plugin-ledger-connector-fabric\", \"type\": \"org.hyperledger.cactus.plugin_import_type.LOCAL\", \"action\": \"org.hyperledger.cactus.plugin_import_action.INSTALL\",  \"options\": { \"connectionProfile\": {}, \"instanceId\": \"some-unique-instance-id\"}}]'</p> </li> <li> <p>Launch container with plugin configuration as an environment variable:</p> <p>docker run \\   --rm \\   --publish 3000:3000 \\   --publish 4000:4000 \\   --env AUTHORIZATION_PROTOCOL='NONE' \\   --env AUTHORIZATION_CONFIG_JSON='{}' \\   --env GRPC_TLS_ENABLED=false \\   --env PLUGINS='[{\"packageName\": \"hyperledger/cactus-plugin-ledger-connector-besu\", \"type\": \"org.hyperledger.cactus.plugin_import_type.LOCAL\", \"action\": \"org.hyperledger.cactus.plugin_import_action.INSTALL\",  \"options\": {\"rpcApiHttpHost\": \"http://localhost:8545\", \"instanceId\": \"some-unique-besu-connector-instance-id\"}}]' \\   cas</p> </li> <li> <p>Launch container with plugin configuration as a CLI argument:</p> <p>docker run \\   --rm \\   --publish 3000:3000 \\   --publish 4000:4000 \\   --env AUTHORIZATION_PROTOCOL='NONE' \\   --env AUTHORIZATION_CONFIG_JSON='{}' \\   --env GRPC_TLS_ENABLED=false \\   cas \\     ./node_modules/.bin/cactusapi \\     --plugins='[{\"packageName\": \"hyperledger/cactus-plugin-ledger-connector-besu\", \"type\": \"org.hyperledger.cactus.plugin_import_type.LOCAL\", \"action\": \"org.hyperledger.cactus.plugin_import_action.INSTALL\",  \"options\": {\"rpcApiHttpHost\": \"http://localhost:8545\", \"instanceId\": \"some-unique-besu-connector-instance-id\"}}]'</p> </li> <li> <p>Launch container with configuration file mounted from host machine:</p> <p>echo '[{\"packageName\": \"hyperledger/cactus-plugin-ledger-connector-besu\", \"type\": \"org.hyperledger.cactus.plugin_import_type.LOCAL\", \"action\": \"org.hyperledger.cactus.plugin_import_action.INSTALL\",  \"options\": {\"rpcApiHttpHost\": \"http://localhost:8545\", \"instanceId\": \"some-unique-besu-connector-instance-id\"}}]' &gt; cactus.json</p> <p>docker run \\   --rm \\   --publish 3000:3000 \\   --publish 4000:4000 \\   --env AUTHORIZATION_PROTOCOL='NONE' \\   --env AUTHORIZATION_CONFIG_JSON='{}' \\   --env GRPC_TLS_ENABLED=false \\   --mount type=bind,source=\"$(pwd)\"/cactus.json,target=/cactus.json \\   cas \\     ./node_modules/.bin/cactusapi \\     --config-file=/cactus.json</p> </li> </ul>"},{"location":"cactus/packages/cactus-cmd-api-server/#testing-api-calls-with-the-container","title":"Testing API calls with the container","text":"<p>Don\u2019t have a Besu network on hand to test with? Test or develop against our Besu All-In-One container!</p> <ol> <li> <p>Terminal Window 1 (Ledger)</p> <p>docker run --publish 8545:8545 hyperledger/cactus-besu-all-in-one:latest</p> </li> <li> <p>Terminal Window 2 (Cactus API Server)</p> <p>docker run \\   --network host \\   --rm \\   --publish 3000:3000 \\   --publish 4000:4000 \\   --env AUTHORIZATION_PROTOCOL='NONE' \\   --env AUTHORIZATION_CONFIG_JSON='{}' \\   --env GRPC_TLS_ENABLED=false \\   --env PLUGINS='[{\"packageName\": \"hyperledger/cactus-plugin-ledger-connector-besu\", \"type\": \"org.hyperledger.cactus.plugin_import_type.LOCAL\", \"action\": \"org.hyperledger.cactus.plugin_import_action.INSTALL\",  \"options\": {\"rpcApiHttpHost\": \"http://localhost:8545\", \"instanceId\": \"some-unique-besu-connector-instance-id\"}}]' \\   cas</p> </li> <li> <p>Terminal Window 3 (curl - replace eth accounts as needed)</p> <p>curl --location --request POST 'http://127.0.0.1:4000/api/v1/plugins/@hyperledger/cactus-plugin-ledger-connector-besu/run-transaction' \\ --header 'Content-Type: application/json' \\ --data-raw '{     \"web3SigningCredential\": {       \"ethAccount\": \"627306090abaB3A6e1400e9345bC60c78a8BEf57\",       \"secret\": \"c87509a1c067bbde78beb793e6fa76530b6382a4c0241e5e4a9ec0a0f44dc0d3\",       \"type\": \"PRIVATE_KEY_HEX\"     },     \"consistencyStrategy\": {       \"blockConfirmations\": 0,       \"receiptType\": \"NODE_TX_POOL_ACK\"     },     \"transactionConfig\": {       \"from\": \"627306090abaB3A6e1400e9345bC60c78a8BEf57\",       \"to\": \"f17f52151EbEF6C7334FAD080c5704D77216b732\",       \"value\": 1,       \"gas\": 10000000     } }'</p> </li> <li> <p>The above should produce a response that looks similar to this:</p> <p>{     \"success\": true,     \"data\": {         \"transactionReceipt\": {             \"blockHash\": \"0x7c97c038a5d3bd84613fe23ed442695276d5d2df97f4e7c4f10ca06765033ffd\",             \"blockNumber\": 1218,             \"contractAddress\": null,             \"cumulativeGasUsed\": 21000,             \"from\": \"0x627306090abab3a6e1400e9345bc60c78a8bef57\",             \"gasUsed\": 21000,             \"logs\": [],             \"logsBloom\": \"0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\",             \"status\": true,             \"to\": \"0xf17f52151ebef6c7334fad080c5704d77216b732\",             \"transactionHash\": \"0xc7fcb46c735bdc696d500bfc70c72595a2b8c31813929e5c61d9a5aec3376d6f\",             \"transactionIndex\": 0         }     } }</p> </li> </ol>"},{"location":"cactus/packages/cactus-cmd-api-server/#prometheus-exporter","title":"Prometheus Exporter","text":"<p>This class creates a prometheus exporter, which scrapes the total Cactus node count.</p>"},{"location":"cactus/packages/cactus-cmd-api-server/#usage-prometheus","title":"Usage Prometheus","text":"<p>The prometheus exporter object is initialized in the <code>ApiServer</code> class constructor itself, so instantiating the object of the <code>ApiServer</code> class, gives access to the exporter object. You can also initialize the prometheus exporter object separately and then pass it to the <code>IApiServerConstructorOptions</code> interface for <code>ApiServer</code> constructor.</p> <p><code>getPrometheusMetricsV1</code> function returns the prometheus exporter metrics, currently displaying the total plugins imported, which currently refreshes to match the plugin count, everytime <code>setTotalPluginImports</code> method is called.</p>"},{"location":"cactus/packages/cactus-cmd-api-server/#prometheus-integration","title":"Prometheus Integration","text":"<p>To use Prometheus with this exporter make sure to install Prometheus main component. Once Prometheus is setup, the corresponding scrape_config needs to be added to the prometheus.yml</p> <p>- job_name: 'consortium_manual_exporter'   metrics_path: /api/v1/api-server/get-prometheus-exporter-metrics   scrape_interval: 5s   static_configs:     - targets: ['{host}:{port}']</p> <p>Here the <code>host:port</code> is where the prometheus exporter metrics are exposed. The test cases (For example, packages/cactus-plugin-consortium-manual/src/test/typescript/unit/consortium/get-node-jws-endpoint-v1.test.ts) exposes it over <code>0.0.0.0</code> and a random port(). The random port can be found in the running logs of the test case and looks like (42379 in the below mentioned URL) <code>Metrics URL: http://0.0.0.0:42379/api/v1/api-server/get-prometheus-exporter-metrics/get-prometheus-exporter-metrics</code></p> <p>Once edited, you can start the prometheus service by referencing the above edited prometheus.yml file. On the prometheus graphical interface (defaulted to http://localhost:9090), choose Graph from the menu bar, then select the Console tab. From the Insert metric at cursor drop down, select cactus_api_server_total_plugin_imports and click execute</p>"},{"location":"cactus/packages/cactus-cmd-api-server/#shutdown-hook","title":"Shutdown Hook","text":"<p>The API config contains a flag:</p> <pre><code>{\n  \"enableShutdownHook\": true\n}\n</code></pre> <p>This allows for graceful shutdown of the API server after a SIGINT via cli CTRL + C. This hook can be disabled by passing in false either via the TypeScript constructor or the JSON config file.</p>"},{"location":"cactus/packages/cactus-cmd-api-server/#helper-code","title":"Helper code","text":""},{"location":"cactus/packages/cactus-cmd-api-server/#responsetypets","title":"response.type.ts","text":"<p>This file contains the various responses of the metrics.</p>"},{"location":"cactus/packages/cactus-cmd-api-server/#data-fetcherts","title":"data-fetcher.ts","text":"<p>This file contains functions encasing the logic to process the data points.</p>"},{"location":"cactus/packages/cactus-cmd-api-server/#metricsts","title":"metrics.ts","text":"<p>This file lists all the prometheus metrics and what they are used for.</p>"},{"location":"cactus/packages/cactus-cmd-api-server/#faq","title":"FAQ","text":""},{"location":"cactus/packages/cactus-cmd-api-server/#what-is-the-difference-between-a-cactus-node-and-a-cactus-api-server","title":"What is the difference between a Cactus Node and a Cactus API Server?","text":"<p>The node is what has an identity within your PKI and can be made up of 1-N API server instances that all share the same configuration/identity of the node. See deployment scenarios above for a much more detailed explanation.</p>"},{"location":"cactus/packages/cactus-cmd-api-server/#is-the-api-server-horizontally-scalable","title":"Is the API server horizontally scalable?","text":"<p>Yes, 100%. Keep in mind though that the API server can be loaded up with arbitrary plugins meaning that if you write a plugin that has a central database that can only do 1 transaction per second, then it will not help you much that the API server itself is horizontally scalable because deploying a thousand instances of the API server will just result in you having a thousand instances of your plugin all waiting for that underlying database with its 1 TPS throughput hogging your system. When we say that the API server is horizontally scalable, we mean that the API server itself is designed not to have any such state mentioned in the example above. You are responsible for only deploying plugins in the API server that are horizontally scalable as well. In short, your whole system is only horizontally scalable if all components of it are horizontally scalable.</p>"},{"location":"cactus/packages/cactus-cmd-api-server/#does-the-api-server-automatically-protect-me-from-malicious-plugins","title":"Does the API server automatically protect me from malicious plugins?","text":"<p>No. If you install a third-party plugin that wasn\u2019t vetted by anyone and that plugin happens to have malicious code in it to steal your private keys, it can do so. You are responsible for making sure that the plugins you install have no known security vulnerabilities or backdoors e.g. they are considered \u201csecure\u201d. The double quotes around \u201csecure\u201d is meant to signify the fact that no software is ever really truly secure, just merely lacking of known vulnerabilities at any given point in time.</p>"},{"location":"cactus/packages/cactus-cmd-api-server/#can-i-use-the-api-server-with-plugins-deployed-as-a-service","title":"Can I use the API server with plugins deployed as a service?","text":"<p>Yes. You can deploy your plugin written in any language, anywhere as long as it is accessible over the network and does come with a Typescript API client that you can use to install into the API server as a proxy for an in-process plugin implementation.</p> <p>Previous Next</p>"},{"location":"cactus/packages/cactus-common/","title":"<code>@hyperledger/cactus-common</code>","text":"<p>TODO: description</p>"},{"location":"cactus/packages/cactus-common/#usage","title":"Usage","text":"<p>// TODO: DEMONSTRATE API</p> <p>Previous Next</p>"},{"location":"cactus/packages/cactus-core/","title":"<code>@hyperledger/cactus-core</code>","text":"<p>This module is responsible for providing the backbone for the rest of the packages when it comes to the features of Cactus.</p> <p>The main difference between this and the <code>cactus-common</code> package is that this one does not guarantee it\u2019s features to work in the browser.</p> <p>The main difference from the <code>cactus-core-api</code> package is that this is meant to contain actual implementations while <code>cactus-core-api</code> is meant to be strictly about defining interfaces. Based on that latter constraint we may move the <code>PluginRegistry</code> out of that package and into this one in the near future.</p>"},{"location":"cactus/packages/cactus-core/#usage","title":"Usage","text":"<p>// TODO: DEMONSTRATE API</p> <p>Previous Next</p>"},{"location":"cactus/packages/cactus-plugin-consortium-manual/","title":"<code>@hyperledger/cactus-plugin-consortium-manual</code>","text":""},{"location":"cactus/packages/cactus-plugin-consortium-manual/#prometheus-exporter","title":"Prometheus Exporter","text":"<p>This class creates a prometheus exporter, which scrapes the total Cactus node count.</p>"},{"location":"cactus/packages/cactus-plugin-consortium-manual/#usage-prometheus","title":"Usage Prometheus","text":"<p>The prometheus exporter object is initialized in the <code>PluginConsortiumManual</code> class constructor itself, so instantiating the object of the <code>PluginConsortiumManual</code> class, gives access to the exporter object. You can also initialize the prometheus exporter object separately and then pass it to the <code>IPluginConsortiumManualOptions</code> interface for <code>PluginConsortiumManual</code> constructor.</p> <p><code>getPrometheusMetricsV1</code> function returns the prometheus exporter metrics, currently displaying the total cactus node count, which currently refreshes to match the node count in the consortium, everytime <code>updateMetricNodeCount</code> method of the <code>PluginConsortiumManual</code> class is called.</p>"},{"location":"cactus/packages/cactus-plugin-consortium-manual/#prometheus-integration","title":"Prometheus Integration","text":"<p>To use Prometheus with this exporter make sure to install Prometheus main component. Once Prometheus is setup, the corresponding scrape_config needs to be added to the prometheus.yml</p> <p>- job_name: 'consortium_manual_exporter'   metrics_path: api/v1/plugins/hyperledger/cactus-plugin-consortium-manual/get-prometheus-exporter-metrics   scrape_interval: 5s   static_configs:     - targets: ['{host}:{port}']</p> <p>Here the <code>host:port</code> is where the prometheus exporter metrics are exposed. The test cases (For example, packages/cactus-plugin-consortium-manual/src/test/typescript/unit/consortium/get-node-jws-endpoint-v1.test.ts) exposes it over <code>0.0.0.0</code> and a random port(). The random port can be found in the running logs of the test case and looks like (42379 in the below mentioned URL) <code>Metrics URL: http://0.0.0.0:42379/api/v1/plugins/@hyperledger/cactus-plugin-consortium-manual/get-prometheus-exporter-metrics</code></p> <p>Once edited, you can start the prometheus service by referencing the above edited prometheus.yml file. On the prometheus graphical interface (defaulted to http://localhost:9090), choose Graph from the menu bar, then select the Console tab. From the Insert metric at cursor drop down, select cactus_consortium_manual_total_node_count and click execute</p>"},{"location":"cactus/packages/cactus-plugin-consortium-manual/#helper-code","title":"Helper code","text":""},{"location":"cactus/packages/cactus-plugin-consortium-manual/#responsetypets","title":"response.type.ts","text":"<p>This file contains the various responses of the metrics.</p>"},{"location":"cactus/packages/cactus-plugin-consortium-manual/#data-fetcherts","title":"data-fetcher.ts","text":"<p>This file contains functions encasing the logic to process the data points.</p>"},{"location":"cactus/packages/cactus-plugin-consortium-manual/#metricsts","title":"metrics.ts","text":"<p>This file lists all the prometheus metrics and what they are used for.</p> <p>Previous Next</p>"},{"location":"cactus/packages/cactus-plugin-keychain-vault/","title":"<code>@hyperledger/cactus-plugin-keychain-vault</code>","text":""},{"location":"cactus/packages/cactus-plugin-keychain-vault/#prometheus-exporter","title":"Prometheus Exporter","text":"<p>This class creates a prometheus exporter, which scrapes the transactions (total transaction count) for the use cases incorporating the use of Keychain vault plugin.</p>"},{"location":"cactus/packages/cactus-plugin-keychain-vault/#usage","title":"Usage","text":"<p>The prometheus exporter object is initialized in the <code>PluginKeychainVault</code> class constructor itself, so instantiating the object of the <code>PluginKeychainVault</code> class, gives access to the exporter object. You can also initialize the prometheus exporter object separately and then pass it to the <code>IPluginKeychainVaultOptions</code> interface for <code>PluginKeychainVault</code> constructor.</p> <p><code>getPrometheusMetricsV1</code> function returns the prometheus exporter metrics, currently displaying the total key count, which currently increments everytime the <code>set()</code> and <code>delete()</code> method of the <code>PluginKeychainVault</code> class is called.</p>"},{"location":"cactus/packages/cactus-plugin-keychain-vault/#prometheus-integration","title":"Prometheus Integration","text":"<p>To use Prometheus with this exporter make sure to install Prometheus main component. Once Prometheus is setup, the corresponding scrape_config needs to be added to the prometheus.yml</p> <p>- job_name: 'keychain_vault_exporter'   metrics_path: api/v1/plugins/hyperledger/cactus-plugin-keychain-vault/get-prometheus-exporter-metrics   scrape_interval: 5s   static_configs:     - targets: ['{host}:{port}']</p> <p>Here the <code>host:port</code> is where the prometheus exporter metrics are exposed. The test cases (For example, packages/cactus-plugin-keychain-vault/src/test/typescript/integration/plugin-keychain-vault.test.ts) exposes it over <code>0.0.0.0</code> and a random port(). The random port can be found in the running logs of the test case and looks like (42379 in the below mentioned URL) <code>Metrics URL: http://0.0.0.0:42379/api/v1/plugins/@hyperledger/cactus-plugin-keychain-plugin/get-prometheus-exporter-metrics</code></p> <p>Once edited, you can start the prometheus service by referencing the above edited prometheus.yml file. On the prometheus graphical interface (defaulted to http://localhost:9090), choose Graph from the menu bar, then select the Console tab. From the Insert metric at cursor drop down, select cactus_keychain_vault_total_key_count and click execute</p>"},{"location":"cactus/packages/cactus-plugin-keychain-vault/#helper-code","title":"Helper code","text":""},{"location":"cactus/packages/cactus-plugin-keychain-vault/#responsetypets","title":"response.type.ts","text":"<p>This file contains the various responses of the metrics.</p>"},{"location":"cactus/packages/cactus-plugin-keychain-vault/#data-fetcherts","title":"data-fetcher.ts","text":"<p>This file contains functions encasing the logic to process the data points</p>"},{"location":"cactus/packages/cactus-plugin-keychain-vault/#metricsts","title":"metrics.ts","text":"<p>This file lists all the prometheus metrics and what they are used for.</p> <p>Previous Next</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-besu/","title":"<code>@hyperledger/cactus-plugin-ledger-connector-besu</code>","text":"<p>This plugin provides <code>Cactus</code> a way to interact with Besu networks. Using this we can perform:</p> <ul> <li> <p>Deploy Smart-contracts through bytecode.</p> </li> <li> <p>Build and sign transactions using different keystores.</p> </li> <li> <p>Invoke smart-contract functions that we have deployed on the network.</p> </li> </ul>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-besu/#summary","title":"Summary","text":"<ul> <li> <p>Getting Started</p> </li> <li> <p>Architecture</p> </li> <li> <p>Usage</p> </li> <li> <p>Prometheus Exporter</p> </li> <li> <p>Running the tests</p> </li> <li> <p>Built With</p> </li> <li> <p>Contributing</p> </li> <li> <p>License</p> </li> <li> <p>Acknowledgments</p> </li> </ul>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-besu/#getting-started","title":"Getting Started","text":"<p>Clone the git repository on your local machine. Follow these instructions that will get you a copy of the project up and running on your local machine for development and testing purposes.</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-besu/#prerequisites","title":"Prerequisites","text":"<p>In the root of the project to install the dependencies execute the command:</p> <p>npm run configure</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-besu/#compiling","title":"Compiling","text":"<p>In the project root folder, run this command to compile the plugin and create the dist directory:</p> <p>npm run tsc</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-besu/#architecture","title":"Architecture","text":"<p>The sequence diagrams for various endpoints are mentioned below</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-besu/#run-transaction-endpoint","title":"run-transaction-endpoint","text":"<p> The above diagram shows the sequence diagram of run-transaction-endpoint. User A (One of the many Users) interacts with the API Client which in turn, calls the API server. API server then executes transact() method which is explained in detailed in the subsequent diagrams.  The above diagram shows the sequence diagram of transact() method of the PluginLedgerConnectorBesu class. The caller to this function, which in reference to the above sequence diagram is API server, sends RunTransactionRequest object as an argument to the transact() method. Based on the type of Web3SigningCredentialType, corresponding responses are sent back to the caller.  The above diagram shows transactCactusKeychainReference() method being called by the transact() method of the PluginLedgerConnector class when the Web3SigningCredentialType is CACTUSKEYCHAINREF. This method inturn calls transactPrivateKey() which calls the signTransaction() method of web3 library.  The above diagram shows transactPrivateKey() method being called by the transact() method of the PluginLedgerConnector class when the Web3SigningCredentialType is PRIVATEKEYHEX. This method then calls the signTransaction() method of the web3 library.  The above diagram shows transactSigned() method being called by the transact() method of the PluginLedgerConnector class when the Web3SigningCredentialType is NONE. This method calls the sendSignedTransaction() of the web3 library and then calls pollForTxReceipt() method.  The above diagram shows pollForTxReceipt() method which is called by the transactSigned() method as described in the previous sequence diagram. This method waits for the block confirmation in a loop and then sends the corresponding response back to the caller.</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-besu/#usage","title":"Usage","text":"<p>To use this import public-api and create new PluginFactoryLedgerConnector. Then use it to create a connector.</p> <p>const factory = new PluginFactoryLedgerConnector({     pluginImportType: PluginImportType.LOCAL,   });   const connector: PluginLedgerConnectorBesu = await factory.create({     rpcApiHttpHost,     instanceId: uuidv4(),     pluginRegistry: new PluginRegistry(),   });</p> <p>You can make calls through the connector to the plugin API:</p> <p>async invokeContract(req: InvokeContractV1Request):Promise&lt;InvokeContractV1Response&gt;; async transactSigned(rawTransaction: string): Promise&lt;RunTransactionResponse&gt;; async transactPrivateKey(req: RunTransactionRequest): Promise&lt;RunTransactionResponse&gt;; async transactCactusKeychainRef(req: RunTransactionRequest):Promise&lt;RunTransactionResponse&gt;; async deployContract(req: DeployContractSolidityBytecodeV1Request):Promise&lt;RunTransactionResponse&gt;; async signTransaction(req: SignTransactionRequest):Promise&lt;Optional&gt;; <p>Call example to deploy a contract:</p> <p>const deployOut = await connector.deployContract({   web3SigningCredential: {     ethAccount: firstHighNetWorthAccount,     secret: besuKeyPair.privateKey,     type: Web3SigningCredentialType.PrivateKeyHex,   },   bytecode: SmartContractJson.bytecode,   gas: 1000000, });</p> <p>The field \u201ctype\u201d can have the following values:</p> <p>enum Web3SigningCredentialType {     CACTUSKEYCHAINREF = 'CACTUS_KEYCHAIN_REF',     GETHKEYCHAINPASSWORD = 'GETH_KEYCHAIN_PASSWORD',     PRIVATEKEYHEX = 'PRIVATE_KEY_HEX',     NONE = 'NONE' }</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-besu/#transaction-privacy-feature","title":"Transaction Privacy Feature","text":"<p>Private transactions using Besu are currently enabled.</p> <p>The privateFor and privateFrom fields must be populated, more information about Besu Private Transactions here.</p> <p>Call example to deploy a private contract:</p> <p>const deployOut = await connector1.deployContract({     bytecode: SmartContract.bytecode,     contractAbi: SmartContract.abi,     contractName: SmartContract.contractName,     constructorArgs: [],     privateTransactionConfig: {       privateFrom: SendingTesseraPublicKey,       privateFor: [         Member1TesseraPrivateKey,         Member2TesseraPrivateKey,       ],     },     web3SigningCredential: {       secret:SendingBesuPrivateKey,       type: Web3SigningCredentialType.PrivateKeyHex,     },     gas: 3000000   });</p> <p>Extensive documentation and examples in the readthedocs (WIP)</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-besu/#buildingrunning-the-container-image-locally","title":"Building/running the container image locally","text":"<p>In the Cactus project root say:</p> <p>DOCKER_BUILDKIT=1 docker build -f ./packages/cactus-plugin-ledger-connector-besu/Dockerfile . -t cplcb</p> <p>Build with a specific version of the npm package:</p> <p>DOCKER_BUILDKIT=1 docker build --build-arg NPM_PKG_VERSION=1.0.0 -f ./packages/cactus-plugin-ledger-connector-besu/Dockerfile . -t cplcb</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-besu/#running-the-container","title":"Running the container","text":"<p>Launch container with plugin configuration as an environment variable:</p> <p>docker run \\   --rm \\   --publish 3000:3000 \\   --publish 4000:4000 \\   --env PLUGINS='[{\"packageName\": \"hyperledger/cactus-plugin-ledger-connector-besu\", \"type\": \"org.hyperledger.cactus.plugin_import_type.LOCAL\", \"action\": \"org.hyperledger.cactus.plugin_import_action.INSTALL\",  \"options\": {\"rpcApiHttpHost\": \"http://localhost:8545\", \"rpcApiWsHost\":\"ws://localhost:8546\", \"instanceId\": \"some-unique-besu-connector-instance-id\"}}]' \\   cplcb</p> <p>Launch container with plugin configuration as a CLI argument:</p> <p>docker run \\   --rm \\   --publish 3000:3000 \\    --publish 4000:4000 \\   cplcb \\     ./node_modules/.bin/cactusapi \\     --plugins='[{\"packageName\": \"hyperledger/cactus-plugin-ledger-connector-besu\", \"type\": \"org.hyperledger.cactus.plugin_import_type.LOCAL\", \"action\": \"org.hyperledger.cactus.plugin_import_action.INSTALL\",  \"options\": {\"rpcApiHttpHost\": \"http://localhost:8545\", \"rpcApiWsHost\":\"ws://localhost:8546\", \"instanceId\": \"some-unique-besu-connector-instance-id\"}}]'</p> <p>Launch container with configuration file mounted from host machine:</p> <p>echo '[{\"packageName\": \"hyperledger/cactus-plugin-ledger-connector-besu\", \"type\": \"org.hyperledger.cactus.plugin_import_type.LOCAL\", \"action\": \"org.hyperledger.cactus.plugin_import_action.INSTALL\",  \"options\": {\"rpcApiHttpHost\": \"http://localhost:8545\", \"rpcApiWsHost\":\"ws://localhost:8546\", \"instanceId\": \"some-unique-besu-connector-instance-id\"}}]' &gt; cactus.json</p> <p>docker run \\   --rm \\   --publish 3000:3000 \\   --publish 4000:4000 \\   --mount type=bind,source=\"$(pwd)\"/cactus.json,target=/cactus.json \\   cplcb \\     ./node_modules/.bin/cactusapi \\     --config-file=/cactus.json</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-besu/#testing-api-calls-with-the-container","title":"Testing API calls with the container","text":"<p>Don\u2019t have a Besu network on hand to test with? Test or develop against our Besu All-In-One container!</p> <p>Terminal Window 1 (Ledger)</p> <p>docker run \\   --publish 0.0.0.0:8545:8545/tcp \\   --publish 0.0.0.0:8546:8546/tcp \\   --publish 0.0.0.0:8888:8888/tcp \\   --publish 0.0.0.0:9001:9001/tcp \\   --publish 0.0.0.0:9545:9545/tcp \\   ghcr.io/hyperledger/cactus-besu-all-in-one:2022-05-12-2330a96</p> <p>Terminal Window 2 (Cactus API Server)</p> <p>docker run \\   --network host \\   --rm \\   --publish 3000:3000 \\   --publish 4000:4000 \\   --env AUTHORIZATION_PROTOCOL='NONE' \\   --env AUTHORIZATION_CONFIG_JSON='{}' \\   --env GRPC_TLS_ENABLED=false \\   --env PLUGINS='[{\"packageName\": \"hyperledger/cactus-plugin-ledger-connector-besu\", \"type\": \"org.hyperledger.cactus.plugin_import_type.LOCAL\", \"action\": \"org.hyperledger.cactus.plugin_import_action.INSTALL\",  \"options\": {\"rpcApiHttpHost\": \"http://localhost:8545\", \"rpcApiWsHost\":\"ws://localhost:8546\", \"instanceId\": \"some-unique-besu-connector-instance-id\"}}]' \\   cplcb</p> <p>Terminal Window 3 (curl - replace eth accounts as needed)</p> <p>curl --location --request POST 'http://127.0.0.1:4000/api/v1/plugins/@hyperledger/cactus-plugin-ledger-connector-besu/run-transaction' \\ --header 'Content-Type: application/json' \\ --data-raw '{     \"web3SigningCredential\": {       \"ethAccount\": \"627306090abaB3A6e1400e9345bC60c78a8BEf57\",       \"secret\": \"c87509a1c067bbde78beb793e6fa76530b6382a4c0241e5e4a9ec0a0f44dc0d3\",       \"type\": \"PRIVATE_KEY_HEX\"     },     \"consistencyStrategy\": {       \"blockConfirmations\": 0,       \"receiptType\": \"NODE_TX_POOL_ACK\"     },     \"transactionConfig\": {       \"from\": \"627306090abaB3A6e1400e9345bC60c78a8BEf57\",       \"to\": \"f17f52151EbEF6C7334FAD080c5704D77216b732\",       \"value\": 1,       \"gas\": 10000000     } }'</p> <p>The above should produce a response that looks similar to this:</p> <p>{     \"success\": true,     \"data\": {         \"transactionReceipt\": {             \"blockHash\": \"0x7c97c038a5d3bd84613fe23ed442695276d5d2df97f4e7c4f10ca06765033ffd\",             \"blockNumber\": 1218,             \"contractAddress\": null,             \"cumulativeGasUsed\": 21000,             \"from\": \"0x627306090abab3a6e1400e9345bc60c78a8bef57\",             \"gasUsed\": 21000,             \"logs\": [],             \"logsBloom\": \"0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\",             \"status\": true,             \"to\": \"0xf17f52151ebef6c7334fad080c5704d77216b732\",             \"transactionHash\": \"0xc7fcb46c735bdc696d500bfc70c72595a2b8c31813929e5c61d9a5aec3376d6f\",             \"transactionIndex\": 0         }     } }</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-besu/#prometheus-exporter","title":"Prometheus Exporter","text":"<p>This class creates a prometheus exporter, which scrapes the transactions (total transaction count) for the use cases incorporating the use of Besu connector plugin.</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-besu/#prometheus-exporter-usage","title":"Prometheus Exporter Usage","text":"<p>The prometheus exporter object is initialized in the <code>PluginLedgerConnectorBesu</code> class constructor itself, so instantiating the object of the <code>PluginLedgerConnectorBesu</code> class, gives access to the exporter object. You can also initialize the prometheus exporter object separately and then pass it to the <code>IPluginLedgerConnectorBesuOptions</code> interface for <code>PluginLedgerConnectoBesu</code> constructor.</p> <p><code>getPrometheusMetricsV1</code> function returns the prometheus exporter metrics, currently displaying the total transaction count, which currently increments everytime the <code>transact()</code> method of the <code>PluginLedgerConnectorBesu</code> class is called.</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-besu/#prometheus-integration","title":"Prometheus Integration","text":"<p>To use Prometheus with this exporter make sure to install Prometheus main component. Once Prometheus is setup, the corresponding scrape_config needs to be added to the prometheus.yml</p> <p>- job_name: 'besu_ledger_connector_exporter'   metrics_path: api/v1/plugins/hyperledger/cactus-plugin-ledger-connector-besu/get-prometheus-exporter-metrics   scrape_interval: 5s   static_configs:     - targets: ['{host}:{port}']</p> <p>Here the <code>host:port</code> is where the prometheus exporter metrics are exposed. The test cases (For example, packages/cactus-plugin-ledger-connector-besu/src/test/typescript/integration/plugin-ledger-connector-besu/deploy-contract/deploy-contract-from-json.test.ts) exposes it over <code>0.0.0.0</code> and a random port(). The random port can be found in the running logs of the test case and looks like (42379 in the below mentioned URL) <code>Metrics URL: http://0.0.0.0:42379/api/v1/plugins/@hyperledger/cactus-plugin-ledger-connector-besu/get-prometheus-exporter-metrics</code></p> <p>Once edited, you can start the prometheus service by referencing the above edited prometheus.yml file. On the prometheus graphical interface (defaulted to http://localhost:9090), choose Graph from the menu bar, then select the Console tab. From the Insert metric at cursor drop down, select cactus_besu_total_tx_count and click execute</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-besu/#helper-code","title":"Helper code","text":""},{"location":"cactus/packages/cactus-plugin-ledger-connector-besu/#responsetypets","title":"response.type.ts","text":"<p>This file contains the various responses of the metrics.</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-besu/#data-fetcherts","title":"data-fetcher.ts","text":"<p>This file contains functions encasing the logic to process the data points</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-besu/#metricsts","title":"metrics.ts","text":"<p>This file lists all the prometheus metrics and what they are used for.</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-besu/#running-the-tests","title":"Running the tests","text":"<p>To check that all has been installed correctly and that the pugin has no errors run the tests:</p> <ul> <li>Run this command at the project\u2019s root:</li> </ul> <p>npm run test:plugin-ledger-connector-besu</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-besu/#contributing","title":"Contributing","text":"<p>We welcome contributions to Hyperledger Cactus in many forms, and there\u2019s always plenty to do!</p> <p>Please review CONTRIBUTING.md to get started.</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-besu/#license","title":"License","text":"<p>This distribution is published under the Apache License Version 2.0 found in the LICENSE file.</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-besu/#acknowledgments","title":"Acknowledgments","text":"<p>Previous Next</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-corda/","title":"<code>@hyperledger/cactus-plugin-ledger-connector-corda</code>","text":""},{"location":"cactus/packages/cactus-plugin-ledger-connector-corda/#summary","title":"Summary","text":"<p>The Corda connector is written in Kotlin and ships as a Spring Boot JVM application that accepts API requests and translates those into Corda RPC calls.</p> <p>Deploying the Corda connector therefore involves also deploying the mentioned JVM application in addition to deploying the Cactus API server with the desired plugins configured.</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-corda/#concepts","title":"Concepts","text":""},{"location":"cactus/packages/cactus-plugin-ledger-connector-corda/#contract-invocation-json-dsl","title":"Contract Invocation JSON DSL","text":"<p>One of our core design principles for Hyperledger Cactus is to have low impact deployments meaning that changes to the ledgers themselves should be kept to a minimum or preferably have no need for any at all. With this in mind, we had to solve the challenge of providing users with the ability to invoke Corda flows as dynamically as possible within the confines of the strongly typed JVM contrasted with the weakly typed Javascript language runtime of NodeJS.</p> <p>Corda might release some convenience features to ease this in the future, but in the meantime we have the Contract Invocation JSON DSL which allows developers to specify truly arbitrary JVM types as part of their contract invocation arguments even if otherwise these types would not be possible to serialize or deserialize with traditional tooling such as the excellent Jackson JSON Java library or similar ones.</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-corda/#expressing-primitive-vs-reference-types-with-the-dls","title":"Expressing Primitive vs Reference Types with the DLS","text":"<p>The features of the DSL include expressing whether a contract invocation parameter is a reference or a primitive JVM data types. This is a language feature that Javascript has as well to some extent, but for those in need of a refresher, here\u2019s a writeup from a well known Q/A website that I found on the internet: What\u2019s the difference between primitive and reference types?</p> <p>To keep it simple, the following types are primitive data types in the Java Virtual Machine (JVM) and everything else not included in the list below can be safely considered a reference type:</p> <ul> <li> <p>boolean</p> </li> <li> <p>byte</p> </li> <li> <p>short</p> </li> <li> <p>char</p> </li> <li> <p>int</p> </li> <li> <p>long</p> </li> <li> <p>float</p> </li> <li> <p>double</p> </li> </ul> <p>If you\u2019d like to further clarify how this works and feel like an exciting adventure then we recommend that you dive into the source code of the deserializer implementation of the JSON DSL and take a look at the following points of interest in the code located there:</p> <ul> <li> <p><code>val exoticTypes: Map&lt;String, Class&lt;*&gt;&gt;</code></p> </li> <li> <p><code>fun instantiate(jvmObject: JvmObject)</code></p> </li> </ul>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-corda/#flow-invocation-types","title":"Flow Invocation Types","text":"<p>Can be dynamic or tracked dynamic and the corresponding enum values are defined as:</p> <p>/**  * Determines which flow starting method will be used on the back-end when invoking the flow. Based on the value here the plugin back-end might invoke the rpc.startFlowDynamic() method or the rpc.startTrackedFlowDynamic() method. Streamed responses are aggregated and returned in a single response to HTTP callers who are not equipped to handle streams like WebSocket/gRPC/etc. do.  * @export  * @enum {string}  */ export enum FlowInvocationType {     TRACKEDFLOWDYNAMIC = 'TRACKED_FLOW_DYNAMIC',     FLOWDYNAMIC = 'FLOW_DYNAMIC' }</p> <p>Official Corda Java Docs - startFlowDynamic()</p> <p>Official Corda Java Docs - startTrackedFlowDynamic()</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-corda/#usage","title":"Usage","text":"<p>Take a look at how the API client can be used to run transactions on a Corda ledger: <code>packages/cactus-plugin-ledger-connector-corda/src/test/typescript/integration/jvm-kotlin-spring-server.test.ts</code></p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-corda/#invoke-contract-flow-with-no-parameters","title":"Invoke Contract (flow) with no parameters","text":"<p>Below, we\u2019ll demonstrate invoking a simple contract with no parameters.</p> <p>The contract source:</p> <p>package com.example.organization.samples.application.flows;</p> <p>class SomeCoolFlow {   // constructor with no arguments   public SomeCoolFlow() {     this.doSomething();   }</p> <p>public doSomething(): void {     throw new RuntimeException(\"Method not implemented.\");   } }</p> <p>Steps to build your request:</p> <ol> <li> <p>Find out the fully qualified class name of your contract (flow) and set this as the value for the request parameter <code>flowFullClassName</code></p> </li> <li> <p>Decide on your flow invocation type which largely comes down to answering the question of: Does your invocation follow a request/response pattern or more like a channel subscription where multiple updates at different times are streamed to the client in response to the invocation request? In our example we assume the simpler request/response communication pattern and therefore will set the <code>flowInvocationType</code> to <code>FlowInvocationType.FLOWDYNAMIC</code></p> </li> <li> <p>Invoke the flow via the API client with the <code>params</code> argument being specified as an empty array <code>[]</code></p> <p>import { DefaultApi as CordaApi } from \"hyperledger/cactus-plugin-ledger-connector-corda\"; import { FlowInvocationType } from \"hyperledger/cactus-plugin-ledger-connector-corda\";</p> <p>const apiUrl = \"your-cactus-host.example.com\"; // don't forget to specify the port if applicable const apiClient = new CordaApi({ basePath: apiUrl });</p> <p>const res = await apiClient.invokeContractV1({   flowFullClassName: \"com.example.organization.samples.application.flows.SomeCoolFlow\",   flowInvocationType: FlowInvocationType.FLOWDYNAMIC,   params: [],   timeoutMs: 60000, });</p> </li> </ol>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-corda/#invoke-contract-flow-with-a-single-integer-parameter","title":"Invoke Contract (flow) with a single integer parameter","text":"<p>Below, we\u2019ll demonstrate invoking a simple contract with a single numeric parameter.</p> <p>The contract source:</p> <p>package com.example.organization.samples.application.flows;</p> <p>class SomeCoolFlow {   // constructor with a primitive type long argument   public SomeCoolFlow(long myParameterThatIsLong) {     // do something with the parameter here   } }</p> <p>Steps to build your request:</p> <ol> <li> <p>Find out the fully qualified class name of your contract (flow) and set this as the value for the request parameter <code>flowFullClassName</code></p> </li> <li> <p>Decide on your flow invocation type. More details at Invoke Contract (flow) with no parameters</p> </li> <li> <p>Find out what is the fully qualified class name of the parameter you wish to pass in. You can do this be inspecting the sources of the contract itself. If you do not have access to those sources, then the documentation of the contract should have answers or the person who authored said contract. In our case here the fully qualified class name for the number parameter is simply <code>long</code> because it is a primitive data type and as such these can be referred to in their short form, but the fully qualified version also works such as: <code>java.lang.Long</code>. When in doubt about these, you can always consult the official java.lang.Long Java Docs After having determined the above, you can construct your first <code>JvmObject</code> JSON object as follows in order to pass in the number <code>42</code> as the first and only parameter for our flow invocation:</p> <p>params: [   {     jvmTypeKind: JvmTypeKind.PRIMITIVE,     jvmType: {       fqClassName: \"long\",     },     primitiveValue: 42,   } ]</p> </li> <li> <p>Invoke the flow via the API client with the <code>params</code> populated as explained above:</p> <p>import { DefaultApi as CordaApi } from \"hyperledger/cactus-plugin-ledger-connector-corda\"; import { FlowInvocationType } from \"hyperledger/cactus-plugin-ledger-connector-corda\";</p> <p>// don't forget to specify the port if applicable const apiUrl = \"your-cactus-host.example.com\"; const apiClient = new CordaApi({ basePath: apiUrl });</p> <p>const res = await apiClient.invokeContractV1({   flowFullClassName: \"com.example.organization.samples.application.flows.SomeCoolFlow\",   flowInvocationType: FlowInvocationType.FLOWDYNAMIC,   params: [     {       jvmTypeKind: JvmTypeKind.PRIMITIVE,       jvmType: {         fqClassName: \"long\",       },       primitiveValue: 42,     }   ],   timeoutMs: 60000, });</p> </li> </ol>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-corda/#invoke-contract-flow-with-a-custom-class-parameter","title":"Invoke Contract (flow) with a custom class parameter","text":"<p>Below, we\u2019ll demonstrate invoking a contract with a single class instance parameter.</p> <p>The contract sources:</p> <p>package com.example.organization.samples.application.flows;</p> <p>// contract with a class instance parameter class BuildSpaceshipFlow {   public BuildSpaceshipFlow(SpaceshipInfo buildSpecs) {     // build spaceship as per the specs   } }</p> <p>package com.example.organization.samples.application.flows;</p> <p>// The type that the contract accepts as an input parameter class SpaceshipInfo {   public SpaceshipInfo(String name, Integer seatsForHumans) {   } }</p> <p>Assembling and Sending your request:</p> <p>Invoke the flow via the API client with the <code>params</code> populated as shown below.</p> <p>Key thing notice here is that we now have a class instance as a parameter for our contract (flow) invocation so we have to describe how this class instance itself will be instantiated by providing a nested array of parameters via the <code>jvmCtorArgs</code> which stands for Java Virtual Machine Constructor Arguments meaning that elements of this array will be passed in dynamically (via Reflection) to the class constructor.</p> <p>Java Equivalent</p> <p>cordaRpcClient.startFlowDynamic(   BuildSpaceshipFlow.class,   new SpaceshipInfo(     \"The last spaceship you'll ever need.\",     10000000   ) );</p> <p>Cactus Invocation JSON DLS Equivalent to the Above Java Snippet</p> <p>import { DefaultApi as CordaApi } from \"hyperledger/cactus-plugin-ledger-connector-corda\"; import { FlowInvocationType } from \"hyperledger/cactus-plugin-ledger-connector-corda\";</p> <p>// don't forget to specify the port if applicable const apiUrl = \"your-cactus-host.example.com\"; const apiClient = new CordaApi({ basePath: apiUrl });</p> <p>const res = await apiClient.invokeContractV1({   flowFullClassName: \"com.example.organization.samples.application.flows.BuildSpaceshipFlow\",   flowInvocationType: FlowInvocationType.FLOWDYNAMIC,   params: [     {       jvmTypeKind: JvmTypeKind.REFERENCE,         jvmType: {         fqClassName: \"com.example.organization.samples.application.flows.SpaceshipInfo\",       },</p> <pre><code>  jvmCtorArgs: \\[\n    {\n      jvmTypeKind: JvmTypeKind.PRIMITIVE,\n      jvmType: {\n        fqClassName: \"java.lang.String\",\n      },\n      primitiveValue: \"The last spaceship you'll ever need.\",\n    },\n    {\n      jvmTypeKind: JvmTypeKind.PRIMITIVE,\n      jvmType: {\n        fqClassName: \"java.lang.Long\",\n      },\n      primitiveValue: 10000000000,\n    },\n  \\],\n}\n</code></pre> <p>],   timeoutMs: 60000, });</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-corda/#transaction-monitoring","title":"Transaction Monitoring","text":"<ul> <li> <p>There are two interfaces to monitor changes of vault states - reactive <code>watchBlocksV1</code> method, and low-level HTTP API calls.</p> </li> <li> <p>Note: The monitoring APIs are implemented only on kotlin-server connector (<code>main-server</code>), not typescript connector!</p> </li> <li> <p>For usage examples review the functional test file: <code>packages/cactus-plugin-ledger-connector-corda/src/test/typescript/integration/monitor-transactions-v4.8.test.ts</code></p> </li> <li> <p>Because transactions read from corda are stored on the connector, they will be lost if connector is closed/killed before transaction were read by the clients.</p> </li> <li> <p>Each client has own set of state monitors that are managed independently. After starting the monitoring, each new transaction is queued on the connector until read and explicitly cleared by <code>watchBlocksV1</code> or direct HTTP API call.</p> </li> <li> <p>Client monitors can be periodically removed by the connector, if there was no action from the client for specified amount of time.</p> </li> <li> <p>Client expiration delay can be configured with <code>cactus.sessionExpireMinutes</code> option. It default to 30 minutes.</p> </li> <li> <p>Each transaction has own index assigned by the corda connector. Index is unique for each client monitoring session. For instance:</p> <ul> <li> <p>Stopping monitoring for given state will reset the transaction index counter for given client. After restart, it will report first transaction with index 0.</p> </li> <li> <p>Each client can see tha same transaction with different index.</p> </li> <li> <p>Index can be used to determine the transaction order for given client session.</p> </li> </ul> </li> </ul>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-corda/#watchblocksv1","title":"watchBlocksV1","text":"<ul> <li> <p><code>watchBlocksV1(options: watchBlocksV1Options): Observable&lt;CordaBlock&gt;</code></p> </li> <li> <p>Reactive (RxJS) interface to observe state changes.</p> </li> <li> <p>Internally, it uses polling of low-level HTTP APIs.</p> </li> <li> <p>Watching block should return each block at least once, no blocks should be missed after startMonitor has started. The only case when transaction is lost is when connector we were connected to died.</p> </li> <li> <p>Transactions can be duplicated in case internal <code>ClearMonitorTransactionsV1</code> call was not successful (for instance, because of connection problems).</p> </li> <li> <p>Options:</p> <ul> <li> <p><code>stateFullClassName: string</code>: state to monitor.</p> </li> <li> <p><code>pollRate?: number</code>: how often poll the kotlin server for changes (default 5 seconds).</p> </li> </ul> </li> </ul>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-corda/#low-level-http-api","title":"Low-level HTTP API","text":"<ul> <li> <p>These should not be used when watchBlocks API is sufficient.</p> </li> <li> <p>Consists of the following methods:</p> <ul> <li> <p><code>startMonitorV1</code>: Start monitoring for specified state changes. All changes after calling this function will be stored in internal kotlin-server buffer, ready to be read by calls to <code>GetMonitorTransactionsV1</code>. Transactions occuring before the call to startMonitorV1 will not be reported.</p> </li> <li> <p><code>GetMonitorTransactionsV1</code>: Read all transactions for given state name still remaining in internal buffer.</p> </li> <li> <p><code>ClearMonitorTransactionsV1</code>: Remove transaction for given state name with specified index number from internal buffer. Should be used to acknowledge receiving specified transactions in user code, so that transactions are not reported multiple times.</p> </li> <li> <p><code>stopMonitorV1</code>: Don\u2019t watch for transactions changes anymore, remove any transactions that were not read until now.</p> </li> </ul> </li> </ul>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-corda/#custom-configuration-via-env-variables","title":"Custom Configuration via Env Variables","text":"<p>{   \"cactus\": {     \"threadCount\": 3,     \"sessionExpireMinutes\": 10,     \"corda\": {       \"node\": {         \"host\": \"localhost\"       },       \"rpc\": {         \"port\": 10006,         \"username\": \"user1\",         \"password\": \"test\"       }     }   } }</p> <p>SPRING_APPLICATION_JSON='{\"cactus\":{\"corda\":{\"node\": {\"host\": \"localhost\"}, \"rpc\":{\"port\": 10006, \"username\":\"user1\", \"password\": \"test\"}}}}' gradle test</p> <p>{   \"flowFullClassName\" : \"net.corda.samples.example.flows.ExampleFlow\\({\"\\)\"}Initiator\",   \"flowInvocationType\" : \"FLOW_DYNAMIC\",   \"params\" : [ {     \"jvmTypeKind\" : \"PRIMITIVE\",     \"jvmType\" : {       \"fqClassName\" : \"java.lang.Integer\"     },     \"primitiveValue\" : 42,     \"jvmCtorArgs\" : null   }, {     \"jvmTypeKind\" : \"REFERENCE\",     \"jvmType\" : {       \"fqClassName\" : \"net.corda.core.identity.Party\"     },     \"primitiveValue\" : null,     \"jvmCtorArgs\" : [ {       \"jvmTypeKind\" : \"REFERENCE\",       \"jvmType\" : {         \"fqClassName\" : \"net.corda.core.identity.CordaX500Name\"       },       \"primitiveValue\" : null,       \"jvmCtorArgs\" : [ {         \"jvmTypeKind\" : \"PRIMITIVE\",         \"jvmType\" : {           \"fqClassName\" : \"java.lang.String\"         },         \"primitiveValue\" : \"PartyB\",         \"jvmCtorArgs\" : null       }, {         \"jvmTypeKind\" : \"PRIMITIVE\",         \"jvmType\" : {           \"fqClassName\" : \"java.lang.String\"         },         \"primitiveValue\" : \"New York\",         \"jvmCtorArgs\" : null       }, {         \"jvmTypeKind\" : \"PRIMITIVE\",         \"jvmType\" : {           \"fqClassName\" : \"java.lang.String\"         },         \"primitiveValue\" : \"US\",         \"jvmCtorArgs\" : null       } ]     }, {       \"jvmTypeKind\" : \"REFERENCE\",       \"jvmType\" : {         \"fqClassName\" : \"org.hyperledger.cactus.plugin.ledger.connector.corda.server.impl.PublicKeyImpl\"       },       \"primitiveValue\" : null,       \"jvmCtorArgs\" : [ {         \"jvmTypeKind\" : \"PRIMITIVE\",         \"jvmType\" : {           \"fqClassName\" : \"java.lang.String\"         },         \"primitiveValue\" : \"EdDSA\",         \"jvmCtorArgs\" : null       }, {         \"jvmTypeKind\" : \"PRIMITIVE\",         \"jvmType\" : {           \"fqClassName\" : \"java.lang.String\"         },         \"primitiveValue\" : \"X.509\",         \"jvmCtorArgs\" : null       }, {         \"jvmTypeKind\" : \"PRIMITIVE\",         \"jvmType\" : {           \"fqClassName\" : \"java.lang.String\"         },         \"primitiveValue\" : \"MCowBQYDK2VwAyEAoOv19eiCDJ7HzR9UrfwbFig7qcD1jkewKkkS4WF9kPA=\",         \"jvmCtorArgs\" : null       } ]     } ]   } ],   \"timeoutMs\" : null }</p> <p>I 16:51:01 1 Client.main - nodeDiagnosticInfo= {   \"version\" : \"4.6\",   \"revision\" : \"85e387e\",   \"platformVersion\" : 8,   \"vendor\" : \"Corda Open Source\",   \"cordapps\" : [ {     \"type\" : \"Workflow CorDapp\",     \"name\" : \"workflows-1.0\",     \"shortName\" : \"Example-Cordapp Flows\",     \"minimumPlatformVersion\" : 8,     \"targetPlatformVersion\" : 8,     \"version\" : \"1\",     \"vendor\" : \"Corda Open Source\",     \"licence\" : \"Apache License, Version 2.0\",     \"jarHash\" : {       \"offset\" : 0,       \"size\" : 32,       \"bytes\" : \"V7ssTw0etgg3nSGk1amArB+fBH8fQUyBwIFs0DhID+0=\"     }   }, {     \"type\" : \"Contract CorDapp\",     \"name\" : \"contracts-1.0\",     \"shortName\" : \"Example-Cordapp Contracts\",     \"minimumPlatformVersion\" : 8,     \"targetPlatformVersion\" : 8,     \"version\" : \"1\",     \"vendor\" : \"Corda Open Source\",     \"licence\" : \"Apache License, Version 2.0\",     \"jarHash\" : {       \"offset\" : 0,       \"size\" : 32,       \"bytes\" : \"Xe0eoh4+T6fsq4u0QKqkVsVDMYSWhuspHqE0wlOlyqU=\"     }   } ] }</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-corda/#building-docker-image-locally","title":"Building Docker Image Locally","text":"<p>The <code>cccs</code> tag used in the below example commands is a shorthand for the full name of the container image otherwise referred to as <code>cactus-corda-connector-server</code>.</p> <p>From the project root:</p> <p>DOCKER_BUILDKIT=1 docker build ./packages/cactus-plugin-ledger-connector-corda/src/main-server/ -t cccs</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-corda/#example-nodediagnosticinfo-json-response","title":"Example NodeDiagnosticInfo JSON Response","text":"<p>{   \"version\": \"4.6\",   \"revision\": \"85e387e\",   \"platformVersion\": 8,   \"vendor\": \"Corda Open Source\",   \"cordapps\": [     {       \"type\": \"Workflow CorDapp\",       \"name\": \"workflows-1.0\",       \"shortName\": \"Obligation Flows\",       \"minimumPlatformVersion\": 8,       \"targetPlatformVersion\": 8,       \"version\": \"1\",       \"vendor\": \"Corda Open Source\",       \"licence\": \"Apache License, Version 2.0\",       \"jarHash\": {         \"bytes\": \"Vf9MllnrC7vrWxrlDE94OzPMZW7At1HhTETL/XjiAmc=\",         \"offset\": 0,         \"size\": 32       }     },     {       \"type\": \"CorDapp\",       \"name\": \"corda-confidential-identities-4.6\",       \"shortName\": \"corda-confidential-identities-4.6\",       \"minimumPlatformVersion\": 1,       \"targetPlatformVersion\": 1,       \"version\": \"Unknown\",       \"vendor\": \"Unknown\",       \"licence\": \"Unknown\",       \"jarHash\": {         \"bytes\": \"nqBwqHJMbLW80hmRbKEYk0eAknFiX8N40LKuGsD0bPo=\",         \"offset\": 0,         \"size\": 32       }     },     {       \"type\": \"Contract CorDapp\",       \"name\": \"corda-finance-contracts-4.6\",       \"shortName\": \"Corda Finance Demo\",       \"minimumPlatformVersion\": 1,       \"targetPlatformVersion\": 8,       \"version\": \"1\",       \"vendor\": \"R3\",       \"licence\": \"Open Source (Apache 2)\",       \"jarHash\": {         \"bytes\": \"a43Q/GJG6JKTZzq3U80P8L1DWWcB/D+Pl5uitEtAeQQ=\",         \"offset\": 0,         \"size\": 32       }     },     {       \"type\": \"Workflow CorDapp\",       \"name\": \"corda-finance-workflows-4.6\",       \"shortName\": \"Corda Finance Demo\",       \"minimumPlatformVersion\": 1,       \"targetPlatformVersion\": 8,       \"version\": \"1\",       \"vendor\": \"R3\",       \"licence\": \"Open Source (Apache 2)\",       \"jarHash\": {         \"bytes\": \"wXdD4Iy50RaWzPp7n9s1xwf4K4MB8eA1nmhPquTMvxg=\",         \"offset\": 0,         \"size\": 32       }     },     {       \"type\": \"Contract CorDapp\",       \"name\": \"contracts-1.0\",       \"shortName\": \"Obligation Contracts\",       \"minimumPlatformVersion\": 8,       \"targetPlatformVersion\": 8,       \"version\": \"1\",       \"vendor\": \"Corda Open Source\",       \"licence\": \"Apache License, Version 2.0\",       \"jarHash\": {         \"bytes\": \"grTZzN71Cpxw6rZe/U5SB6/ehl99B6VQ1+ZJEx1rixs=\",         \"offset\": 0,         \"size\": 32       }     }   ] }</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-corda/#monitoring","title":"Monitoring","text":""},{"location":"cactus/packages/cactus-plugin-ledger-connector-corda/#usage-prometheus","title":"Usage Prometheus","text":"<p>The prometheus exporter object is initialized in the <code>PluginLedgerConnectorCorda</code> class constructor itself, so instantiating the object of the <code>PluginLedgerConnectorCorda</code> class, gives access to the exporter object. You can also initialize the prometheus exporter object seperately and then pass it to the <code>IPluginLedgerConnectorCordaOptions</code> interface for <code>PluginLedgerConnectoCorda</code> constructor.</p> <p><code>getPrometheusExporterMetricsEndpointV1</code> function returns the prometheus exporter metrics, currently displaying the total transaction count, which currently increments everytime the <code>transact()</code> method of the <code>PluginLedgerConnectorCorda</code> class is called.</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-corda/#prometheus-integration","title":"Prometheus Integration","text":"<p>To use Prometheus with this exporter make sure to install Prometheus main component. Once Prometheus is setup, the corresponding scrape_config needs to be added to the prometheus.yml</p> <p>- job_name: 'corda_ledger_connector_exporter'   metrics_path: api/v1/plugins/hyperledger/cactus-plugin-ledger-connector-corda/get-prometheus-exporter-metrics   scrape_interval: 5s   static_configs:     - targets: ['{host}:{port}']</p> <p>Here the <code>host:port</code> is where the prometheus exporter metrics are exposed. An example URL for metric would be something like this: <code>http://localhost:42379/api/v1/plugins/@hyperledger/cactus-plugin-ledger-connector-corda/get-prometheus-exporter-metrics</code></p> <p>Once edited, you can start the prometheus service by referencing the above edited prometheus.yml file. On the prometheus graphical interface (defaulted to http://localhost:9090), choose Graph from the menu bar, then select the Console tab. From the Insert metric at cursor drop down, select cactus_corda_total_tx_count and click execute</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-corda/#helper-code","title":"Helper code","text":""},{"location":"cactus/packages/cactus-plugin-ledger-connector-corda/#responsetypets","title":"response.type.ts","text":"<p>This file contains the various responses of the metrics.</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-corda/#data-fetcherts","title":"data-fetcher.ts","text":"<p>This file contains functions encasing the logic to process the data points</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-corda/#metricsts","title":"metrics.ts","text":"<p>This file lists all the prometheus metrics and what they are used for.</p> <p>Previous Next</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-fabric/","title":"<code>@hyperledger/cactus-plugin-ledger-connector-fabric</code>","text":""},{"location":"cactus/packages/cactus-plugin-ledger-connector-fabric/#1-usage","title":"1. Usage","text":"<p>This plugin provides a way to interact with Fabric networks. Using this one can perform:</p> <ul> <li> <p>Deploy smart contracts (chaincode).</p> </li> <li> <p>Execute transactions on the ledger.</p> </li> <li> <p>Invoke chaincode functions.</p> </li> </ul> <p>The above functionality can either be accessed by importing the plugin directly as a library (embedding) or by hosting it as a REST API through the Cactus API server</p> <p>We also publish the Cactus API server as a container image to the GitHub Container Registry that you can run easily with a one liner. The API server is also embeddable in your own NodeJS project if you choose to do so.</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-fabric/#11-installation","title":"1.1. Installation","text":"<p>npm</p> <p>npm install hyperledger/cactus-plugin-ledger-connector-fabric</p> <p>yarn</p> <p>yarn add hyperledger/cactus-plugin-ledger-connector-fabric</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-fabric/#12-using-as-a-library","title":"1.2. Using as a Library","text":"<p>import {   PluginLedgerConnectorFabric,   DefaultEventHandlerStrategy, } from \"hyperledger/cactus-plugin-ledger-connector-fabric\";</p> <p>const plugin = new PluginLedgerConnectorFabric({   // See test cases for exact details on what parameters are needed });</p> <p>const req: RunTransactionRequest = {   // See tests for specific examples on request properties };</p> <p>try {   const res = await plugin.transact(req); } catch (ex: Error) {   // Make sure to handle errors gracefully (which is dependent on your use-case)   console.error(ex);   throw ex; }</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-fabric/#13-using-via-the-api-client","title":"1.3. Using Via The API Client","text":"<p>Prerequisites</p> <ul> <li> <p>A running Fabric ledger (network)</p> </li> <li> <p>You have a running Cactus API server on <code>$HOST:$PORT</code> with the Fabric connector plugin installed on it (and the latter configured to have access to the Fabric ledger from point 1)</p> </li> </ul> <p>import {   PluginLedgerConnectorFabric,   DefaultApi as FabricApi,   DefaultEventHandlerStrategy, } from \"hyperledger/cactus-plugin-ledger-connector-fabric\";</p> <p>// Step zero is to deploy your Fabric ledger and the Cactus API server const apiUrl = `https://\\({HOST}:\\)`;</p> <p>const config = new Configuration({ basePath: apiUrl });</p> <p>const apiClient = new FabricApi(config);</p> <p>const req: RunTransactionRequest = {   // See tests for specific examples on request properties };</p> <p>try {   const res = await apiClient.runTransactionV1(req); } catch (ex: Error) {   // Make sure to handle errors gracefully (which is dependent on your use-case)   console.error(ex);   throw ex; }</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-fabric/#14-signing-credentials-with-hashicorp-vault","title":"1.4. Signing Credentials with Hashicorp Vault","text":"<p>To support signing of message with multiple identity types</p> <p>// vault server config for supporting vault identity provider const vaultConfig:IVaultConfig = {   endpoint : \"http://localhost:8200\",   transitEngineMountPath: \"/transit\", } // web-socket server config for supporting vault identity provider const webSocketConfig:IVaultConfig = {   server: socketServer as FabricSocketServer } // provide list of identity signing to be supported const supportedIdentity:FabricSigningCredentialType[] = [FabricSigningCredentialType.VaultX509,FabricSigningCredentialType.WsX509,FabricSigningCredentialType.X509] const pluginOptions:IPluginLedgerConnectorFabricOptions = {   // other options   vaultConfig : vaultConfig,   webSocketConfig : webSocketConfig,   supportedIdentity:supportedIdentity   // .. other options } const connector: PluginLedgerConnectorFabric = new PluginLedgerConnectorFabric(pluginOptions);</p> <p>To enroll an identity</p> <p>await connector.enroll(         {           keychainId: \"keychain-identifier-for storing-certData\",           keychainRef: \"cert-data-identifier\",</p> <pre><code>      // require in case of vault\n      type: FabricSigningCredentialType.VaultX509, // FabricSigningCredentialType.X509\n      vaultTransitKey: {\n        token: \"vault-token\",\n        keyName: \"vault-key-label\",\n      },\n      // required in case of web-socket server\n      type: FabricSigningCredentialType.WsX509,\n      webSocketKey: {\n        signature: signature,\n        sessionId: sessionId,\n      },\n    },\n    {\n      enrollmentID: \"client2\",\n      enrollmentSecret: \"pw\",\n      mspId: \"Org1MSP\",\n      caId: \"ca.org1.example.com\",\n    },\n  );\n</code></pre> <p>To Register an identity using register\u2019s key</p> <p>const secret = await connector.register(         {           keychainId: \"keychain-id-that-store-certData-of-registrar\",           keychainRef: \"certData-label\",</p> <pre><code>      // require in case of vault\n      type: FabricSigningCredentialType.VaultX509, // FabricSigningCredentialType.X509\n      vaultTransitKey: {\n        token: testToken,\n        keyName: registrarKey,\n      },\n      // required in case of web-socket server\n      type: FabricSigningCredentialType.WsX509,\n      webSocketKey: {\n        signature: signature,\n        sessionId: sessionId,\n      },\n    },\n    {\n      enrollmentID: \"client-enrollmentID\",\n      enrollmentSecret: \"pw\",\n      affiliation: \"org1.department1\",\n    },\n    \"ca.org1.example.com\", // caID\n  );\n</code></pre> <p>To transact with fabric</p> <p>const resp = await connector.transact{   signingCredential: {           keychainId: keychainId,           keychainRef: \"client-certData-id\",</p> <pre><code>      // require in case of vault\n      type: FabricSigningCredentialType.VaultX509, // FabricSigningCredentialType.X509\n      vaultTransitKey: {\n        token: testToken,\n        keyName: registrarKey,\n      },\n      // required in case of web-socket server\n      type: FabricSigningCredentialType.WsX509,\n      webSocketKey: {\n        signature: signature,\n        sessionId: sessionId,\n      },\n    },\n    // .. other options\n</code></pre> <p>}</p> <p>To Rotate the key</p> <p>await connector.rotateKey(   {         keychainId: keychainId,         keychainRef: \"client-certData-id\",         type: FabricSigningCredentialType.VaultX509, // FabricSigningCredentialType.X509</p> <pre><code>    // require in case of vault\n    vaultTransitKey: {\n      token: testToken,\n      keyName: registrarKey,\n    },\n    // key rotation currently not available using web-socket server\n    // web-socket connection not used to manages external keys\n    // user should re-enroll with new pub/priv key pair\n</code></pre> <p>},   {       enrollmentID: string;       enrollmentSecret: string;       caId: string;   } )</p> <p>Extensive documentation and examples in the readthedocs (WIP)</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-fabric/#141-identity-providers","title":"1.4.1. Identity Providers","text":"<p>Identity providers allows client to manage their private more effectively and securely. Cactus Fabric Connector support multiple type of providers. Each provider differ based upon where the private are stored. On High level certificate credential are stored as</p> <p>{   type: FabricSigningCredentialType;   credentials: {     certificate: string;     // if identity type is IdentityProvidersType.X509     privateKey?: string;   };   mspId: string; }</p> <p>Currently Cactus Fabric Connector supports following Identity Providers</p> <ul> <li> <p>X509 : Simple and unsecured provider wherein <code>private</code> key is stored along with certificate in some <code>datastore</code>. Whenever connector require signature on fabric message, private key is brought from the <code>datastore</code> and message signed at the connector.</p> </li> <li> <p>Vault-X.509 : Secure provider wherein <code>private</code> key is stored with vault\u2019s transit transit engine and certificate in <code>certDatastore</code>. Rather then bringing the key to the connector, message digest are sent to the vault server which returns the <code>signature</code>.</p> </li> <li> <p>WS-X.509 : Secure provider wherein <code>private</code> key is stored with <code>client</code> and certificate in <code>certDatastore</code>. To get the fabric messages signed, message digest is sent to the client via <code>webSocket</code> connection opened by the client in the beginning (as described above)</p> </li> </ul>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-fabric/#142-setting-up-a-ws-x509-provider","title":"1.4.2. Setting up a WS-X.509 provider","text":"<p>The following packages are used to access private keys (via web-socket) stored on a clients external device (e.g., browser, mobile app, or an IoT device\u2026). -ws-identity: web-socket server that issues new ws-session tickets, authenticates incoming connections, and sends signature requests -ws-identity-client: backend connector to send requests from fabric application to ws-identity -ws-wallet: external clients crypto key tool: create new key pair, request session ticket and open web-socket connection with ws-identity</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-fabric/#143-building-the-ws-identity-docker-image","title":"1.4.3. Building the ws-identity docker image","text":"<p>TBD</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-fabric/#15-monitoring-new-blocks-watchblocks","title":"1.5 Monitoring new blocks (WatchBlocks)","text":"<ul> <li> <p>Use <code>ApiClient</code> to receive new blocks from a fabric ledger.</p> </li> <li> <p>Type of the response can be configured.</p> </li> <li> <p>Credentials must be configured using <code>gatewayOptions</code> argument (you can either send them directly in request or use wallet stored in keychain).</p> </li> </ul>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-fabric/#151-example","title":"1.5.1 Example","text":"<p>For more detailed example check fabric-watch-blocks-v1-endpoint.test.ts</p> <p>// Setup const signingCredential = {   keychainId: uuidv4(),   keychainRef: \"user2\", };</p> <p>// Create RxJS Observable. // This will connect to the fabric connector and start the monitoring operation. const watchObservable = apiClient.watchBlocksV1({   channelName: \"mychannel\", // fabric channel name   gatewayOptions: { // use signing credential from keychain     identity: signingCredential.keychainRef,     wallet: {       keychain: signingCredential,     },   },   WatchBlocksListenerTypeV1.Full, // return full block data });</p> <p>// Subscribe to the observable to receive new blocks const subscription = watchObservable.subscribe({   next(event) {     // Handle new event   },   error(err) {     // Handle error from connector   }, });</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-fabric/#152-listener-type","title":"1.5.2 Listener Type","text":"<p>There are two types of listener type - original and cactus ones.</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-fabric/#original","title":"Original","text":"<p>Corresponds directly to <code>BlockType</code> from <code>fabric-common</code>:</p> <ul> <li> <p><code>WatchBlocksListenerTypeV1.Filtered</code>,</p> </li> <li> <p><code>WatchBlocksListenerTypeV1.Full</code>,</p> </li> <li> <p><code>WatchBlocksListenerTypeV1.Private</code>,</p> </li> </ul>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-fabric/#cactus-custom","title":"Cactus (custom)","text":"<p>Parses the data and returns custom formatted block.</p> <ul> <li><code>WatchBlocksListenerTypeV1.CactusTransactions</code>: Returns transactions summary. Compatible with legacy <code>fabric-socketio</code> monitoring operation.</li> </ul>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-fabric/#2-architecture","title":"2. Architecture","text":"<p>The sequence diagrams for various endpoints are mentioned below</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-fabric/#21-run-transaction-endpoint","title":"2.1. run-transaction-endpoint","text":"<p>The above diagram shows the sequence diagram of run-transaction-endpoint. User A (One of the many Users) interacts with the API Client which in turn, calls the API server. API server then executes transact() method which is explained in detailed in the subsequent diagram.</p> <p></p> <p>The above diagram shows the sequence diagram of transact() method of the PluginLedgerConnectorFabric class. The caller to this function, which in reference to the above sequence diagram is API server, sends RunTransactionRequest object as an argument to the transact() method. Based on the invocationType (FabricContractInvocationType.CALL, FabricCOntractInvocationType.SEND), corresponding responses are send back to the caller.</p> <p></p> <p>The above diagram shows the sequence diagram of enroll() method of the PluginLedgerConnectorFabric class. The caller to this function, which in reference to the above sequence diagram is API server, sends Signer object along with EnrollmentRequest as an argument to the enroll() method. Based on the singerType (FabricSigningCredentialType.X509, FabricSigningCredentialType.VaultX509, FabricSigningCredentialType.WsX509), corresponding identity is enrolled and stored inside keychain.</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-fabric/#3-containerization","title":"3. Containerization","text":""},{"location":"cactus/packages/cactus-plugin-ledger-connector-fabric/#31-buildingrunning-the-container-image-locally","title":"3.1. Building/running the container image locally","text":"<p>In the Cactus project root say:</p> <p>DOCKER_BUILDKIT=1 docker build -f ./packages/cactus-plugin-ledger-connector-fabric/Dockerfile . -t cplcb</p> <p>Build with a specific version of the npm package:</p> <p>DOCKER_BUILDKIT=1 docker build --build-arg NPM_PKG_VERSION=0.4.1 -f ./packages/cactus-plugin-ledger-connector-fabric/Dockerfile . -t cplcb</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-fabric/#32-running-the-container","title":"3.2. Running the container","text":"<p>Launch container with plugin configuration as an environment variable:</p> <p>docker run \\   --rm \\   --publish 3000:3000 \\   --publish 4000:4000 \\   --env PLUGINS='[{\"packageName\": \"hyperledger/cactus-plugin-ledger-connector-fabric\", \"type\": \"org.hyperledger.cactus.plugin_import_type.LOCAL\", \"action\": \"org.hyperledger.cactus.plugin_import_action.INSTALL\",  \"options\": {\"instanceId\": \"some-unique-fabric-connector-instance-id\", \"dockerBinary\": \"usr/local/bin/docker\",\"cliContainerEnv\": {     \"CORE_PEER_LOCALMSPID\": \"Org1MSP\",     \"CORE_PEER_ADDRESS\": \"peer0.org1.example.com:7051\",     \"CORE_PEER_MSPCONFIGPATH\":       \"/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp\",     \"CORE_PEER_TLS_ROOTCERT_FILE\":       \"/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt\",     \"ORDERER_TLS_ROOTCERT_FILE\":       \"/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem\"   },   \"discoveryOptions\": {     \"enabled\": true,     \"asLocalhost\": true   }   }}}]' \\   cplcb</p> <p>Launch container with plugin configuration as a CLI argument:</p> <p>docker run \\   --rm \\   --publish 3000:3000 \\    --publish 4000:4000 \\   cplcb \\     ./node_modules/.bin/cactusapi \\     --plugins='[{\"packageName\": \"hyperledger/cactus-plugin-ledger-connector-fabric\", \"type\": \"org.hyperledger.cactus.plugin_import_type.LOCAL\", \"action\": \"org.hyperledger.cactus.plugin_import_action.INSTALL\",  \"options\": {\"instanceId\": \"some-unique-fabric-connector-instance-id\", \"dockerBinary\": \"usr/local/bin/docker\",\"cliContainerEnv\": {     \"CORE_PEER_LOCALMSPID\": \"Org1MSP\",     \"CORE_PEER_ADDRESS\": \"peer0.org1.example.com:7051\",     \"CORE_PEER_MSPCONFIGPATH\":       \"/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp\",     \"CORE_PEER_TLS_ROOTCERT_FILE\":       \"/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt\",     \"ORDERER_TLS_ROOTCERT_FILE\":       \"/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem\"   },   \"discoveryOptions\": {     \"enabled\": true,     \"asLocalhost\": true   }   }}}]'</p> <p>Launch container with configuration file mounted from host machine:</p> <p>echo '[{\"packageName\": \"hyperledger/cactus-plugin-ledger-connector-fabric\", \"type\": \"org.hyperledger.cactus.plugin_import_type.LOCAL\", \"action\": \"org.hyperledger.cactus.plugin_import_action.INSTALL\",  \"options\": {\"instanceId\": \"some-unique-fabric-connector-instance-id\", \"dockerBinary\": \"usr/local/bin/docker\",\"cliContainerEnv\": {     \"CORE_PEER_LOCALMSPID\": \"Org1MSP\",     \"CORE_PEER_ADDRESS\": \"peer0.org1.example.com:7051\",     \"CORE_PEER_MSPCONFIGPATH\":       \"/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp\",     \"CORE_PEER_TLS_ROOTCERT_FILE\":       \"/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt\",     \"ORDERER_TLS_ROOTCERT_FILE\":       \"/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem\"   },   \"discoveryOptions\": {     \"enabled\": true,     \"asLocalhost\": true   }   }}}]' &gt; cactus.json</p> <p>docker run \\   --rm \\   --publish 3000:3000 \\   --publish 4000:4000 \\   --mount type=bind,source=\"$(pwd)\"/cactus.json,target=/cactus.json \\   cplcb \\     ./node_modules/.bin/cactusapi \\     --config-file=/cactus.json</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-fabric/#33-testing-api-calls-with-the-container","title":"3.3. Testing API calls with the container","text":"<p>Don\u2019t have a fabric network on hand to test with? Test or develop against our fabric All-In-One container!</p> <p>Terminal Window 1 (Ledger)</p> <p>docker run --privileged -p 0.0.0.0:8545:8545/tcp  -p 0.0.0.0:8546:8546/tcp  -p 0.0.0.0:8888:8888/tcp  -p 0.0.0.0:9001:9001/tcp  -p 0.0.0.0:9545:9545/tcp ghcr.io/hyperledger/cactus-fabric-all-in-one:v1.0.0-rc.2</p> <p>Terminal Window 2 (Cactus API Server)</p> <p>docker run \\   --network host \\   --rm \\   --publish 3000:3000 \\   --publish 4000:4000 \\   --env PLUGINS='[{\"packageName\": \"hyperledger/cactus-plugin-ledger-connector-fabric\", \"type\": \"org.hyperledger.cactus.plugin_import_type.LOCAL\", \"action\": \"org.hyperledger.cactus.plugin_import_action.INSTALL\",  \"options\": {\"instanceId\": \"some-unique-fabric-connector-instance-id\", \"dockerBinary\": \"usr/local/bin/docker\",\"cliContainerEnv\": {     \"CORE_PEER_LOCALMSPID\": \"Org1MSP\",     \"CORE_PEER_ADDRESS\": \"peer0.org1.example.com:7051\",     \"CORE_PEER_MSPCONFIGPATH\":       \"/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp\",     \"CORE_PEER_TLS_ROOTCERT_FILE\":       \"/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt\",     \"ORDERER_TLS_ROOTCERT_FILE\":       \"/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem\"   },   \"discoveryOptions\": {     \"enabled\": true,     \"asLocalhost\": true   }   }}}]' \\   cplcb</p> <p>Terminal Window 3 (curl - replace eth accounts as needed)</p> <p>curl --location --request POST 'http://127.0.0.1:4000/api/v1/plugins/@hyperledger/cactus-plugin-ledger-connector-fabric/run-transaction' \\ --header 'Content-Type: application/json' \\ --data-raw '{     channelName: \"mychannel\",     contractName: \"contract-example\";     invocationType: \"FabricContractInvocationType.SEND\";     methodName: \"example\" }'</p> <p>The above should produce a response that looks similar to this:</p> <p>{     \"success\": true,     \"data\": {         \"transactionReceipt\": {             \"blockHash\": \"0x7c97c038a5d3bd84613fe23ed442695276d5d2df97f4e7c4f10ca06765033ffd\",             \"blockNumber\": 1218,             \"contractAddress\": null,             \"cumulativeGasUsed\": 21000,             \"from\": \"0x627306090abab3a6e1400e9345bc60c78a8bef57\",             \"gasUsed\": 21000,             \"logs\": [],             \"logsBloom\": \"0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\",             \"status\": true,             \"to\": \"0xf17f52151ebef6c7334fad080c5704d77216b732\",             \"transactionHash\": \"0xc7fcb46c735bdc696d500bfc70c72595a2b8c31813929e5c61d9a5aec3376d6f\",             \"transactionIndex\": 0         }     } }</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-fabric/#4-prometheus-exporter","title":"4. Prometheus Exporter","text":"<p>This class creates a prometheus exporter, which scraps the transactions (total transaction count) for the use cases incorporating the use of Fabric connector plugin.</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-fabric/#41-usage-prometheus","title":"4.1. Usage Prometheus","text":"<p>The prometheus exporter object is initialized in the <code>PluginLedgerConnectorFabric</code> class constructor itself, so instantiating the object of the <code>PluginLedgerConnectorFabric</code> class, gives access to the exporter object. You can also initialize the prometheus exporter object seperately and then pass it to the <code>IPluginLedgerConnectorFabricOptions</code> interface for <code>PluginLedgerConnectoFabric</code> constructor.</p> <p><code>getPrometheusExporterMetricsEndpointV1</code> function returns the prometheus exporter metrics, currently displaying the total transaction count, which currently increments everytime the <code>transact()</code> method of the <code>PluginLedgerConnectorFabric</code> class is called.</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-fabric/#42-prometheus-integration","title":"4.2. Prometheus Integration","text":"<p>To use Prometheus with this exporter make sure to install Prometheus main component. Once Prometheus is setup, the corresponding scrape_config needs to be added to the prometheus.yml</p> <p>- job_name: 'fabric_ledger_connector_exporter'   metrics_path: api/v1/plugins/hyperledger/cactus-plugin-ledger-connector-fabric/get-prometheus-exporter-metrics   scrape_interval: 5s   static_configs:     - targets: ['{host}:{port}']</p> <p>Here the <code>host:port</code> is where the prometheus exporter metrics are exposed. The test cases (For example, <code>packages/cactus-plugin-ledger-connector-fabric/src/test/typescript/integration/fabric-v2-2-x/run-transaction-endpoint-v1.test.ts</code>) exposes it over <code>0.0.0.0</code> and a random port(). The random port can be found in the running logs of the test case and looks like (42379 in the below mentioned URL) <code>Metrics URL: http://0.0.0.0:42379/api/v1/plugins/@hyperledger/cactus-plugin-ledger-connector-fabric/get-prometheus-exporter-metrics</code></p> <p>Once edited, you can start the prometheus service by referencing the above edited prometheus.yml file. On the prometheus graphical interface (defaulted to http://localhost:9090), choose Graph from the menu bar, then select the Console tab. From the Insert metric at cursor drop down, select cactus_fabric_total_tx_count and click execute</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-fabric/#43-helper-code","title":"4.3. Helper code","text":""},{"location":"cactus/packages/cactus-plugin-ledger-connector-fabric/#431-responsetypets","title":"4.3.1. response.type.ts","text":"<p>This file contains the various responses of the metrics.</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-fabric/#432-data-fetcherts","title":"4.3.2. data-fetcher.ts","text":"<p>This file contains functions encasing the logic to process the data points</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-fabric/#433-metricsts","title":"4.3.3. metrics.ts","text":"<p>This file lists all the prometheus metrics and what they are used for.</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-fabric/#5-contributing","title":"5. Contributing","text":"<p>We welcome contributions to Hyperledger Cactus in many forms, and there\u2019s always plenty to do!</p> <p>Please review CONTRIBUTING.md to get started.</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-fabric/#6-license","title":"6. License","text":"<p>This distribution is published under the Apache License Version 2.0 found in the LICENSE file.</p>"},{"location":"cactus/packages/cactus-plugin-ledger-connector-fabric/#7-acknowledgments","title":"7. Acknowledgments","text":"<p>Previous Next</p>"},{"location":"cactus/packages/cactus-test-api-client/","title":"<code>@hyperledger/cactus-test-api-client</code>","text":"<p>This is the test package for the package that\u2019s called <code>cactus-api-client</code></p>"},{"location":"cactus/packages/cactus-test-api-client/#usage","title":"Usage","text":"<p>// TODO: DEMONSTRATE API</p>"},{"location":"cactus/packages/cactus-test-api-client/#faq","title":"FAQ","text":""},{"location":"cactus/packages/cactus-test-api-client/#what-is-a-dedicated-test-package-for","title":"What is a dedicated test package for?","text":"<p>This is a dedicated test package meaning that it verifies the integration between two packages that are somehow dependent on each other and therefore these tests cannot be added properly in the child package due to circular dependency issues and it would not be fitting to add it in the parent because the child package\u2019s tests should not be held by the parent as a matter of principle.</p> <p>Previous Next</p>"},{"location":"cactus/packages/cactus-test-cmd-api-server/","title":"<code>@hyperledger/cactus-test-cmd-api-server</code>","text":"<p>This is the test package for the package that\u2019s called <code>cactus-cmd-api-server</code></p>"},{"location":"cactus/packages/cactus-test-cmd-api-server/#usage","title":"Usage","text":"<p>// TODO: DEMONSTRATE API</p>"},{"location":"cactus/packages/cactus-test-cmd-api-server/#faq","title":"FAQ","text":""},{"location":"cactus/packages/cactus-test-cmd-api-server/#what-is-a-dedicated-test-package-for","title":"What is a dedicated test package for?","text":"<p>This is a dedicated test package meaning that it verifies the integration between two packages that are somehow dependent on each other and therefore these tests cannot be added properly in the child package due to circular dependency issues and it would not be fitting to add it in the parent because the child package\u2019s tests should not be held by the parent as a matter of principle.</p> <p>Previous Next</p>"},{"location":"cactus/packages/cactus-test-tooling/","title":"<code>@hyperledger/cactus-test-tooling</code>","text":"<p>TODO: description</p>"},{"location":"cactus/packages/cactus-test-tooling/#usage","title":"Usage","text":"<p>// TODO: DEMONSTRATE API</p>"},{"location":"cactus/packages/cactus-test-tooling/#docker-image-for-the-ws-identity-server","title":"Docker image for the ws-identity server","text":"<p>A docker image of the ws-identity server is used to test integration of WS-X.509 credential type in the fabric connector plugin.</p> <p>ws-identity includes A Docker file to build the image: clone the repo, install packages, build src and the image</p> <p>npm install npm run build docker build . -t [image-name]</p> <p>Previous Next</p>"},{"location":"cactus/support/besu/","title":"Besu Support","text":"<p>Note</p> <p>The deployContract feature is for development and test case authoring only, not recommended to be used in production environments for managing smart contracts.</p> <p>Hyperledger Cactus v0.9.0</p> <p>Besu version</p> <p>deployContract*</p> <p>invokeContract</p> <p>runTransaction</p> <p>Besu 21.1.6 and Orion 21.1.1</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>Besu 1.5.1 and Orion 1.6</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>Hyperledger Cactus v0.8.0</p> <p>Besu version</p> <p>deployContract*</p> <p>invokeContract</p> <p>runTransaction</p> <p>Besu 1.5.1 and Orion 1.6</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>Hyperledger Cactus v0.7.0</p> <p>Besu version</p> <p>deployContract*</p> <p>invokeContract</p> <p>runTransaction</p> <p>Besu 1.5.1 and Orion 1.6</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>Hyperledger Cactus v0.6.0</p> <p>Besu version</p> <p>deployContract*</p> <p>invokeContract</p> <p>runTransaction</p> <p>Besu 1.5.1 and Orion 1.6</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>Hyperledger Cactus v0.5.0</p> <p>Besu version</p> <p>deployContract*</p> <p>invokeContract</p> <p>runTransaction</p> <p>Besu 1.5.1 and Orion 1.6</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>Hyperledger Cactus v0.4.1</p> <p>Besu version</p> <p>deployContract*</p> <p>invokeContract</p> <p>runTransaction</p> <p>Besu 1.5.1 and Orion 1.6</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>Previous Next</p>"},{"location":"cactus/support/corda/","title":"Corda Support","text":"<p>Note</p> <p>The deployContract feature is for development and test case authoring only, not recommended to be used in production environments for managing smart contracts.</p> <p>Hyperledger Cactus v0.9.0</p> <p>Corda version</p> <p>deployContract*</p> <p>invokeContract</p> <p>runTransaction</p> <p>Corda 4.8</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>Corda 4.7</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>Corda 4.5</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>Previous Next</p>"},{"location":"cactus/support/fabric/","title":"Fabric Support","text":"<p>Note</p> <p>The deployContract feature is for development and test case authoring only, not recommended to be used in production environments for managing smart contracts.</p> <p>Hyperledger Cactus v0.9.0</p> <p>Fabric version</p> <p>deployContract*</p> <p>invokeContract</p> <p>runTransaction</p> <p>Fabric 2.2.0</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>Fabric 1.4.8</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>Hyperledger Cactus v0.8.0</p> <p>Fabric version</p> <p>deployContract*</p> <p>invokeContract</p> <p>runTransaction</p> <p>Fabric 2.2.0</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>Hyperledger Cactus v0.7.0</p> <p>Fabric version</p> <p>deployContract*</p> <p>invokeContract</p> <p>runTransaction</p> <p>Fabric 2.2.0</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>Hyperledger Cactus v0.6.0</p> <p>Fabric version</p> <p>deployContract*</p> <p>invokeContract</p> <p>runTransaction</p> <p>Fabric 2.2.0</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>Hyperledger Cactus v0.5.0</p> <p>Fabric version</p> <p>deployContract*</p> <p>invokeContract</p> <p>runTransaction</p> <p>Fabric 2.2.0</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>Hyperledger Cactus v0.4.1</p> <p>Fabric version</p> <p>deployContract*</p> <p>invokeContract</p> <p>runTransaction</p> <p>Fabric 2.2.0</p> <p>\u274c</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>Previous Next</p>"},{"location":"cactus/support/substrate/","title":"Substrate Support","text":"<pre><code>Substrate chains include Polkadot, Kusama, Rococco, etc. The deployContract feature is for development and test case authoring only, not recommended to be used in production environments for managing smart contracts.\n</code></pre> Hyperledger Cactus v1.0.0-rc3    | Substrate API version | deployContract* | invokeContract | runTransaction |   | --- | :---: | :---: | :---: |   | @polkadot/api 10.9.1 | \u2705 [test]() | \u2705 [test]() | \u2705 [test]() |   <p>Previous</p>"},{"location":"cactus/support/xdai/","title":"xDai Support","text":"<p>Note</p> <p>The deployContract feature is for development and test case authoring only, not recommended to be used in production environments for managing smart contracts.</p> <p>Hyperledger Cactus v0.9.0</p> <p>xDai version</p> <p>deployContract*</p> <p>invokeContract</p> <p>runTransaction</p> <p>xDai 1.8.27</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>Hyperledger Cactus v0.8.0</p> <p>xDai version</p> <p>deployContract*</p> <p>invokeContract</p> <p>runTransaction</p> <p>xDai 1.8.27</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>Hyperledger Cactus v0.7.0</p> <p>xDai version</p> <p>deployContract*</p> <p>invokeContract</p> <p>runTransaction</p> <p>xDai 1.8.27</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>Hyperledger Cactus v0.6.0</p> <p>xDai version</p> <p>deployContract*</p> <p>invokeContract</p> <p>runTransaction</p> <p>xDai 1.8.27</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>Hyperledger Cactus v0.5.0</p> <p>xDai version</p> <p>deployContract*</p> <p>invokeContract</p> <p>runTransaction</p> <p>xDai 1.8.27</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>\u2705 test</p> <p>Hyperledger Cactus v0.4.1</p> <p>xDai version</p> <p>deployContract*</p> <p>invokeContract</p> <p>runTransaction</p> <p>xDai 1.8.27</p> <p>\u274c</p> <p>\u274c</p> <p>\u274c</p> <p>Previous Next</p>"},{"location":"concepts/data-sharing/","title":"Data Sharing","text":"<p>This is a basic interoperability mode or use case pattern. Here is a description.</p>"},{"location":"contributing/asking-a-question/","title":"Asking a Question","text":"<p>Tip</p> <ul> <li>check the FAQs to see if your question has already been asked.</li> <li>make sure you provide all relevant details.</li> <li>include information about what you have already tried.</li> <li>review How to Ask Technical Questions to Get Quality Answers prior to asking your question.</li> </ul>"},{"location":"contributing/asking-a-question/#chat","title":"Chat","text":"<p>Hyperledger\u2019s Discord server is the place to go for real-time chat about everything from quick help to involved discussions.</p> <p>For general Hyperledger Cacti discussions, join the Discord server and visit #Cacti.</p>"},{"location":"contributing/asking-a-question/#mailing-lists","title":"Mailing Lists","text":"<p>The Hyperledger Cacti mailing list is hosted by the Hyperledger Foundation: https://lists.hyperledger.org. </p>"},{"location":"contributing/how-to-contribute/","title":"How to Contribute","text":"<p>The Hyperledger Cacti repository contains specific instructions for contributing to that project.</p> <p>In this section, you will find generic instructions and guidelines for contributing to any Hyperledger project.</p>"},{"location":"contributing/how-to-contribute/#ways-to-contribute","title":"Ways to Contribute","text":"<p>Contributions from the development community help improve the capabilities of Hyperledger Cacti. These contributions are the most effective way to make a positive impact on the project.</p> <p>Ways you can contribute:</p> <ul> <li>Bugs or issues: Report problems or defects found when working with the project (see Reporting a Bug)</li> <li>Core features and enhancements: Provide expanded capabilities or optimizations</li> <li>Documentation: Improve existing documentation or create new information</li> <li>Tests: Add functional, performance, or scalability tests</li> </ul> <p>Issues can be found in GitHub. Any unassigned items are probably still open. When in doubt, ask on Discord about a specific issue (see Asking a Question). We also use the #good-first-issue tag to represent issues that might be good for first timers.</p>"},{"location":"contributing/how-to-contribute/#the-commit-process","title":"The Commit Process","text":"<p>Hyperledger Cacti is Apache 2.0 licensed and accepts contributions via GitHub pull requests. When contributing code, please follow these guidelines:</p> <ul> <li>Fork the repository and make your changes in a feature branch</li> <li>Include unit and integration tests for any new features and updates to existing tests</li> <li>Ensure that the unit and integration tests run successfully prior to submitting the pull request.</li> </ul>"},{"location":"contributing/how-to-contribute/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>A pull request can contain a single commit or multiple commits. The most important guideline is that a single commit should map to a single fix or enhancement. Here are some example scenarios:</p> <ul> <li>If a pull request adds a feature but also fixes two bugs, the pull request should have three commits: one commit for the feature change and two commits for the bug fixes.</li> <li>If a PR is opened with five commits that contain changes to fix a single issue, the PR should be rebased to a single commit.</li> <li>If a PR is opened with several commits, where the first commit fixes one issue and the rest fix a separate issue, the PR should be rebased to two commits (one for each issue).</li> </ul> <p>Important</p> <p>Your pull request should be rebased against the current main branch. Do not merge the current main branch in with your topic branch. Do not use the Update Branch button provided by GitHub on the pull request page.</p>"},{"location":"contributing/how-to-contribute/#commit-messages","title":"Commit Messages","text":"<p>Commit messages should follow common Git conventions, such as using the imperative mood, separate subject lines, and a line length of 72 characters.  These rules are well documented in Chris Beam's blog post.</p>"},{"location":"contributing/how-to-contribute/#signed-off-by","title":"Signed-off-by","text":"<p>Each commit must include a \"Signed-off-by\" line in the commit message (<code>git commit -s</code>). This sign-off indicates that you agree the commit satisfies the Developer Certificate of Origin (DCO).</p>"},{"location":"contributing/how-to-contribute/#commit-email-address","title":"Commit Email Address","text":"<p>Your commit email address must match your GitHub email address. For more information, see https://help.github.com/articles/setting-your-commit-email-address-in-git/</p>"},{"location":"contributing/how-to-contribute/#important-github-requirements","title":"Important GitHub Requirements","text":"<p>A pull request cannot merged until it has passed these status checks:</p> <ul> <li>The build must pass all checks</li> <li>The PR must be approved by at least two reviewers without any   outstanding requests for changes</li> </ul>"},{"location":"contributing/how-to-contribute/#inclusive-language","title":"Inclusive Language","text":"<ul> <li>Consider that users who will read the source code and documentation are from different background and cultures and that they have different preferences.</li> <li>Avoid potential offensive terms and, for instance, prefer \"allow list and deny list\" to \"white list and black list\".</li> <li>We believe that we all have a role to play to improve our world, and even if writing inclusive code and documentation might not look like a huge improvement, it's a first step in the right direction.</li> <li>We suggest to refer to Microsoft bias free writing guidelines and Google inclusive doc writing guide as starting points.</li> </ul>"},{"location":"contributing/how-to-contribute/#credits","title":"Credits","text":"<p>This document is based on Hyperledger Sawtooth's Contributing documentation.</p>"},{"location":"contributing/reporting-a-bug/","title":"Reporting a Bug","text":"<p>To report a bug, submit an issue in our public issue tracker.</p> <p>When reporting an issue, please provide as much detail as possible about how to reproduce it. If possible, explain how to reproduce the issue. Details are very helpful. Please include the following information:</p> <ul> <li>Operating system and version (if Mac, include the processor)</li> <li>Project version</li> <li>Environment details (virtual, physical, etc.)</li> <li>Steps to reproduce the issue</li> <li>Actual results</li> <li>Expected results</li> </ul>"},{"location":"contributing/requesting-a-change/","title":"Requesting a Change","text":"<p>Hyperledger Cacti is a powerful tool which serves a wide range of use cases. Put yourself in our shoes \u2013 with a project of this size, it can be challenging to maintain existing functionality while constantly adding new features at the same time. We highly value every idea or contribution from our community, and we kindly ask you to take the time to read the following guidelines before  submitting your change request in our public issue tracker. This will help us  better understand the proposed change, and how it will benefit the community.</p> <p>This guide is our best effort to explain the criteria and reasoning behind our decisions when evaluating change requests and considering them for implementation. </p>"},{"location":"contributing/requesting-a-change/#before-creating-an-issue","title":"Before creating an issue","text":"<p>Before you invest your time to fill out and submit a change request, we kindly ask you to do some preliminary work by answering some questions to determine if your idea is a good fit and matches the project's philosophy and tone.</p> <p>Please find answers to the following questions before creating an issue.</p>"},{"location":"contributing/requesting-a-change/#its-not-a-bug-its-a-feature","title":"It's not a bug, it's a feature","text":"<p>Change requests are intended for suggesting minor adjustments, ideas for new features, or to influence the project's direction and vision. It is important to note that change requests are not intended for reporting bugs, as they're missing essential information for debugging.</p> <p>If you want to report a bug, please refer to our bug reporting guide instead.</p>"},{"location":"contributing/requesting-a-change/#source-of-inspiration","title":"Source of inspiration","text":"<p>If you have seen your idea implemented in similar project, make sure to collect enough information on its implementation before submitting, as this allows us to evaluate potential fit more quickly. Explain what you like and dislike about the implementation.</p>"},{"location":"contributing/requesting-a-change/#benefit-for-the-community","title":"Benefit for the community","text":"<p>Our Discord server is the best place to connect with our community. When  evaluating new ideas, it's essential to seek input from other users and consider  alternative viewpoints. This approach helps to implement new features in a way that benefits a large number of users.</p>"},{"location":"contributing/requesting-a-change/#issue-template","title":"Issue template","text":"<p>Now that you have taken the time to do the necessary preliminary work and ensure  that your idea meets our requirements, you are invited to create a change request. The following guide will walk you through all necessary steps to help you submit a comprehensive and useful issue:</p> <ul> <li>Title</li> <li>Context optional</li> <li>Description</li> <li>Related links</li> <li>Use cases</li> <li>Visuals optional</li> <li>Checklist</li> </ul>"},{"location":"contributing/requesting-a-change/#title","title":"Title","text":"<p>A good title is short and descriptive. It should be a one-sentence executive summary of the idea, so the potential impact and benefit for the community can  be inferred from the title.</p>"},{"location":"contributing/requesting-a-change/#context","title":"Context optional","text":"<p>Before describing your idea, you can provide additional context for us to understand what you are trying to achieve. Explain the circumstances in which you're using Hyperledger Cacti, and what you think might be relevant. Don't write about the change request here.</p> <p>Why we need this</p> <p>Some ideas might only benefit specific settings, environments or edge cases. With a little context, change requests can be prioritized more accurately.</p>"},{"location":"contributing/requesting-a-change/#description","title":"Description","text":"<p>Next, provide a detailed and clear description of your idea. Explain why your  idea is relevant to Hyperledger Cacti and must be implemented here, and not in one of its dependencies.</p> <ul> <li> <p>Explain the what, not the why \u2013 don't explain     the benefits of your idea here, we're getting there.     Focus on describing the proposed change request as precisely as possible.</p> </li> <li> <p>Keep it short and concise \u2013 be brief and to the point when describing      your idea, there is no need to over-describe it. Maintainers and future     users will be grateful for having to read less.</p> </li> <li> <p>One idea at a time \u2013 if you have multiple ideas that don't belong  together, please open separate change requests for each of those ideas.</p> </li> <li> <p> Stretch goal \u2013 if you have a customization or another way to add the proposed change, you can help other users by sharing it here before we maintainers can add it to our code base.</p> </li> </ul> <p>Why we need this</p> <p>To understand and evaluate your proposed change, we need to have a clear understanding of your idea. By providing a detailed and precise description, you can help save you and us time spent discussing further clarification of your idea in the comments.</p>"},{"location":"contributing/requesting-a-change/#related-links","title":"Related links","text":"<p>Please provide any relevant links to issues, discussions, or documentation  sections related to your change request. If you (or someone else) already discussed this idea with the community on our discussion board, please include  the link to the discussion as well.</p> <p>Why we need this</p> <p>Related links help us gain a comprehensive understanding of your change request by providing additional context. Additionally, linking to previous issues and discussions allows us to quickly evaluate the feedback and input already provided by the community.</p>"},{"location":"contributing/requesting-a-change/#use-cases","title":"Use cases","text":"<p>Explain how your change request would work from a user's perspective \u2013 what's the expected impact and why does it not only benefit you, but other users? How many of them? Furthermore, would it potentially break existing functionality?</p> <p>Why we need this</p> <p>Understanding the use cases and benefits of an idea is crucial in evaluating its potential impact and usefulness for the project and its users. This information helps us to understand the expected value of the idea and how it aligns with the goals of the project.</p>"},{"location":"contributing/requesting-a-change/#visuals","title":"Visuals optional","text":"<p>We now have a clear and detailed description of your idea, including information  on its potential use cases and relevant links for context. If you have any  visuals, such as sketches, screenshots, mockups, or external assets, you may  present them in this section.</p> <p>Tip</p> <p>You can drag and drop the files here or include links to external assets.</p> <p>Additionally, if you have seen this change, feature, or improvement used  elsewhere, please provide an example by showcasing  it and describing how it was implemented and incorporated.</p> <p>Why we need this</p> <p>Illustrations and visuals can help us maintainers better understand and envision your idea. Screenshots, sketches, or mockups can create an additional level of detail and clarity that text alone may not be able to convey. Also, seeing how your idea has been implemented in other projects can help us understand its potential impact and feasibility in Hyperledger Cacti, which helps us maintainers evaluate and triage change requests.</p>"},{"location":"contributing/requesting-a-change/#checklist","title":"Checklist","text":"<p>Thanks for following the change request guide and creating a high-quality  change request. This section ensures that you have read this guide and have worked to your best knowledge to provide us with every piece of information to  review your idea for Hyperledger Cacti.</p> <p>We'll take it from here.</p>"},{"location":"contributing/requesting-a-change/#credits","title":"Credits","text":"<p>This document is based on Material for MkDocs Requesting a Change.</p>"},{"location":"guides/developers/","title":"Developer's Guide","text":"<p>We will provide more instructions and guidelines soon. For now, please refer to the Cacti Contributions guide and the project best practices.</p>"},{"location":"guides/operations/","title":"Operator's Guide","text":"<p>We will provide more instructions and guidelines soon. For now, please refer to the Cacti Contributions guide and the project best practices.</p>"},{"location":"guides/upgrading/","title":"Upgrading","text":"<p>We will provide more instructions and guidelines soon. For now, please refer to the Cacti Contributions guide and the project best practices.</p>"},{"location":"references/best-practices/","title":"Project Best Practices","text":"<p>See the Hyperledger Project Best Practices guidelines for a comprehensive and up-to-date set of practices recommended for anyone wishing to build, maintain, or contribute to a team-based open-source project, especially one built on GitHub.</p>"},{"location":"references/business/","title":"BUsiness Uses of Cacti","text":"<p>Here is a list of practical real-world projects that Cacti (or portions of it) have been used in.</p>"},{"location":"references/events/","title":"Events and Podcasts","text":"<p>See list of presentations and panel discussions on the topic of interoperability generally as well as Cacti specifically.</p>"},{"location":"references/github/","title":"Hyperledger GitHub Contribution Guide","text":"<p>See the Hyperledger GitHub Contribution Guide for instructions on how to use, sync, and contribute to any open-source Hyperledger project maintained on GitHub.</p>"},{"location":"references/publications/","title":"Published Articles and Research Papers","text":"<p>See list below.</p>"},{"location":"references/specs/","title":"Technical Specifications","text":"<p>The two legacy projects that Cacti is comprised of have independent sets of design and interface specifications, including examples of usage, as follows:</p> <ul> <li>Cactus: See the official Cactus whitepaper for technical designs and usage.</li> <li>Weaver: See the official Weaver RFCs for technical designs and interface specifications.</li> </ul> <p>Note</p> <p>We will create a unified set of technical specifications for Cacti as the Cactus and Weaver modules get integrated in a deeper way following the reference architecture. Keep watching these pages for updates!</p>"},{"location":"references/openapi/","title":"All Cacti Open API Specifications","text":""},{"location":"references/openapi/#packages","title":"Packages","text":"<ul> <li>cacti-plugin-ledger-connector-stellar</li> <li>cactus-cmd-api-server</li> <li>cactus-core-api</li> <li>cactus-plugin-bungee-hermes</li> <li>cactus-plugin-consortium-manual</li> <li>cactus-plugin-htlc-eth-besu</li> <li>cactus-plugin-htlc-eth-besu-erc20</li> <li>cactus-plugin-keychain-aws-sm</li> <li>cactus-plugin-keychain-azure-kv</li> <li>cactus-plugin-keychain-google-sm</li> <li>cactus-plugin-keychain-memory</li> <li>cactus-plugin-keychain-memory-wasm</li> <li>cactus-plugin-keychain-vault</li> <li>cactus-plugin-ledger-connector-aries</li> <li>cactus-plugin-ledger-connector-besu</li> <li>cactus-plugin-ledger-connector-cdl</li> <li>cactus-plugin-ledger-connector-corda</li> <li>cactus-plugin-ledger-connector-ethereum</li> <li>cactus-plugin-ledger-connector-fabric</li> <li>cactus-plugin-ledger-connector-iroha2</li> <li>cactus-plugin-ledger-connector-polkadot</li> <li>cactus-plugin-ledger-connector-sawtooth</li> <li>cactus-plugin-ledger-connector-sawtooth</li> <li>cactus-plugin-ledger-connector-xdai</li> <li>cactus-plugin-persistence-ethereum</li> <li>cactus-plugin-persistence-fabric</li> <li>cactus-plugin-satp-hermes</li> </ul>"},{"location":"references/openapi/#extensions","title":"Extensions","text":"<ul> <li>cactus-plugin-htlc-coordinator-besu</li> <li>cactus-plugin-object-store-ipfs</li> </ul>"},{"location":"references/openapi/#examples","title":"Examples","text":"<ul> <li>cactus-example-carbon-accounting-business-logic-plugin</li> <li>cactus-example-supply-chain-business-logic-plugin</li> </ul>"},{"location":"references/openapi/cacti-plugin-ledger-connector-stellar_openapi/","title":"Cacti plugin ledger connector stellar openapi","text":""},{"location":"references/openapi/cactus-cmd-api-server_openapi/","title":"Cactus cmd api server openapi","text":""},{"location":"references/openapi/cactus-core-api_openapi/","title":"Cactus core api openapi","text":""},{"location":"references/openapi/cactus-example-carbon-accounting-business-logic-plugin_openapi/","title":"Cactus example carbon accounting business logic plugin openapi","text":""},{"location":"references/openapi/cactus-example-supply-chain-business-logic-plugin_openapi/","title":"Cactus example supply chain business logic plugin openapi","text":""},{"location":"references/openapi/cactus-plugin-bungee-hermes_openapi/","title":"Cactus plugin bungee hermes openapi","text":""},{"location":"references/openapi/cactus-plugin-consortium-manual_openapi/","title":"Cactus plugin consortium manual openapi","text":""},{"location":"references/openapi/cactus-plugin-htlc-coordinator-besu_openapi/","title":"Cactus plugin htlc coordinator besu openapi","text":""},{"location":"references/openapi/cactus-plugin-htlc-eth-besu-erc20_openapi/","title":"Cactus plugin htlc eth besu erc20 openapi","text":""},{"location":"references/openapi/cactus-plugin-htlc-eth-besu_openapi/","title":"Cactus plugin htlc eth besu openapi","text":""},{"location":"references/openapi/cactus-plugin-keychain-aws-sm_openapi/","title":"Cactus plugin keychain aws sm openapi","text":""},{"location":"references/openapi/cactus-plugin-keychain-azure-kv_openapi/","title":"Cactus plugin keychain azure kv openapi","text":""},{"location":"references/openapi/cactus-plugin-keychain-google-sm_openapi/","title":"Cactus plugin keychain google sm openapi","text":""},{"location":"references/openapi/cactus-plugin-keychain-memory-wasm_openapi/","title":"Cactus plugin keychain memory wasm openapi","text":""},{"location":"references/openapi/cactus-plugin-keychain-memory_openapi/","title":"Cactus plugin keychain memory openapi","text":""},{"location":"references/openapi/cactus-plugin-keychain-vault_openapi/","title":"Cactus plugin keychain vault openapi","text":""},{"location":"references/openapi/cactus-plugin-ledger-connector-aries_openapi/","title":"Cactus plugin ledger connector aries openapi","text":""},{"location":"references/openapi/cactus-plugin-ledger-connector-besu_openapi/","title":"Cactus plugin ledger connector besu openapi","text":""},{"location":"references/openapi/cactus-plugin-ledger-connector-cdl_openapi/","title":"Cactus plugin ledger connector cdl openapi","text":""},{"location":"references/openapi/cactus-plugin-ledger-connector-corda_openapi/","title":"Cactus plugin ledger connector corda openapi","text":""},{"location":"references/openapi/cactus-plugin-ledger-connector-ethereum_openapi/","title":"Cactus plugin ledger connector ethereum openapi","text":""},{"location":"references/openapi/cactus-plugin-ledger-connector-fabric_openapi/","title":"Cactus plugin ledger connector fabric openapi","text":""},{"location":"references/openapi/cactus-plugin-ledger-connector-iroha2_openapi/","title":"Cactus plugin ledger connector iroha2 openapi","text":""},{"location":"references/openapi/cactus-plugin-ledger-connector-polkadot_openapi/","title":"Cactus plugin ledger connector polkadot openapi","text":""},{"location":"references/openapi/cactus-plugin-ledger-connector-sawtooth_openapi/","title":"Cactus plugin ledger connector sawtooth openapi","text":""},{"location":"references/openapi/cactus-plugin-ledger-connector-xdai_openapi/","title":"Cactus plugin ledger connector xdai openapi","text":""},{"location":"references/openapi/cactus-plugin-object-store-ipfs_openapi/","title":"Cactus plugin object store ipfs openapi","text":""},{"location":"references/openapi/cactus-plugin-persistence-ethereum_openapi/","title":"Cactus plugin persistence ethereum openapi","text":""},{"location":"references/openapi/cactus-plugin-persistence-fabric_openapi/","title":"Cactus plugin persistence fabric openapi","text":""},{"location":"references/openapi/cactus-plugin-satp-hermes_openapi/","title":"Cactus plugin satp hermes openapi","text":""},{"location":"weaver/design-principles/","title":"Design Principles","text":"<p>We list principles and considerations that guide the design of a framework for interoperability between decentralized networks, along with associated reasoning. Our present solution, though a work-in-progress, attempts to adhere to these principles.</p>"},{"location":"weaver/design-principles/#how-to-determine-need-for-interoperation-and-its-mode-and-mechanics","title":"How to determine need for interoperation, and its mode and mechanics?","text":"<ul> <li>Assess dependence decision (i,e., between networks) to determine goals and required assurances:<ul> <li>The decision to depend on a network is a complex one, as a network is itself an affiliation of independent parties.</li> <li>There are different approaches with varying levels of complexity and assurance.</li> <li>Examine structural assurances provided by networks and their participants, and do a cost-benefit analysis to determine a suitable approach.</li> </ul> </li> <li>The mechanics of interoperation can be derived from assumptions made in the above assessment.</li> <li>Our assumptions and aproach:<ul> <li>Individual network participants are untrustworthy.</li> <li>The network is trustworthy in the collective.</li> <li>The internal consensus mechanism of a network protects it from Byzantine failures.</li> <li>Interoperability needs will not force structural changes or forks in a network nor constrain that network's internal evolution.</li> </ul> </li> </ul>"},{"location":"weaver/design-principles/#principles-and-ideals-for-interoperability-solution-design","title":"Principles and Ideals for Interoperability Solution Design","text":"<p>Here are our guiding principles that accord with our assumptions and approach, in no particular order.</p>"},{"location":"weaver/design-principles/#favor-technical-assurances-over-social-assurances","title":"Favor Technical Assurances over Social Assurances","text":"<ul> <li>Technical assurances are provided by protocols and security mechanisms, including distributed consensus.</li> <li>Social assurances include governance (collectively, through a consortium, or via a hierarchy), legal rules and regulations, reputations and history of past behavior.</li> <li>The reason to favor the former is that it can provide provable guarantees that are independent of the trustworthiness of individual participants, whereas the latter can be brittle and rely on participants' compliance.</li> </ul>"},{"location":"weaver/design-principles/#be-inclusive-and-accommodate-heterogeneity","title":"Be Inclusive and Accommodate Heterogeneity","text":"<ul> <li>Avoid approaches for protocol design that are specific to a particular DLT implementation or network structure.</li> <li>Specify the communication protocol in a network-neutral language.</li> <li>Design protocol units that can abstract out common features for information and assurances from diverse DLTs.</li> </ul>"},{"location":"weaver/design-principles/#allow-networks-to-retain-independence-and-collective-sovereignty","title":"Allow Networks to Retain Independence and Collective Sovereignty","text":"<ul> <li>A network is treated as an independent self-governing system with the freedom of choice to interoperate with another on a need basis.</li> <li>Network members retain collective sovereignty over their internal processes as well as access control rules governing remote interoperation.</li> <li>Networks have full and collective control, via their native consensus and smart contract mechanisms, over exposure of data, assets, and transactions to other networks.<ul> <li>A network acts as a unit for framing and enforcing rules controlling access to information held on its ledger(s) by a remote network.</li> </ul> </li> <li>Similarly, networks have full and collective control, via their native consensus and smart contract mechanisms, over acceptance of data or assets and verifications of transactions occurring in, other networks.</li> </ul>"},{"location":"weaver/design-principles/#minimize-network-coupling","title":"Minimize Network Coupling","text":"<ul> <li>Networks/consortia must retain independence for governance and configuration<ul> <li>Therefore, interoperation must require loose coupling rather than a merging or overlapping of two networks</li> </ul> </li> <li>Loose coupling between dependent networks allows changes to counterparty networks' implementations with minimal or no impact to cross-network dependencies.</li> <li>Domain decoupling:<ul> <li>Define standards for contract interfaces</li> <li>Define standards for representing data types and assets types (e.g. https://www.gs1.org/traceability)</li> <li>Define standards for identity portability</li> </ul> </li> <li>Communication decoupling:<ul> <li>Define standards for network interface/API</li> <li>Define standards for protocol behavior</li> <li>Define standards for messaging formats</li> </ul> </li> </ul>"},{"location":"weaver/design-principles/#do-not-compromise-on-privacy-and-confidentiality","title":"Do not Compromise on Privacy and Confidentiality","text":"<ul> <li>By design, a permissioned network should retain its privacy, and interoperation mechanisms should not leak information outside the bounds of what access control rules allow.</li> <li>Cross-network communications should be kept private and confidential and revealed only to interested parties, applying the principle of least privilege.</li> </ul>"},{"location":"weaver/design-principles/#minimize-trust-footprint-and-avoid-centralization","title":"Minimize Trust Footprint and Avoid Centralization","text":"<ul> <li>Design for decentralization across networks as within networks:<ul> <li>Avoid introducing centralized services that are easy to compromise</li> <li>Assume that failure scenarios that apply to networks also hold for any service coordinating interoperability.</li> </ul> </li> <li>Reduce trust to only what is essential (i.e. identity providers in the network).</li> <li>No trusted third-party intermediary or infrastructure (e.g., Polka Dot, Cosmos) should be relied upon for the purpose of cross network data verification or settlement.</li> <li>Reduce trust and centralization to only essential functions that cannot be completely decentralized:<ul> <li>Communicate messages across networks using some networking infrastructure:<ul> <li>This communication infrastructure is not trusted to maintain confidentiality or integrity of messages, and it may mount denial of service attacks.</li> </ul> </li> <li>Identity provision and verification:<ul> <li>This is necessary for permissioned networks that have private memberships governed by a committee that may be centralized or distributed.</li> </ul> </li> </ul> </li> </ul>"},{"location":"weaver/design-principles/#favor-dependence-on-proofs-over-trust","title":"Favor dependence on proofs over trust","text":"<ul> <li>This is also implied by the \"No Trusted Intermediaries\" principle.</li> <li>Information transferred across networks must carry verifiable proofs.</li> <li>The receiving network must be able to specify a verification policy for proofs that it can independently and collectively (i.e., through consensus) verify.</li> </ul>"},{"location":"weaver/design-principles/#minimize-impact-and-adaptation","title":"Minimize Impact and Adaptation","text":"<ul> <li>Enabling interoperation must not require changes to existing network protocols.</li> <li>Enabling interoperation must not impact existing network operation in any way nor require any blockchain forks.</li> <li>Adaptation in existing smart contracts and applications must be avoided unless absolutely necessary, and follow modular principles.</li> </ul>"},{"location":"weaver/design-principles/#maximize-operational-efficiency","title":"Maximize Operational Efficiency","text":"<ul> <li>Minimize payloads in cross-network protocol units.</li> <li>Strive for event-driven asynchronous messaging architectures (this is also implied by the \"Minimal Coupling\" principle).</li> </ul>"},{"location":"weaver/design-principles/#design-guidelines-for-network-architects-and-developers","title":"Design Guidelines for Network Architects and Developers","text":"<ul> <li>Architects and application developers (both in the smart contract and services layers) must design with interoperability in mind:<ul> <li>This has the advantage of minimizing or eliminating any code adaptations required for interoperability during a network's life cycle.</li> </ul> </li> <li>Apply standards when defining assets, data and logic within network apps to maximize external consumption:<ul> <li>Networks with well-defined standards-based interfaces simplifies interoperability:<ul> <li>Interfaces include: contracts, data/assets, identity, APIs, protocol, messaging.</li> </ul> </li> </ul> </li> <li>Enables network implementation to evolve while eliminating or minimising external impact:<ul> <li>Implement in a modular way: many patterns and principles exist in the field of web services.</li> <li>Decouple interoperability-related application modules as much as possible (this guideline applies to blockchain-related modules within enterprise apps too).<ul> <li>This will make maintenance easier and also allow administrators to minimize the amount of code that needs to be deployed in higher-security enterprise zones.</li> </ul> </li> </ul> </li> </ul>"},{"location":"weaver/interoperability-modes/","title":"Interoperability Modes","text":""},{"location":"weaver/interoperability-modes/#modes-of-interoperability","title":"Modes of Interoperability","text":"<p>We identify distinct modes or patterns of interoperation based on the nature and purpose of the artifact that two networks (or parties within) have a common interest in and the purpose they wish to achieve.</p> <p>First, we will classify artifacts present on shared ledgers broadly into the following two types:</p> <ul> <li>Assets: This is a ledger item that is associated with a single entity (or limited set of entities), representing the real-world ownership of that item by an entity. Bitcoins in the Bitcoin network and Ether on the Ethereum network are well-known examples, but assets repreenting a wide range of tangible goods can reside on blockchian ledgers, like property titles, bank drafts, precious stones, and financial instruments like bonds and securities.</li> <li>Data Records: This is any information held on a ledger that describes the state of the world, context, or properties of an entity or object. It is not \"owned\" by, or associated with, specific entities, but is rather common knowledge within a blockchain network.</li> </ul> <p>The salient distinction between assets and data from an interoperability perspective is that the former may be present only in one network at any given instant in order to maintain its integrity whereas the latter can have copies in multiple networks without losing its value.</p> <p>Three common modes in which independent networks will seek to interoperate are as follows. (We can also refer to them as three distinct purposes.)</p>"},{"location":"weaver/interoperability-modes/#asset-transfer","title":"Asset Transfer","text":"<p>This refers to the movement of an asset from its source ledger to a consuming ledger. Since assets has singleton ownership and can't be double spent, the transfer of an asset should result in its burning or locking in the source ledger and its creation on the target ledger.</p> <p>A typical asset transfer use case is illustrated in the figure below, where Party X initially holds Asset in Network A, and through interoperation transfers Asset to Party Y in Network B. The loss of Asset to X in A must occur simultaneously with the gain of Asset for Y in B;. i.e, these transactions must be atomic. (\"Holding an asset\" refers to a record on a network's shared ledger representing the ownership of that asset by a given entity.)</p> <p></p>"},{"location":"weaver/interoperability-modes/#asset-exchange","title":"Asset Exchange","text":"<p>This refers to the change of ownership of an asset in a source network and a corresponding change of ownership in another network. No asset leaves the network it resides in. The well-known terminology for asset exchange is 'Atomic Cross-Chain Swap'.</p> <p>For example: two parties with both Bitcoin and Ethereum accounts may trade Bitcoin forEthereum based on an exchange rate agreed upon off-chain. We generalize this to permissioned networks, where it may be harder to provide guarantees of finality, and therby, atomicity.</p> <p>The figure below illustrates a typical asset exchange. Initially, Party X holds Asset M in Network A and Party Y holds Asset N in Network B. Through interoperation, an exchange occurs whereby Y holds M in A and X holds N in B. The changes in these two networks occur atomically. (Note: in such a use case, both X and Y must be members of both networks.) See DvP in Financial Markets for an example scenario illustrating asset exchanges.</p> <p></p> <p>Both the asset transfer and exchange patterns can be extrapolated to scenarios involving more than 2 parties, 2 assets, and 2 networks. The only fixed criterion is that the actions on all networks happen atomically. For the same reason, the infrastructure and protocols to support both asset transfers and exchanges overlap significantly.</p>"},{"location":"weaver/interoperability-modes/#data-sharing","title":"Data Sharing","text":"<p>This refers to the transfer of data from its source ledger to a consuming ledger. (In many scenarios, data records in one network ledger may need to be shared with another network ledger in order to drive forward a process on the latter.) The data transferred can be the result of invoking a contract or a database query. There are no technical limits to the number of times a given piece of data can be copied to other ledgers.</p> <p>The below figure illustrates this pattern, where initially, Data Record is maintained only on Network A's ledger, and through interoperation, a copy resides on Network B's ledger. (Note: the data record may be transformed within Network B during the sharing process before a transaction is committed to its ledger.) See Global Trade for an example scenario illustrating data sharing.</p> <p></p>"},{"location":"weaver/interoperability-modes/#identity","title":"Identity","text":"<p>This refers to the process by which identity can be expressed and comprehended beyond the boundaries of a single network. The ability to reason about identities as real-world entities along with credentials proving their membership in various networks is key to creating a trust basis that enables the three interoperability  modes listed above. From that perspective, this kind of cross-network identity management lies on a higher plane than data and asset movements. For more details on our thinking, see the Interop RFC pages.</p>"},{"location":"weaver/introduction/","title":"Weaver Framework","text":"<p>Weaver is a framework that enables scalable interconnectivity between disparate distributed ledgers in a manner that preserves core tenets of decentralisation and security. The framework, consisting of a family of protocols, is designed and built with the following key guiding principles, which are further discussed in Design Principles:</p> <ul> <li>Inclusiveness: Avoid approaches that are specific to a particular DLT implementation and design.</li> <li>Independence: Interoperable networks retain sovereignty on their own processes and access control rules.</li> <li>Minimum Trust: Reduce trust to only what is essentials (i.e. identity providers in the network).</li> <li>Privacy by Design: Interaction between parties across networks should be kept private and confidential and revealed only to the interested parties.</li> <li>No Intermediaries: No third-party intermediary should be relied upon for the purpose of cross-network data verification or settlement.</li> <li>Minimal Shared Infrastructure: Rely on external infrastucture only for discovery, identification, and tracking/auditing, and not for cross-network transactions.</li> <li>Leverage Consensus: Use the respective ledgers' native distributed consensus mechanisms as the trust basis for cross-network transactions.</li> <li>Non-Intrusion: Require no changes to the DLT platforms and consensus mechanisms on which the networks are built, nor any dilution of the networks' security models.</li> <li>Transparency: Facilitate tracking and auditing of cross-network transactions.</li> </ul> <p>The protocol is designed around the following key elements:</p> <ol> <li>State Proofs: these allow a network to independently verify that any state it consumes from another network is valid according to the rules and policies of that network, or adheres to validity policies it imposes on state from that network.</li> <li>Asset Locks and Claims: these allow a network to freeze an asset for a given time period on behalf of a user or allow a user to claim a frozen asset from its previous owner, either within a network or from a different network.</li> <li>Relays: these are decentralised peer-to-peer services that enable communication of messages between networks.</li> </ol> <p>Weaver has a specification outlined through a set of RFCs and a reference implementation of that specification, which is discussed in this documentation.</p>"},{"location":"weaver/publications/","title":"Publications","text":"<p>Visit the repository to find the current list of articles, talks, and research papers.</p>"},{"location":"weaver/publications/#2021","title":"2021","text":""},{"location":"weaver/publications/#verifiable-observation-of-permissioned-ledgers","title":"Verifiable Observation of Permissioned Ledgers","text":"<p>IEEE International Conference on Blockchain and Cryptocurrency, 2021</p> <p>Ermyas Abebe, Yining Hu, Allison Irvin, Dileban Karunamoorthy, Vinayaka Pandit, Venkatraman Ramakrishna, Jiangshan Yu</p> <p><code>[arXiv]</code></p>"},{"location":"weaver/publications/#decentralized-cross-network-identity-management-for-blockchain-interoperation","title":"Decentralized Cross-Network Identity Management for Blockchain Interoperation","text":"<p>IEEE International Conference on Blockchain and Cryptocurrency, 2021</p> <p>Bishakh Chandra Ghosh, Sandip Chakraborty, Venkatraman Ramakrishna, Chander Govindarajan,Dushyant Behl, Dileban Karunamoorthy, Ermyas Abebe</p> <p><code>[arXiv]</code></p>"},{"location":"weaver/publications/#2019","title":"2019","text":""},{"location":"weaver/publications/#enabling-enterprise-blockchain-interoperability-with-trusted-data-transfer","title":"Enabling Enterprise Blockchain Interoperability with Trusted Data Transfer","text":"<p>Proceedings of the 20<sup>th</sup> International Middleware Conference Industrial Track, 2019</p> <p>Ermyas Abebe, Dushyant Behl, Chander Govindarajan, Yining Hu, Dileban Karunamoorthy, Petr Novotny, Vinayaka Pandit, Venkatraman Ramakrishna, Christian Vecchiola</p> <p><code>[Proceedings]</code> <code>[arXiv]</code></p>"},{"location":"weaver/publications/#on-the-interoperability-of-distributed-ledgers-medium","title":"On the Interoperability of Distributed Ledgers, Medium","text":"<p>Dileban Karunamoorthy, Ermyas Abebe</p> <p><code>[Medium]</code></p>"},{"location":"weaver/specifications/","title":"Specifications","text":"<p>The Weaver specifications (RFCs) capture abstractions, models, protocols and data formats for enabling cross-ledger communication.</p> <p>For newcomers who wish to find out more details about the Weaver design and wish to contribute to the code base, we recommend starting with the models. Protocol engineers will find in RFC: 01-009 a useful overview of the relay model, and may then progress on to reading one of the existing protocols' design and implementation; e.g., the data sharing protocol in RFC: 02-001. If you are interested in adding support for a new ledger technology, see the existing driver implementations and existing interoperability module implementations. Where relevant we use ABNF for formal syntax definitions.</p>"},{"location":"weaver/architecture-and-design/decentralized-identity/","title":"Decentralized Identity","text":"<p>Interoperation for asset or data transfers/exchanges relies on a message-passing infratructure and pan-network data processing modules, as we have seen in earlier pages. But there is yet another crucial basis these data processing modules need to satisfy our design principles of network independence and avoidance of trust parties. This is the ability of a network as a whole and of its individual members to accurately identify and authenticate another network's members.</p> <p>Further, for the networks to remain independent and interact ad hoc with each other, we cannot impose a central authority that unifies their private identity management systems. So the identity basis of interoperation must be decentralized, leading inevitably to the requirement of exchanging identity information across networks as a pre-requisite for asset and data transfers/exchanges. This is illustrated in the figure below where interoperation protocols are classified in two planes (or tiers), data and identity, with the former depending on the latter.</p> <p></p> <ul> <li>In the data plane lies the protocols that effect the actual exchanges of data and assets. The figure above illustrates a typical data-sharing instance, where the network at the left requests a data record from the right. The latter receives the request via the two relays (not explicitly marked in this diagram) and runs an access control check through consensus in its interop module before responding with the data record and supporting proof. The network at the left receives the data and proof, again via the two relays, and verifies the data using the supplied proof. Note: since a core part of both request and proof are digital signatures of network members, the ability to identify and authenticate network members is necessary to perform these endpoint functions.</li> <li>Here is where the identity plane enters the picture, as a trust anchor for the data plane. The most general function of this plane is illustrated in the figure, where the networks get each others' identity and configuration (i.e., membership structure and network topology) information. This exchange has as its own trust basis (or dependency) a set of identity providers and verifiers. (Note: these identity providers and verifiers may belong to the two networks or they could be external entities.) The outcome of the exchange is a record of the other network's identity and configuration information on one's ledger, which can then be looked up in a data plane protocol instance.</li> </ul>"},{"location":"weaver/architecture-and-design/decentralized-identity/#identity-plane-strawman-approach","title":"Identity Plane: Strawman Approach","text":"<p>The simplest identity plane protocol involves a direct exchange of identity information between representatives of the two networks: in other words, an API integration. But this approach suffers from the same drawbacks that API integration in the data plane would. It diminishes a blockchain network to a single trusted spokesperson, exposing that network to risk. Even if such a spokesperson could be designated, appropriately framing access control policies for potentially every other blockchain network in the world would be very challenging. This approach is therefore insecure and not scalable, and therefore ought to be treated purely as a strawman.</p>"},{"location":"weaver/architecture-and-design/decentralized-identity/#networks-as-groups-of-self-sovereign-members","title":"Networks as Groups of Self-Sovereign Members","text":"<p>A secure and sustainable identity plane plaform can be built on the basis of self-sovereign identity and decentralized identifiers. We recognize that:</p> <ul> <li>Each constituent member of a blockchain network may already possess an identity from a third-party provider</li> <li>Membership within a network can be treated as a property of a sovereign organization rather than subordination to a network's governing authority</li> <li>DIDs allow members to control who they wish to share their identities with and the levels of exposure</li> <li>Network membership lists and individual members' identities can respectively be validated by different providers, thereby maintaining decentralization of infrastructure</li> </ul>"},{"location":"weaver/architecture-and-design/decentralized-identity/#distributed-identity-management-infrastructure","title":"Distributed Identity Management Infrastructure","text":"<p>The distributed identity management infrastructure for interoperation is illustrated in the figure below. We assume the existence of one or more Interoperation Identity Networks (IINs) that act as registries and credential validators for the organizations that form the memberships of blockchain networks.</p> <p></p> <p>An IIN can be built from scratch to facilitate blockchain interoperation, but it can also be an augmentation of an existing decentralized identity provider or registry. Its purpose is to maintain identity records and credentials for organizations and validate these to third parties as per the desire of the identity or credential owner. In this model, an IIN can itself be reputed or it can bring together many reputed and trusted identity providers (called stewards) into a shared network. As long as the members of two blockchain networks have shared trust in one or more IINs, an identity plane exchange can be effected, thereby setting the foundation for data and asset transfers.</p>"},{"location":"weaver/architecture-and-design/decentralized-identity/#interoperation-identity-network","title":"Interoperation Identity Network","text":"<p>The ideal IIN architecture is illustrated in the figure below, inspired by Hyperleder Indy, whose architecture is used in our canonical (or reference) implementation. Built on a DLT itself, an Indy-based IIN can provide the combination of assurance and decentralization that a centralized registry cannot. Further, such an IIN will support the entire SSI and DID standard, maintaining credential schemas and verification keys, and issuing verifiable credentials that can be used for privacy-preserving authentications.</p> <p></p> <p>An IIN is modeled as a network with a distributed shared ledger, implemented using an Indy Node Pool and running BFT consensus. The ledger is also (ideally) meant to be publicly accessible, though there is nothing preventing our protocols from working with a private IIN.</p> <p>A canonical IIN maintains the following:</p> <ul> <li>DID records corresponding to organizations that are members of one or more blockchain networks, whose salient attributes include:<ul> <li>Unique (within an IIN) identifier or verinym for the identity owner</li> <li>Service endpoint for the identity owner</li> <li>Credential schemas</li> <li>Credential definitions (public keys used to authenticate signed credentials)</li> </ul> </li> </ul> <p>Every IIN has a set of bootstrapped trust anchors called stewards. A steward can create other trust anchors by issuing them suitable credentials. The trust anchors are the primary identity providers in our distributed identity management architecture. They can be existing reputed authorities or identity providers who are trusted to certify blockchain networks' memberships, or they can be created ad hoc by a consortium representing the members of a blockchain network.</p> <p>For one blockchain network to discover and validate another in the identity plane, it must trust one or more IINs and trust anchors who can provide that validation. We envision a shared and mutually reinforcing trust among stewards and other anchors within an IIN. An anchor could gain trust by virtue of joining a well-established IIN. Similarly, an IIN bootstrapped with well-known stewards gains trust because of the collective reputations of those stewards.</p> <p>Examples of entities that can act as stewards or trust anchors within IINs: the Sovrin Foundation (an organization dedicated to enabling open-source digital ID management, and which also maintains Indy), companies like Maersk or Walmart that have founded real-world blockchain networks, companies like IBM or R3 that maintain popular DLT platforms.</p> <p>IINs don't have to be built on Indy. Alternatives like Sidetree exist, providing similar functionality. There are also various existing DID registries that are already issuing credentials to existing organizations. To the extent possible, we would like to leverage all of this existing infrastructure and not force any network menmber to find yet another identity provider. Therefore, these existing registries or networks can be used as IINs: the only requirement is that they follow the standards for SSI and DIDs and issuing VCs.</p>"},{"location":"weaver/architecture-and-design/decentralized-identity/#network-membership-credentials","title":"Network Membership Credentials","text":"<p>Two kinds of credentials (each with a schema and a definition) are maintained on an IIN ledger:</p> <ol> <li>Member list: This contains a network name or ID and a set of DIDs of that network's members.<ul> <li>This is a per-network credential whose schema and verification key must be maintained on an IIN.</li> <li>This is issued by a steward or trust anchor in an IIN and is associated with that steward's or anchor's DID.</li> </ul> </li> <li>Membership: This contains an oranization's attributes, including the set of IDs of networks to which it belongs.<ul> <li>This is designed to be an extensible credential, i.e., support more attributes in the future.</li> <li>An existing membership credential (of the VC form) can be used as long as it matches the schema recorded on an IIN.</li> <li>The issuer must be a steward or trust anchor (or equivalent, if it's a non-Indy registry) in an IIN.</li> <li>This is associated with the member's DID.</li> </ul> </li> </ol>"},{"location":"weaver/architecture-and-design/decentralized-identity/#identity-info-units-of-exchange","title":"Identity Info: Units of Exchange","text":"<p>The IIN is used to discover the membership list of a foreign network and establish the authenticity of its members. Memnbership credentials are independent of blockchain networks.</p> <p>But data plane transfers and exchanges require knowledge of in-network identities and certificates, which are issued by a network's membership manager(s) to peers and clients. These are not shared through IINs for several reasons. First, the volume of this information can be quite high and further it is subject to change based on a network's internal needs. Also, a network or its members may not wish to expose all this information to an IIN, which is designed to be publicly accessible. Therefore, it is infeasible or undesirable to shared network-specific credentials via established IINs. Instead, we will enable the peer-to-peer exchange of such credentials after the membership discovery and validation procedure is complete.</p> <p>Specifically, the identity information for a network member consists of the set of certificate chains of the membership managers for that particular member (organization). These consist of one or more hierarchies of root and intermediate CA certificates. For example:</p> <ul> <li>In Fabric, each organization uses one or more MSPs (membership service providers), each running one or more root and intermediate Fabric-CA servers. Any network peer belonging to an organization is issued a certificate authorized by one of these certificate chains. To authenticate a network peer or client in a data plane protocol, knowledge of these certificate chains is essential.</li> <li>In Corda, the entire network typically consists of a hierarchy of CAs, from a root to multiple doormen, and from each doorman to multiple nodes. Finally, the certificates used to sign transactions are issued by the node CAs. Therefore, knowledge of the root, doormen, and node CA certificates is essential for authenticating signers.</li> </ul> <p>More generally, each unit of exchange corresponding to a network member is a Security Group, so-called because each network member is an independent organization in its own right with a security domain.</p>"},{"location":"weaver/architecture-and-design/decentralized-identity/#iin-agents-as-member-representatives","title":"IIN Agents as Member Representatives","text":"<p>Every network member needs a proxy (either an abstraction or a separate module) for communication with IINs and with the members of foreign networks in the identity plane. We use the term \"IIN Agent\" to refer to this proxy, and illustrate its functioning as a module within a Fabric network through the reference diagram below.</p> <p></p> <p>In the reference implementation, IIN Agents are built as Hyperledger Aries nodes and communicate with each other and with IIN stewards and trust anchors using the Aries protocol. (IIN stewards and trust anchors are also built as Aries nodes.)</p> <p>The list of trusted IINs is recorded on the local network's shared ledger, as illustrated in the figure (and thereby agreed through network consensus). To be able to interoperate with another network, the latter's members must have identity records maintained by sume subset of these trusted IINs and their VCs must be issued by these IINs stewards and trust anchors.</p>"},{"location":"weaver/architecture-and-design/decentralized-identity/#protocols","title":"Protocols","text":"<p>Let us consider a scenario where NETWORK 1 and NETWORK 2 wish to interoperate, and their respective member organizations are as follows:</p> <ul> <li>NETWORK 1: Org3, Org4, Org5</li> <li>NETWORK 2: Org1, Org2</li> </ul> <p>Each network discovers the other's member list and obtains and records ech member's security group to the local shared ledger. We can enumerate these as follows:</p> <ul> <li>NETWORK 1 discovers and registers NETWORK 2:Org1</li> <li>NETWORK 1 discovers and registers NETWORK 2:Org2</li> <li>NETWORK 2 discovers and registers NETWORK 1:Org3</li> <li>NETWORK 2 discovers and registers NETWORK 1:Org4</li> <li>NETWORK 2 discovers and registers NETWORK 1:Org5</li> </ul> <p>Each of these can be done in parallel and each discovery and registration operation is idempotent as long as the security group of a network member does not change.</p> <p>The high-level workflow for discovery and registration is illustrated below (using NETWORK 2 as the seeker and NETWORK 1 as the provider).</p> <p></p> <p>(Note: \"Network unit\" is synonymous with \"network member\")</p> <p>Prerequisites for this process are:</p> <ul> <li>The member list credential of NETWORK 1 is provided by a steward or trust anchor in a particular IIN which is also on the trust list recorded in the ledger of NETWORK 2.</li> <li>The membership credentials for both organizations in NETWORK 1 are supplied by one or more IINs that are on the trust list of NETWORK 2.</li> <li>Each of the 5 organizations (2 in NETWORK 1 and 3 in NETWORK 2) has an IIN Agent running on their behalf.</li> </ul> <p>Let us take the example of NETWORK 2 having already obtained the security group info for Org4 and Org5 in NETWORK 1. It is now discovering and registering NETWORK 1:Org3. We assume that there is a single IIN with a single Steward for validating member list as well as membership credentials for all members of both the networks.</p> <p>Note: we assume here for simplicity that a steward as a reputed identity provider has a mechanism to validate the bona fides of an orgganization and its membership in a given network. There are other techniques involving group signatures that could be applied to corroborate an organization's claim to network membership rather than requiring a steward to use an out-of-band security mechanism, but that is presently beyond the scope of this design.</p> <p>The discovery and registration procedure steps are as follows:</p> <ul> <li>The IIN Agent for Org3 registers its membership to NETWORK 1 at the Steward in IIN:<ul> <li>NETWORK 1:Org3 gets a DID (verinym) issued</li> <li>The Steward updates the member list credential for NETWORK 1 to include Org3</li> <li>Org3 obtains a membership credential from Steward</li> </ul> </li> <li>The IIN Agent for Org3 issues itself a self-signed VC containing its security group info</li> <li>The IIN Agent for NETWORK 2:Org2 (only one organization in the network needs to do this) obtains the new member list credential from Steward in IIN and validates it using the IIN ledger records</li> <li>The IIN Agent for NETWORK 2:Org2 discovers that Org3 is a member of NETWORK 1, fetches Org3's membership credential from Org3's IIN Agent, and validates it using the IIN ledger records</li> <li>The IIN agent for NETWORK 2:Org2 fetches the self-signed security group credential from the IIN agent of NETWORK 1:Org3 and validates it</li> <li>The IIN agent for NETWORK 2:Org2 triggers a flow among the IIN Agents of NETWORK 2 to collect signatures endorsing the security group info for NETWORK 1:Org3 fetched above<ul> <li>The IIN Agent for NETWORK 2:Org1 gets this endorsement request, and validates both the membership credential and the security group info for NETWORK 1:Org3 by communicating with the Steward, the IIN ledger, and the IIN Agent for NETWORK 1:Org3</li> <li>The IIN Agent for NETWORK 2:Org1 signs the request from Org2 containing the security group info for NETWORK 1:Org3 after the above check succeeds</li> </ul> </li> <li>When the IIN agent for NETWORK 2:Org2 gets signatures from the IIN Agents representing each member of NETWORK 2, it submits the security group info for NETWORK 1:Org3 alon with the signatures to the interop module (typically smart contract) for recording on the ledger of NETWORK 2<ul> <li>Now the ledger of NETWORK 2 contains the identities and certificates of all three members of NETWORK 1: Org3,Org4,Org5, and data plane interoperation may ensue.</li> </ul> </li> </ul> <p>Note: the last step above (recording to the local ledger via the interop module) may be performed by IIN Agents of both Org1 and Org2 as they have no means of synchronizing their actions, but this recording will be idempotent and hence not cause any harm.</p> <p>The process above is illustrated with a few more details in the sequence of protocol diagrams below.</p> <p></p> <p></p> <p></p>"},{"location":"weaver/architecture-and-design/decentralized-identity/#references","title":"References","text":"<p>Bishakh Chandra Ghosh, Venkatraman Ramakrishna, Chander Govindarajan, Dushyant Behl, Dileban Karunamoorthy, Ermyas Abebe, Sandip Chakraborty, Decentralized Cross-Network Identity Management for Blockchain Interoperation, ICBC 2021</p>"},{"location":"weaver/architecture-and-design/drivers/","title":"Drivers","text":"<p>The driver is responsible for all communication between the relay and its network. In the previous sections we have thought about the driver as a component of the relay. We have done this because conceptually it makes sense to think about it like that. However, in our reference implementation we have made it a separate process which communicates with the relay via gRPC, as shown below. There are two main reasons for this:</p> <ol> <li>There must exist a different driver for each network type (e.g. Fabric, Corda etc.) and therefore having the driver as a separate process makes it easy to \"plug\" different drivers into the relay.</li> <li>A possible use case of the relay is that a single relay instance may have multiple drivers (e.g. if multiple entities in the network want to run their own driver). In this case, this plugin style approach of drivers makes it possible to do without having to modify code for each configuration.</li> </ol> <p></p>"},{"location":"weaver/architecture-and-design/overview/","title":"Overview","text":"<p>The below diagram shows a high level architecture diagram of the Weaver framework.</p> <p></p>"},{"location":"weaver/architecture-and-design/overview/#network","title":"Network","text":"<p>The networks in the system can be made up of various heterogenious technologies, including Hyperledger Fabric and Corda. Each network in the system needs to contain an interoperability (IOP) module that enables them to communicate with the relays.</p>"},{"location":"weaver/architecture-and-design/overview/#relay","title":"Relay","text":"<p>The relays act as a conduit to facilitate communication of protocols between networks (e.g. data transfer, asset exchange etc). The roles of the relays are described in more detail in relay.</p>"},{"location":"weaver/architecture-and-design/overview/#design-decisions","title":"Design Decisions","text":"<p>The high level design decisions that were made for the system are outlined here.</p>"},{"location":"weaver/architecture-and-design/overview/#synchronous-vs-asynchronous-message-communication","title":"Synchronous vs Asynchronous message communication","text":"<p>We decided to go with an asynchronous message architecture. The primary reason for this is because requests can take an arbitary amount of time to respond, it is not practical for a synchronous message to wait that long for a reply. For example, obtaining a 12 block confirmation on the Bitcoin network can take about 2 hours.</p>"},{"location":"weaver/architecture-and-design/overview/#message-vs-connection-oriented-communication","title":"Message vs connection oriented communication","text":"<p>We decided to go with a message oriented architecture. The primary reason for this is because it makes the system more fault tolerant. With a message oriented architecture the requester and responder don't need to be alive at the same time. For example, if the requestor crashes while the responder is processing the request, the communication is not interrupted since the responder will just send a message when it has finished processing the request. The design choice also enables the systen to be made more fault tolerant in the future by implementing message queues between components in the system.</p>"},{"location":"weaver/architecture-and-design/relay/","title":"Relay","text":"<p>As mentioned in the overview, relays facilitate communication of protocols between networks. To do this, they are composed of three main pieces:</p> <ul> <li><code>Relay service</code> - A gRPC server that listens for and handles incoming requests from other relays. For example, a remote network requesting state.</li> <li><code>App service</code> - A gRPC server that listens for and handles requests from applications that are requesting an asset from a remote network.</li> <li><code>Driver</code> - The driver is responsible for all communication between the relay and its network. The driver is described in more detail in drivers.</li> </ul> <p>The diagram below shows an example communication between two networks, A and B, where network A is requesting state from network B.</p> <p></p> <ol> <li>An application sends a request to their networks relay over gRPC</li> <li>The local relay inspects the query within the request and uses the relevant information to forward the request to the correct remote relay</li> <li>The remote relay's driver interprets the query and invokes the smart contract for the query</li> <li>Once network B has returned a response to its relay, the relay forwards the response back to relay A</li> <li>The application gets the response from the relay, this can either be via a push or pull mechanism</li> <li>The application invokes a domain specific smart contract to process the response from network B</li> </ol>"},{"location":"weaver/architecture-and-design/weaver-dapps/","title":"Weaver Dapps","text":"<p>As mentioned in the overview, DLTs that integrate with Weaver must contain an interop (IOP) module to facilitate interoperation between ledgers. The interop module contains all the logic responsible for membership, verification policies and access control policies (refer to the RFCs for more information on these). Below shows the architecture of how these interop modules work with the two currently supported DLTs, Fabric and Corda.</p>"},{"location":"weaver/architecture-and-design/weaver-dapps/#fabric","title":"Fabric","text":"<p>When Fabric is the requesting network, the IOP module is used to verify the proof and then forward the state onto the application chaincode.</p> <p></p> <p>When Fabric is the responding network, the IOP module is in charge of verifying the identity of the requester, making sure the requester has access to the state they are requesting, and then finally retrieving the state from the application chaincode to send back to the requesting network.</p> <p></p> <p>Verification Policy, Access Control and Membership are modular components within the interop chaincode for separation of concerns of the code.</p>"},{"location":"weaver/architecture-and-design/weaver-dapps/#corda","title":"Corda","text":"<p>As can be seen from the diagrams below, the architecture for Corda is very similar to that of Fabric. The main difference is that the interop module and the application specific flows are in separate CorDapps, instead of separate chaincodes like in Fabric.</p> <p></p> <p></p>"},{"location":"weaver/getting-started/guide/","title":"Using Weaver","text":"<p>The easiest way to understand how Weaver works is to run it at a small scale:</p> <ul> <li>First, launch a set of basic test networks built on Fabric, Corda and Besu. These networks offer the most basic capabilities of their DLT platforms and run toy applications (contracts and Layer-2) that can easily be tracked and debugged. You can launch these networks in one of several different ways: building Weaver components and dependencies locally or importing pre-built ones from Github packages, running core components in the host or in Docker containers. The choice depends on whether you just want to get these networks up and running or if you wish to customize the setup by modifying source code and configurations.</li> <li>Once the test networks are launched, you can test two distinct kinds of interoperation modes:<ul> <li>Data sharing: all combinations of Fabric and Corda networks supported</li> <li>Asset exchange: all pairs of network types from {Fabric, Corda, Besu} are supported</li> <li>Asset transfer: all combinations of Fabric and Corda networks supported</li> </ul> </li> <li>(To bring down the test networks, go back to the \"Setup\" pages and follow instructions in the respective \"Teardown\" sections.)</li> <li>After you run these tests and get a flavor of how the system and protocols work, you will be ready to move on to \"real\" networks, enhancing them with interoperation capabilities by incorporating Weaver into them. Check out the guidelines and templates for Fabric, Corda, and Besu networks.</li> </ul> <p>If you wish to go further and understand Weaver specifics, dig into the code, or contribute to the open-source project, check out the project repository. For specific information about individual Weaver components, see:</p> <ul> <li>Relay module</li> <li>Fabric and Corda drivers</li> <li>Fabric Interoperation Chaincode, Interoperation CorDapp, and Besu Interoperation Contract</li> <li>Common protobufs: compiled in JavaScript, Golang, Java, Rust and Solidity</li> <li>Fabric Interoperation SDKs in Node.js and Golang</li> <li>Corda Interoperation SDK in Kotlin/Java </li> <li>Besu Interoperation SDK in Node.js </li> <li>Sample Fabric and Corda applications for experimentation and testing</li> <li>Fabric, Corda, and Besu test network setups</li> </ul> <p>The Weaver RFCs contain detailed specifications of the models, data structures, protocols, and message formats.</p>"},{"location":"weaver/getting-started/enabling-weaver-network/corda/","title":"Corda","text":"<p>After testing the Weaver interoperation mechanisms on basic sample networks, you may be interested in finding out how you can equip an existing real network, whether in development or in production, to exercise these mechanisms. In this document, we will demonstrate how to equip a Corda network and application with Weaver components and capabilities.</p>"},{"location":"weaver/getting-started/enabling-weaver-network/corda/#model","title":"Model","text":"<p>The figure below illustrates a typical Corda network. The infrastructure consists of a set of nodes (each maintaining its share of the global state in a local vault), notaries, and CAs. On the nodes are installed one or more CorDapps, representing shared business logic across subsets of those nodes. The core of a CorDapp consists of a collection of workflows (or flows) and contracts acting on states; we layer the flows above the contracts in thebelow image just to illustrate that flows represent transaction (state update) triggers, and contract validations occur during the executions of flows. Further up in the stack lie client applications associated with CorDapps that can are used to trigger flows (and by implication, contracts).</p> <p></p> <p>Such a network equipped with Weaver components and capabilities will look like the figure below. Legacy components are marked in grey and Weaver and bridging components in green.</p> <p></p> <p>The relay and driver are the only additional infrastructure that need to be installed. One or more relays can be installed, as can one or more drivers. The drivers are illustrated in the client layer rather than in the bottom layer because, though they are coupled with relays, they trigger flows just like any client application does.</p> <p>Existing CorDapp flows and contracts deployed on the network's nodes remain undisturbed. All that is required is the deployment of an Interoperation CorDapp (flows and contracts) on every node that needs to offer or consume state from foreign networks.</p> <p>Client applications will need some additional code and configuration because the decisions to exercise interoperation mechanisms (relay queries for data sharing or atomic asset exchanges) are strictly part of business logic. But Weaver's Corda Interoperation Java-Kotlin SDK offers various helper functions to ease this process and keep the adaptation to a minimum, as we wil see later in this document. Finally, an identity service must be offered by the network to expose its CAs' certificate chains to foreign networks, thereby laying the basis for interoperation. This service simply needs to offer a REST endpoint, and can be implemented as a standalone application or (more conveniently) as an augmentation of one or more of the existing client layer applications.</p>"},{"location":"weaver/getting-started/enabling-weaver-network/corda/#procedural-overview","title":"Procedural Overview","text":"<p>A Corda network is typically created in phases, in the following sequence:</p> <ol> <li>Development: This involves writing CorDapp which consists of contracts and workflows, and client layer applications. The cordapp's deployment name/ID and its transaction API must be designed first, but subsequent development of the two layers of applications can then proceed parallelly.</li> <li>Pre-Configuration: This involves creating a desired specification (as a set of configuration diles) of the network topology and the ledgers it maintains.</li> <li>Startup and Bootstrap: This is the launch phase, in which the network components and applications are started and bootstrapped (i.e., configured with initial state and operating rules).</li> </ol> <p>Assuming that the reader is familiar with this procedure, we will walk through the changes required in each phase to make your network ready for interoperation using Weaver components and code templates. This will involve code addition and adaptation, deployment of additional modules, additional configuration, and creation of additional ledger state records. The requirements and effort will vary with the mode of interoperation you wish to support in your Fabric network.</p>"},{"location":"weaver/getting-started/enabling-weaver-network/corda/#development-phase","title":"Development Phase","text":"<p>A Corda distributed application's business logic code spans three layers as illustrated in the network model:</p>"},{"location":"weaver/getting-started/enabling-weaver-network/corda/#cordapp","title":"CorDapp","text":"<p>CorDapps (Corda Distributed Applications) are distributed applications that run on the Corda platform. The goal of a CorDapp is to allow nodes to reach agreement on updates to the ledger. They achieve this goal by defining flows that Corda node owners can invoke over RPC.</p>"},{"location":"weaver/getting-started/enabling-weaver-network/corda/#for-data-sharing","title":"For Data Sharing","text":"<p>No code changes are required for Weaver enablement, because data sharing involves:</p> <ul> <li>View packaging (and optionally, encryption) logic and access control logic in a source network, and</li> <li>View validation logic in a destination network</li> </ul> <p>This logic is standard and independent of contract, workflow, and state, particulars. It is already implemented in the Interoperation CorDapp offered by Weaver. Hence you just need to deploy that CorDapp to exercise data sharing from, or to, your application CorDapp. Your application CorDapp can be oblivious of the Interoperation CorDapp's workings and of the view request-response protocol.</p>"},{"location":"weaver/getting-started/enabling-weaver-network/corda/#for-asset-exchange","title":"For Asset Exchange","text":"<p>To exchange an asset using Weaver, the asset's state on the ledger must be controlled in the following ways:</p> <ul> <li>Locked in favor of a party</li> <li>Claimed by the party to whom the asset is pledged</li> <li>Returned to the original owner if it is not claimed within a given timeframe</li> </ul> <p>In addition, the state of the asset (i.e., whether it is locked), and its current and targeted owners, must be determinable by looking at the ledger records.</p> <p>The bookkeeping logic required to maintain records of locks can be abstracted away from the particulars of a digital asset and its workflow. But as such assets and their properties (including ownership) can be, and are, encoded in an arbitrary number of ways, we cannot provide a one-size-fits all set of functions (like in the data sharing protocol) to exchange any kind of asset. Instead, we must rely on the application CorDapp managing an asset, as it knows precisely what the asset's properties are and how they can be updated and queried on the ledger.</p> <p>What Weaver offers, therefore, is the following:</p> <ul> <li>Lock management logic implemented in the Interoperation CorDapp that treats each asset as an abstract object (an instance of generic corda's <code>ContractState</code>) and is agnostic of the assets' internals. It consumes (burns) the asset state and creates a new <code>HTLC</code> state that indicates that the asset is locked, while in claim and unlock new asset state is created (minted) with appropriate owner while consuming <code>HTLC</code> state. This logic can be exercised in by installing Interoperation CorDapp on the nodes.</li> <li>A set of template functions with sample (and extensible) code that must be added to the application CorDapp to augment the above lock management functions.</li> </ul> <p>Below, we list the template functions with sample code that you, as a developer, must use and adapt within your CorDapp.</p> <ul> <li> <p>Flow to get Asset State: For non-fungible assets, create a flow like:   <pre><code>class RetrieveStateAndRef(\n    val type: String, \n    val id: String\n): FlowLogic&lt;StateAndRef&lt;AssetState&gt;&gt;\n</code></pre>   And for fungible assets, create a flow like:   <pre><code>class RetrieveStateAndRef(\n    val type: String, \n    val quantity: Long\n): FlowLogic&lt;StateAndRef&lt;AssetState&gt;&gt;\n</code></pre>   The name of these flows can be anything, but the parameters should be same, and return type should <code>StateAndRef</code>. These flows are supposed to get the <code>StateAndRef</code> object to the asset state that has to be locked, which can be identified by <code>type</code> and <code>id</code> for non-fungible assets, and <code>type</code> and <code>quantity</code> for fungible assets.</p> </li> <li> <p>Flow to update owner in asset state: Create a flow like:   <pre><code>class UpdateOwnerFromPointer(\n  val statePointer: StaticPointer&lt;AssetState&gt;\n) : FlowLogic&lt;AssetState&gt;()\n</code></pre>   Again the name can be anything but the function parameter should be same, i.e. take a <code>StaticPointer</code> and return the <code>ContractState</code> of the asset involved in asset exchange. This flow is supposed to resolve the <code>StaticPointer</code> to actual asset, and update the owner of this asset to the caller of this flow.</p> </li> </ul>"},{"location":"weaver/getting-started/enabling-weaver-network/corda/#for-asset-transfer","title":"For Asset Transfer","text":"<p>TBD</p>"},{"location":"weaver/getting-started/enabling-weaver-network/corda/#contracts-cordapp","title":"Contracts CorDapp","text":"<p>No code changes are required for Weaver enablement. For asset exchange, Weaver assumes that application CorDapp that manages assets must already have a asset creation (mint) contract command and asset deletion (burn) contract command, which can be invoked when <code>Issuer</code> party is involved in the transaction.</p>"},{"location":"weaver/getting-started/enabling-weaver-network/corda/#client-layer-applications","title":"Client Layer applications","text":"<p>Weaver provides an SDK to help you adapt your applications to exercise the various interoperability modes. These are called out as SDK Helpers in the network model illustrated earlier. Your Corda network's Client layer applications have business logic embedded in them that, broadly speaking, accept data from users and other external agents and invoke workflows from CorDapp over RPC. When you use Weaver for network interoperability, other options can be added, namely requesting and accepting data from foreign networks, and triggering locks and claims for atomic exchanges spanning two networks. Weaver's Corda Interoperation SDK offers a library to exercise these options. But this will involve modification to the application's business logic. To use Weaver's Corda SDK, you need to create a personal access token with <code>read:packages</code> access in GitHub, to access Weaver packages. You also need to add the following to your application's <code>build.gradle</code> file: <pre><code>repositories {\n  maven {\n      url https://maven.pkg.github.com/hyperledger/cacti\n      credentials {\n          username &lt;github-email&gt;\n          password &lt;github-personal-access-token&gt;\n      }\n  }\n}\ndependencies {\n  implementation(group: 'org.hyperledger.cacti.weaver.sdk.corda', name: 'weaver-sdk-corda', version: \"2.0.0-rc.2\")\n  implementation(group: 'org.hyperledger.cacti.weaver.imodule.corda', name: 'interop-contracts', version: \"2.0.0-rc.2\")\n  implementation(group: 'org.hyperledger.cacti.weaver.imodule.corda', name: 'interop-workflows', version: \"2.0.0-rc.2\")\n  implementation(group: 'org.hyperledger.cacti.weaver.protos', name: 'protos-java-kt', version: \"2.0.0-rc.2\")\n}\n</code></pre> (Or check out the package website and select a different version.)</p>"},{"location":"weaver/getting-started/enabling-weaver-network/corda/#for-identity-administration","title":"For Identity Administration","text":"<p>A Corda network needs to share its security domain (or membership) configuration, i.e., its nodes' CA certificate chains, with a foreign network with which it seeks to interoperate. Though such sharing can be implemented using several different mechanisms, ranging from manual to automated, the simplest and most modular way is to expose a REST endpoint that agents in foreign networks can reach. Further, this REST endpoint can be implemented as a standalone web application or it can be an extension of one or more of the existing client layer applications. (Multiple apps can expose the same endpoint serving the same information for redundancy.) We will demonstrate an example of this while leaving other implementation modes to the user. Let's say a Corda network consists of two nodes called <code>PartyA</code> and <code>PartyB</code>, each running a client layer application with a web server whose URL prefixes are <code>http://partya.mynetwork.com:9000</code> and <code>http://partyb.mynetwork.com:9000</code> respectively. Each app then can expose a REST endpoint (again, as an example) <code>http://partya.mynetwork.com:9000/node_sec_grp</code> and <code>http://partyb.mynetwork.com:9000/node_sec_grp</code> respectively. At each web server's backend, you need to implement logic to retrieve the node's ID and it's associated certificated chains. Sample code is given below for a Kotlin implementation built on <code>weaver-sdk-corda</code>. You can use this code verbatim, except for some minor changes like <code>&lt;path-to-root-corda-net-folder&gt;</code>, other parameters like security domain, and list of names of nodes as appropriate for your environment:</p> <p><pre><code>import org.hyperledger.cacti.weaver.sdk.corda.CredentialsCreator\nimport com.google.protobuf.util.JsonFormat\n\n\n@RestController\n@CrossOrigin\n@RequestMapping(\"/\") // The paths for HTTP requests are relative to this base path.\nclass Controller {\n    // Expose \"node_sec_grp\" endpoint using Rest Controller\n    @RequestMapping(value = [\"/node_sec_grp\"], method = arrayOf(RequestMethod.GET), produces = arrayOf(\"application/json\"))\n    private fun GetNetworkConfig(): String {\n        val jsonPrinter = JsonFormat.printer().includingDefaultValueFields()\n\n        val credentialsCreator = CredentialsCreator(\n            \"&lt;path-to-root-corda-net-folder&gt;/build/nodes\",\n            \"mynetwork\", // security domain name\n            [\"PartyA\", \"PartyB\"], // list of nodes \n            \"\", \n            \"\"\n        )\n\n        // Generate Membership\n        val membership = credentialsCreator.createMembership()\n        return jsonPrinter.print(membership)\n    }\n}\n</code></pre> An agent from a foreign network can query either <code>http://partya.mynetwork.com:9000/sec_group</code> or <code>http://partyb.mynetwork.com:9000/sec_group</code> and obtain the security domain (or membership) configuration of the entire network.</p>"},{"location":"weaver/getting-started/enabling-weaver-network/corda/#for-data-sharing_1","title":"For Data Sharing","text":"<p>Consider a scenario inspired by the global trade use case where a letter of credit (L/C) management business logic is installed in the <code>trade-finance-network</code> network, supports a flow named <code>UploadBillOfLading</code>, which validates and records a bill of lading (B/L) supplied by a user via a UI. Weaver will enable such a B/L to be fetched from a different network <code>trade-logistics-network</code> by querying the function <code>GetBillOfLading</code> exposed by the chaincode <code>shipmentcc</code> installed in the <code>tradelogisticschannel</code> channel (The trade logistics network can be built on Corda as well. The steps for Weaver-enablement will mostly be the same, with the exception of view address creation logic. Here, for demonstration purposes, we assume that that counter-party network is built on Fabric).</p> <p>(In preparation, a suitable access control policy must be recorded on <code>tradelogisticschannel</code> in <code>trade-logistics-network</code>, and a suitable verification policy must be recorded in the vault of <code>trade-finance-network</code>. We will see how to do this in the Startup and Bootstrap Weaver Components section later.)</p> <p>You will need to insert some code in the client layer application that accepts a B/L and submits a <code>UploadBillOfLading</code> request in <code>trade-finance-network</code>. (No code changes need to be made in any application in the other network.) The logic to accept a B/L should be replaced (or you can simply add an alternative) by a call to the <code>InteroperableHelper.interopFlow</code> function offered by the cacti-weaver-sdk-corda library. The following code sample illustrates this:</p> <pre><code>import org.hyperledger.cacti.weaver.sdk.corda.InteroperableHelper\nimport com.mynetwork.flow.UploadBillOfLading\n\nval viewAddress = InteroperableHelper.createFabricViewAddress(\n  'trade-logistics-network',               // Security Domain/Group\n  &lt;trade-logistics-relay-url[:&lt;port&gt;],     // Replace with remote network's relay\n  'tradelogisticschannel',                 // Remote network's channel\n  'shipmentcc',                            // Remote network's cc\n  'GetBillOfLading',                       // Remote network's cc Fun\n  [ &lt;shipment-reference&gt; ]                 // Replace &lt;shipment-reference&gt; with a value that can be used to look up the right B/L\n)\ntry {\n  val response = InteroperableHelper.interopFlow(\n      proxy,                                // CordaRPCOps instance to start flows\n      viewAddress,\n      &lt;trade-finance-relay-url&gt;[:&lt;port&gt;]   // Replace with local network's relay address and port\n  ).fold({\n      println(\"Error in Interop Flow: ${it.message}\")\n  }, {\n      val linearId = it.toString()\n      val BoLString = InteroperableHelper.getExternalStatePayloadString(\n          proxy,\n          linearId\n      )\n      val result = proxy.startFlow(::UploadBillOfLading, BoLString)\n      println(\"$result\")\n  }\n} catch (e: Exception) {\n  println(\"Error: ${e.toString()}\")\n}\n</code></pre> <p>Let us understand this code snippet better. The function <code>UploadBillOfLading</code> expects one argument, the bill of lading contents. The <code>InteroperableHelper.createFabricViewAddress</code> is used to create view address that is to passed to <code>InteroperableHelper.interopFlow</code> function. The equivalent function to create a view address for a remote Corda network is <code>InteroperableHelper.createCordaViewAddress</code>. </p> <p>The rest of the code ought to be self-explanatory. Values are hardcoded for explanation purposes.</p> <p>Enabling TLS: By default, the TLS is set to false in <code>interopFlow</code>, i.e. disabled. But if you want to enable TLS, can pass additional parameters to the <code>interopFlow</code> function as follows: <pre><code>val response = InteroperableHelper.interopFlow(\n    proxy,                                // CordaRPCOps instance to start flows\n    viewAddress,\n    &lt;trade-finance-relay-url&gt;[:&lt;port&gt;],   // Replace with local network's relay address and port\n    'trade-finance-network',              // Local network name (destination)\n    true,                                 // Boolean indication TLS is enabled.\n    &lt;relayTlsTrustStorePath&gt;              // JKS file path containing relay server TLS CA certificates\n    &lt;relayTlsTrustStorePassword&gt;,         // password used to create the JKS file\n)\n</code></pre> OR <pre><code>val response = InteroperableHelper.interopFlow(\n    proxy,                                // CordaRPCOps instance to start flows\n    viewAddress,\n    &lt;trade-finance-relay-url&gt;[:&lt;port&gt;],   // Replace with local network's relay address and port\n    'trade-finance-network',              // Local network name (destination)\n    true,                                 // Boolean indication TLS is enabled.\n    &lt;tlsCACertPathsForRelay&gt;,             // colon-separated list of CA certificate file paths\n)\n</code></pre></p>"},{"location":"weaver/getting-started/enabling-weaver-network/corda/#for-asset-exchange_1","title":"For Asset exchange","text":"<p>Let's take an example of asset exchange between <code>Alice</code> and <code>Bob</code>, where Bob wants to purchase an asset of type <code>Gold</code> with id <code>A123</code> from <code>Alice</code> in <code>BondNetwork</code> in exchange for <code>200</code> tokens of type <code>CBDC01</code> in <code>TokenNetwork</code>.</p> <p><code>Alice</code> needs to select a secret text (say <code>s</code>), and hash it (say <code>H</code>) using say <code>SHA512</code>, which will be used to lock her asset in <code>BondNetwork</code>. To lock the non-fungible asset using hash <code>H</code> and timeout duration of 10 minutes, you need to add following code snippet in your application: <pre><code>import org.hyperledger.cacti.weaver.sdk.corda.AssetManager\nimport org.hyperledger.cacti.weaver.sdk.corda.HashFunctions\n\nvar hash: HashFunctions.Hash = HashFunctions.SHA512\nhash.setSerializedHashBase64(H)\nval proxy = &lt;CordaRPCOps-instance-created-using-credentials-of-Alice-in-BondNetwork&gt;\nval issuer = &lt;Issuer-party-in-BondNetwork&gt;\nval recipient = &lt;Bob-party-in-BondNetwork&gt;\nval contractId = AssetManager.createHTLC(\n  proxy,          \n  \"Gold\",         // Type\n  \"A123\",         // ID\n  recipient, \n  hash,           \n  10L,            // Duration tmeout in secs, L denotes Long\n  1,              // 1 if timeout is Duration, 0 if timeout is in absolute epochs\n  \"com.cordaSimpleApplication.flow.RetrieveStateAndRef\", // full name of \"Flow to get Asset State\"\n  AssetContract.Commands.Delete(),  // Contract command for Asset to Burn/Delete the state\n  issuer,\n  observers       // Optional parameter for list of observers for this transaction\n)\n</code></pre></p> <p>Now <code>Bob</code> will lock his tokens in <code>TokenNetwork</code>. To lock the fungible asset using same hash <code>H</code> and timeout of 5 minutes (half the timeout duration used by Alice in <code>BondNetwork</code>), add following code snippet in your application: <pre><code>import org.hyperledger.cacti.weaver.sdk.corda.AssetManager\nimport org.hyperledger.cacti.weaver.sdk.corda.HashFunctions\n\nvar hash: HashFunctions.Hash = HashFunctions.SHA512\nhash.setSerializedHashBase64(H)\nval proxy = &lt;CordaRPCOps-instance-created-using-credentials-of-Bob-in-TokenNetwork&gt;\nval issuer = &lt;Issuer-party-in-TokenNetwork&gt;\nval recipient = &lt;Alice-party-in-TokenNetwork&gt;\nval contractId = AssetManager.createFungibleHTLC(\n  proxy,          \n  \"CBDC01\",       // Type\n  \"200\",          // Quantity\n  recipient, \n  hash,           \n  5L,             // Duration timeout in secs, L denotes Long\n  1,              // 1 if timeout is Duration, 0 if timeout is in absolute epochs\n  \"com.cordaSimpleApplication.flow.RetrieveStateAndRef\", // full name of \"Flow to get Asset State\"\n  AssetContract.Commands.Delete(),  // Contract command for Asset to Burn/Delete the state\n  issuer,\n  observers       // Optional parameter for list of observers for this transaction\n)\n</code></pre></p> <p>The above locks will return <code>contractId</code>, that has to be stored and will be used in other HTLC functions.</p> <p>To query whether the assets are locked or not in any network, use following query function: <pre><code>val isLockedBoolean = AssetManager.isAssetLockedInHTLC(\n  rpc.proxy, \n  contractId\n)\n</code></pre></p> <p>Now to claim the asset using the secret text (pre-image of hash) <code>s</code>, add following code snippet: <pre><code>var hash: HashFunctions.Hash = HashFunctions.SHA512()\nhash.setPreimage(s)\nval issuer = &lt;Issuer-party&gt;\nval proxu = &lt;CordaRPCOps-instance-created-using-credentials-of-claiming-party&gt;\nval res = AssetManager.claimAssetInHTLC(\n  proxy, \n  contractId,                       // ContractId obtained during lock\n  hash,\n  AssetContract.Commands.Issue(),   // Contract command for issuing/minting asset\n  \"com.cordaSimpleApplication.flow.UpdateAssetOwnerFromPointer\", // full name of flow to update owner in asset state\n  issuer,\n  observers                         // Optional parameter for list of observers for this transaction\n)   \n// return value is boolean indicating success or failure of claim \n</code></pre> The above function can be adapted to both <code>BondNetwork</code> and <code>TokenNetwork</code>.</p> <p>If the asset has to be unlocked, use following code snippet: <pre><code>val issuer = &lt;Issuer-party&gt;\nval proxu = &lt;CordaRPCOps-instance-created-using-credentials-of-locking-party&gt;\nval res = AssetManager.reclaimAssetInHTLC(\n  rpc.proxy, \n  contractId,                       // ContractId obtained during lock\n  AssetContract.Commands.Issue(),   // Contract command for issuing/minting asset\n  issuer,\n  observers                         // Optional parameter for list of observers for this transaction\n) \n// return value is boolean indicating success or failure of claim \n</code></pre></p>"},{"location":"weaver/getting-started/enabling-weaver-network/corda/#for-asset-transfer_1","title":"For Asset Transfer","text":"<p>TBD</p>"},{"location":"weaver/getting-started/enabling-weaver-network/corda/#pre-configuration-phase","title":"Pre-Configuration Phase","text":"<p>No changes are required in your network's pre-configuration process for Weaver enablement.</p> <p>Typically, pre-configuration involves:</p> <ul> <li> <p>Generating node folders for each participating node in the network, which contains CorDapps, certificates,  persistence db, etc sub directories. Using Gradle task <code>net.corda.plugins.Cordform</code> or <code>net.corda.plugins.Dockerform</code>, the folders get created under the directory <code>build/nodes</code> (this path is used in above sample code for Identity Service).</p> </li> <li> <p>The RPC address, username and password specified in above task will be used to create an instance of <code>CordaRPCOps</code>, which is the first argument for most <code>weaver-sdk-corda</code> static functions as we saw in previous section. For example, one of them is <code>InteroperableHelper.interopFlow</code>: <pre><code>val response = InteroperableHelper.interopFlow(\n    proxy,                                // CordaRPCOps instance to start flows\n    viewAddress,\n    &lt;trade-finance-relay-url&gt;[:&lt;port&gt;],   // Replace with local network's relay address and port\n)\n</code></pre> Also, the Corda Driver (which we will setup in the following sections) needs a specific RPC user to be created, so make sure to add that in the Gradle task above, and note the credentials.</p> </li> <li> <p>Sample <code>net.corda.plugins.Dockerform</code> task: <pre><code>task prepareDockerNodes(type: net.corda.plugins.Dockerform, dependsOn: ['jar']) {\n    def HOST_ADDRESS = \"0.0.0.0\"\n    nodeDefaults {\n        projectCordapp {\n            deploy = false\n        }\n    }\n    node {\n        name \"O=Notary,L=London,C=GB\"\n        notary = [validating : true]\n        p2pPort 10004\n        rpcSettings {\n            address(\"$HOST_ADDRESS:10003\")\n            adminAddress(\"$HOST_ADDRESS:10005\")\n        }\n        cordapps.clear()\n    }\n    node {\n        name \"O=PartyA,L=London,C=GB\"\n        p2pPort 10007\n        rpcSettings {\n            address(\"$HOST_ADDRESS:10003\")\n            adminAddress(\"$HOST_ADDRESS:10005\")\n        }\n        rpcUsers = [\n                [ user: \"user1\", \"password\": \"test\", \"permissions\": [\"ALL\"]],\n                [ user: \"driverUser1\", \"password\": \"test\", \"permissions\": [\"ALL\"]]] // &lt;-- Driver RPC User\n    }\n    node {\n        name \"O=PartyB,L=London,C=GB\"\n        p2pPort 10009\n        rpcSettings {\n            address(\"$HOST_ADDRESS:10003\")\n            adminAddress(\"$HOST_ADDRESS:10005\")\n        }\n        rpcUsers = [\n                [ user: \"user1\", \"password\": \"test\", \"permissions\": [\"ALL\"]],\n                [ user: \"driverUser1\", \"password\": \"test\", \"permissions\": [\"ALL\"]]] // &lt;-- Driver RPC User\n    }\n}\n</code></pre></p> </li> </ul>"},{"location":"weaver/getting-started/enabling-weaver-network/corda/#startup-and-bootstrap-phase","title":"Startup and Bootstrap Phase","text":"<p>To launch a network using containerized components, you will typically use a Docker Compose or Kubernetes configuration file. No modifications are needed to the node's configurations. Sample instructions are given below for networks launched using Docker Compose; we leave it to the reader to adapt these to their custom launch processes.</p>"},{"location":"weaver/getting-started/enabling-weaver-network/corda/#for-asset-exchange_2","title":"For Asset Exchange","text":"<p>The asset exchange mode currently requires only the Interoperation CorDapp module from Weaver. Relays and drivers are not necessary. In the future, we expect to make the asset exchange protocol moe automated using these components; the instructions here will be updated appropriately.</p>"},{"location":"weaver/getting-started/enabling-weaver-network/corda/#install-interoperation-cordapp-on-nodes","title":"Install Interoperation CorDapp on Nodes","text":"<p>After bootstrapping the nodes folder, copy the following two CorDapps in <code>build/nodes/PartyA/cordapps</code> and <code>build/nodes/PartyB/cordapps</code> folders (<code>PartyA</code> and <code>PartyB</code> node names are for example only):</p> <ul> <li>org.hyperledger.cacti.weaver.imodule.corda.interop-contracts</li> <li>org.hyperledger.cacti.weaver.imodule.corda.interop-workflows</li> </ul> Notes You can follow any installation process for this CorDapp, but make sure it is installed on all the nodes that maintain the states involved in cross-network operations in their vaults."},{"location":"weaver/getting-started/enabling-weaver-network/corda/#for-data-sharing-or-asset-transfer","title":"For Data Sharing or Asset Transfer","text":"<p>Both the data sharing and asset transfer modes require the Interoperation CorDapp, relays, and drivers, to be deployed.</p>"},{"location":"weaver/getting-started/enabling-weaver-network/corda/#install-interoperation-cordapp-on-nodes_1","title":"Install Interoperation CorDapp on Nodes","text":"<p>After bootstrapping the nodes folder, copy the following two CorDapps in <code>build/nodes/PartyA/cordapps</code> and <code>build/nodes/PartyB/cordapps</code> folders (<code>PartyA</code> and <code>PartyB</code> node names are for example only):</p> <ul> <li>org.hyperledger.cacti.weaver.imodule.corda.interop-contracts</li> <li>org.hyperledger.cacti.weaver.imodule.corda.interop-workflows</li> </ul> Notes You can follow any installation process for this CorDapp, but make sure it is installed on all the nodes that maintain the states involved in cross-network operations in their vaults."},{"location":"weaver/getting-started/enabling-weaver-network/corda/#launch-relay","title":"Launch Relay","text":"<p>You need to run one or more relays for network-to-network communication. Here we provide instructions to run one relay running in a Docker container, which is sufficient for data sharing. (Later, we will provide instructions to run multiple relays, which will be useful from a failover perspective.)</p> <p>Weaver provides a pre-built image for the relay. Before launching a container, you just need to customize its configuration for your Fabric network, which you can do by simply creating a folder (let's call it <code>relay_config</code>) and configuring the following files in it:</p> <ul> <li><code>.env</code>: This sets suitable environment variables within the relay container. Copy the <code>.env.template</code> file from the repository and customize it for your purposes, as indicated in the below sample:   <pre><code>PATH_TO_CONFIG=./config.toml\nRELAY_NAME=&lt;\"name\" in config.toml&gt;\nRELAY_PORT=&lt;relay-server-port/\"port\" in config.toml&gt;\nEXTERNAL_NETWORK=&lt;docker-bridge-network&gt;\nDOCKER_IMAGE_NAME=ghcr.io/hyperledger/cacti-weaver-relay-server\nDOCKER_TAG=2.0.0-rc.2\n</code></pre><ul> <li>The <code>PATH_TO_CONFIG</code> variable should point to the properties file typically named <code>config.toml</code> (you can name this whatever you wish). See further below for instructions to write this file.</li> <li>The <code>RELAY_NAME</code> variable specifies a unique name for this relay. It should match what's specified in the <code>config.toml</code> (more on that below).</li> <li>The <code>RELAY_PORT</code> variable specifies the port this relay server will listen on. It should match what's specified in the <code>config.toml</code> (more on that below).</li> <li>The <code>EXTERNAL_NETWORK</code> variable should be set to the name of your Fabric network.</li> <li>The <code>DOCKER_*</code> variables are used to specify the image on which the container will be built. Make sure you set <code>DOCKER_TAG</code> to the latest version you see on GitHub.</li> </ul> </li> </ul> <p>For more details, see the Relay Docker README (\"Relay Server Image\" and \"Running With Docker Compose\" sections).</p> <ul> <li><code>config.toml</code>: This is the file specified in the <code>PATH_TO_CONFIG</code> variable in the <code>.env</code>. It specifies properties of this relay and the driver(s) it supports. A sample is given below:   <pre><code>name=&lt;relay-name&gt;\nport=&lt;relay-port&gt;\nhost=\"0.0.0.0\"\ndb_path=\"db/&lt;relay-name&gt;/requests\"\nremote_db_path=\"db/&lt;relay-name&gt;/remote_request\"\n\n# FOR TLS\ncert_path=\"credentials/fabric_cert.pem\"\nkey_path=\"credentials/fabric_key\"\ntls=&lt;true/false&gt;\n\n[networks]\n[networks.&lt;network-name&gt;]\nnetwork=\"&lt;driver-name&gt;\"\n\n[relays]\n[relays.&lt;foreign-relay-name&gt;]\nhostname=\"&lt;foreign-relay-hostname-or-ip-address&gt;\"\nport=\"&lt;foreign-relay-port&gt;\"\n\n[drivers]\n[drivers.&lt;driver-name&gt;]\nhostname=\"&lt;driver-hostname-or-ip-address&gt;\"\nport=\"&lt;driver-port&gt;\"\n</code></pre><ul> <li><code>&lt;relay-name&gt;</code> should be a unique ID representing this relay; e.g., <code>my_network_relay</code>. It should match the <code>RELAY_NAME</code> value in <code>.env</code>.</li> <li><code>&lt;relay-port&gt;</code> is the port number the relay server will listen on. It should match the <code>RELAY_PORT</code> value in <code>.env</code>.</li> <li><code>db_path</code> and <code>remote_db_path</code> are used internally by the relay to store data. Replace <code>&lt;relay-name&gt;</code> with the same value set for the <code>name</code> parameter. (These can point to any filesystem paths in the relay's container.)</li> <li>If you set <code>tls</code> to <code>true</code>, the relay will enforce TLS communication. The <code>cert_path</code> and <code>key_path</code> should point to a Fabric TLS certificate and key respectively, such as those created using the <code>cryptogen</code> tool.</li> <li><code>&lt;network-name&gt;</code> is a unique identifier for your local network. You can set it to whatever value you wish.</li> <li><code>&lt;driver-name&gt;</code> refers to the driver used by this relay to respond to requests. This also refers to one of the drivers's specifications in the <code>drivers</code> section further below. In this code snippet, we have defined one driver. (The names in lines 14 and 22 must match.) In lines 23 and 24 respectively, you should specify the hostname and port for the driver (whose configuration we will handle later).</li> <li>The <code>relays</code> section specifies all foreign relays this relay can connect to. The <code>&lt;foreign-relay-name&gt;</code> value should be a unique ID for a given foreign relay, and this value will be used by your Layer-2 applications when constructing view addresses for data sharing requests. In lines 18 and 19, you should specify the hostname and port for the foreign relay.</li> <li>Enabling TLS:<ul> <li>You can make your relay accept TLS connections by specifying a TLS certificate file path and private key file path in <code>cert_path</code> and <code>key_path</code> respectively, and set <code>tls</code> to <code>true</code>.</li> <li>To communicate with a foreign relay using TLS, specify that relay's TLS CA certificate path in <code>tlsca_cert_path</code> (currently only one certificate can be configured) and set <code>tls</code> to <code>true</code> by extending that relay's section as follows (Note: this CA certificate should match the one specified in the <code>cert_path</code> property in the foreign relay's <code>config.toml</code> file):   <pre><code>[relays]\n[relays.&lt;foreign-relay-name&gt;]\nhostname=\"&lt;foreign-relay-hostname-or-ip-address&gt;\"\nport=\"&lt;foreign-relay-port&gt;\"\ntls=&lt;true|false&gt;\ntlsca_cert_path=\"&lt;relay-tls-ca-certificate-path&gt;\"\n</code></pre></li> <li>To communicate with a driver using TLS, specify the driver's TLS CA certificate in <code>tlsca_cert_path</code> (currently only one certificate can be configured) and set <code>tls</code> to <code>true</code> by extending that driver's section as follows (Note: this CA certificate must match the certificate used by the driver using the <code>DRIVER_TLS_CERT_PATH</code> property in its <code>.env</code> configuration file, which we will examine later):   <pre><code>[drivers]\n[drivers.&lt;driver-name&gt;]\nhostname=\"&lt;driver-hostname-or-ip-address&gt;\"\nport=\"&lt;driver-port&gt;\"\ntls=&lt;true|false&gt;\ntlsca_cert_path=\"&lt;driver-tls-ca-certificate-path&gt;\"\n</code></pre></li> </ul> </li> </ul> </li> </ul> Notes You can specify more than one foreign relay instance in the <code>relays</code> section. You can specify more than one driver instance in the <code>drivers</code> section. <ul> <li><code>docker-compose.yaml</code>: This specifies the properties of the relay container. You can use the file in the repository verbatim.</li> </ul> <p>To start the relay server, navigate to the folder containing the above files and run the following: <pre><code>docker compose up -d relay-server\n</code></pre></p>"},{"location":"weaver/getting-started/enabling-weaver-network/corda/#launch-driver","title":"Launch Driver","text":"<p>You need to run one or more drivers through which your relay can interact with your Corda network. Here we provide instructions to run one Corda driver running in a Docker container, which is sufficient for data sharing. (Later, we will provide instructions to run multiple drivers, which will be useful both from a failover perspective and to interact with different subsets of your Corda network.)</p> <p>Weaver provides a pre-built image for the Corda driver. Before launching a container, you just need to customize the container configuration for your Corda network, which you can do by simply configuring the following:</p> <ul> <li> <p><code>.env</code>: This sets suitable environment variables within the driver container. Copy the <code>.env.docker.template</code> file from the repository and customize it for your purposes, as indicated in the below sample:   <pre><code>NETWORK_NAME=&lt;container-name-suffix&gt;\nDRIVER_PORT=&lt;driver-server-port&gt;\nDRIVER_RPC_USERNAME=&lt;driver-rpc-username&gt;\nDRIVER_RPC_PASSWORD=&lt;driver-rpc-username&gt;\nEXTERNAL_NETWORK=&lt;docker-bridge-network&gt;\nDOCKER_IMAGE_NAME=ghcr.io/hyperledger/cacti-weaver-driver-corda\nDOCKER_TAG=2.0.0-rc.2\nRELAY_TLS=&lt;true|false&gt;\nRELAY_TLSCA_TRUST_STORE=&lt;truststore-jks-file-path&gt;\nRELAY_TLSCA_TRUST_STORE_PASSWORD=&lt;truststore-jks-file-password&gt;\nRELAY_TLSCA_CERT_PATHS=&lt;colon-separated-CA-cert-paths&gt;\nDRIVER_TLS=&lt;true|false&gt;\nDRIVER_TLS_CERT_PATH=&lt;cert-path&gt;\nDRIVER_TLS_KEY_PATH=&lt;private-key-path&gt;\n</code></pre></p> <ul> <li><code>NETWORK_NAME</code> is only used as suffix for container and has no other significance.</li> <li><code>DRIVER_PORT</code> variable should be set to the port this driver will listen on.</li> <li><code>DRIVER_RPC_USERNAME</code> variable should be set to rpc user created above for the driver.</li> <li><code>DRIVER_RPC_PASSWORD</code> variable should be set to password of above rpc user.</li> <li><code>EXTERNAL_NETWORK</code> variable should be set to the name of your Corda network.</li> <li>Enabling TLS:<ul> <li>You can make your driver accept TLS connections by specifying <code>DRIVER_TLS</code> as <code>true</code> and specifying a TLS certificate file path and private key file path in <code>DRIVER_TLS_CERT_PATH</code> and <code>DRIVER_TLS_KEY_PATH</code> respectively. The same certificate should be specified in this driver's definition in the <code>drivers</code> section in the <code>config.toml</code> file of your relay in the <code>tlsca_cert_path</code> property (see the earlier section on relay configuration).</li> <li>To communicate with your network' relay using TLS (i.e., if the relay is TLS-enabled), specify that relay's TLS CA certificate path in <code>RELAY_TLSCA_CERT_PATH</code> (currently only one certificate can be configured) and set <code>RELAY_TLS</code> to <code>true</code>. This CA certificate should match the one specified in the <code>cert_path</code> property in the relay's <code>config.toml</code> file (see the earlier section on relay configuration):</li> <li>You can point to the folder in your host system containing the certificate and key using the <code>TLS_CREDENTIALS_DIR</code> variable. (This folder will be synced to the <code>/corda-driver/credentials</code> folder in the Fabric Driver container as specified in the docker compose file.) Make sure you point to the right certificate and key file paths within the container using the <code>DRIVER_TLS_CERT_PATH</code>, <code>DRIVER_TLS_KEY_PATH</code>, and <code>RELAY_TLSCA_CERT_PATH</code> variables.</li> </ul> </li> </ul> </li> <li> <p><code>docker-compose.yaml</code>: This specifies the properties of the driver container. You can use the file in the repository verbatim.</p> </li> </ul> <p>To start the driver, navigate to the folder containing the above files and run the following: <pre><code>docker compose up -d\n</code></pre></p>"},{"location":"weaver/getting-started/enabling-weaver-network/corda/#vault-initialization","title":"Vault Initialization","text":"<p>To prepare your network for interoperation with a foreign network, you need to record the following to your vault using the Corda SDK (<code>org.hyperledger.cacti.weaver.sdk.corda.weaver-sdk-corda</code>):</p> <ul> <li>Access control policies:   Let's take the example of the request made from <code>trade-finance-network</code> to <code>trade-logistics-network</code> for a B/L earlier in this document. <code>trade-logistics-network</code> can have a policy of the following form permitting access to the <code>GetBillOfLading</code> function from a client representing the <code>PartyA</code> node in <code>trade-finance-network</code> as follows:   <pre><code>{\n    \"securityDomain\":\"trade-finance-network\",\n    \"rules\":\n        [\n            {\n                \"principal\":\"&lt;PartyA-certificate-pem&gt;\",\n                \"principalType\":\"certificate\",\n                \"resource\":\"exporternode:10003;carriernode:10003#com.mynetwork.flow.GetBillOfLading:*\",\n                \"read\":true\n            }\n        ]\n}\n</code></pre>   In this sample, a single rule is specified for requests coming from <code>trade-finance-network</code>: it states that a workflow call to <code>com.mynetwork.flow.GetBillOfLading</code> made to <code>exporter</code> and <code>carrier</code> nodes of remote Corda network is permitted for a requestor whose certificate is specified in the <code>principal</code> attribute. The <code>*</code> at the end indicates that any arguments passed to the function will pass the access control check. The <code>exporternode:10003</code> and <code>carriernode:10003</code> are of form <code>&lt;hostname/IP&gt;:&lt;RPC_Port&gt;</code>, for <code>exporter</code> and <code>carrier</code> nodes respectively in the remote Corda network.</li> </ul> <p>You need to record this policy rule on your Corda network's vault by invoking either the <code>AccessControlPolicyManager.createAccessControlPolicyState</code> function or the <code>AccessControlPolicyManager.updateAccessControlPolicyState</code> function on the <code>weaver-sdk-corda</code>; use the former if you are recording a set of rules for the given <code>securityDomain</code> for the first time and the latter to overwrite a set of rules recorded earlier. The above JSON needs to be converted to protobuf object of <code>org.hyperledger.cacti.weaver.protos.common.access_control.AccessControl.AccessControlPolicy</code>, using google's protobuf library, and the object is the second argument of above functions (first being the instance of CordaRPCOps).</p> <ul> <li>Verification policies:   Taking the same example as above, an example of a verification policy for a B/L requested by the <code>trade-finance-network</code> from the <code>trade-logistics-network</code> is as follows:   <pre><code>{\n    \"securityDomain\":\"trade-logistics-network\",\n    \"identifiers\":\n        [\n            {\n                \"pattern\":\"tradelogisticschannel:shipmentcc:GetBillOfLading:*\",\n                \"policy\":\n                    {\n                        \"type\":\"Signature\",\n                        \"criteria\":\n                            [\n                                \"ExporterMSP\",\n                                \"CarrierMSP\"\n                            ]\n                    }\n            }\n        ]\n}\n</code></pre>   In this sample, a single verification policy rule is specified for data views coming from <code>trade-logistics-network</code>: it states that the data returned by the <code>GetBillOfLading</code> query made to the <code>shipmentcc</code> chaincode on the <code>tradelogisticschannel</code> channel requires as proof two signatures, one from a peer in the organization whose MSP ID is <code>ExporterMSP</code> and another from a peer in the organization whose MSP ID is <code>CarrierMSP</code>.</li> </ul> Notes If the remote network is built on Corda, the resource specified in the access control policy can be used here as the <code>pattern</code>, with different node names specified in the <code>criteria</code>. <p>You need to record this policy rule on your Corda network's vault by invoking Corda sdk's function <code>VerificationPolicyManager.createVerificationPolicyState(proxy, verificationPolicyProto)</code>, where <code>proxy</code> is an instance of <code>CordaRPCOps</code> as described in previous sections, and <code>verificationPolicyProto</code> is an object of protobuf <code>org.hyperledger.cacti.weaver.protos.common.verification_policy.VerificationPolicyOuterClass.VerificationPolicy</code>. You can examine the full proto structure here. (Google's protobuf library can be used to convert above JSON to protobuf object.)</p> Notes For any cross-network data request, make sure an access control policy is recorded in the source network (<code>trade-logistics-network</code> in the above example) and a corresponding verification policy is recorded in the destination network (<code>trade-finance-network</code> in the above example) before any relay request is triggered. <ul> <li>Foreign network security domain (membership) configuration:   Run the following procedure (pseudocode) to record security domain configuration for every foreign network you wish your Corda network to interoperate with (you will need to collect the identity service URLs for all the foreign networks first):   <pre><code>for each foreign network:\n    send an HTTP GET request to the network's identity service (using 'curl' or 'wget' from a shell script or equivalent programming language APIs).\n    convert the response string to protobuf object of 'org.hyperledger.cacti.weaver.protos.common.membership.MembershipOuterClass.Membership'.\n    invoke 'MembershipManager.createMembershipState(proxy, membershipProto)' or 'MembershipManager.updateMembershipState(proxy, membershipProto)' on Corda sdk.\n</code></pre>   As in the above two cases, use <code>createMembershipState</code> to record a confiuration for the first time for a given <code>securityDomain</code> and <code>updateMembershipState</code> to overwrite a configuration.</li> </ul> Notes Security domain configurations (organization lists and their certificate chains) for any Fabric/Corda network are subject to change, so you should run the above procedure periodically in a loop. <p>Your Corda network is now up and running with the necessary Weaver components, and your network's vault is bootstrapped with the initial configuration necessary for cross-network interactions!</p>"},{"location":"weaver/getting-started/enabling-weaver-network/fabric/","title":"Hyperledger Fabric","text":"<p>After testing the Weaver interoperation mechanisms on basic sample networks, you may be interested in finding out how you can equip an existing real network, whether in development or in production, to exercise these mechanisms. In this document, we will demonstrate how to equip a Fabric network and application with Weaver components and capabilities.</p>"},{"location":"weaver/getting-started/enabling-weaver-network/fabric/#model","title":"Model","text":"<p>The figure below illustrates a typical Fabric network. The infrastructure consists of a set of peers, ordering service nodes, and CAs that perform the roles of MSPs; each serves a given organization which is one of the constituent units of the network. On the peers are installed one or more smart contracts (chaincode), representing shared business logic across the different organizations. Further up lie the so-called Layer-2 (or client) applications that consist of organization-specific business logic and invoke the smart contracts using APIs exposed by the Fabric SDK and with wallet credentials issued by their respective organizations' CAs.</p> <p></p> <p>Such a network equipped with Weaver components and capabilities will look like the figure below. Legacy components are marked in grey and Weaver and bridging components in green.</p> <p></p> <p>The relay and driver are the only additional infrastructure that need to be installed. One or more relays can be installed, as can one or more drivers. The drivers are illustrated in Layer-2 rather than in the bottom layer because, though they are coupled with relays, they exercise contracts using the Fabric SDK and organization-issued credentials just like any Layer-2 application does.</p> <p>Existing chaincode deployed on the network's channels remain undisturbed. All that is required in the smart contracts layer is the deployment of the Fabric Interoperation Chaincode on every channel that needs to offer or consume state from foreign networks.</p> <p>Layer-2, or client, applications will need some additional code and configuration because the decisions to exercise interoperation mechanisms (relay queries for data sharing or atomic asset exchanges) are strictly part of business logic. But Weaver's Fabric Interoperation Node SDK offers various helper functions to ease this process and keep the adaptation to a minimum, as we wil see later in this document. Finally, an identity service must be offered by the network to expose its CAs' certificate chains to foreign networks, thereby laying the basis for interoperation. This service simply needs to offer a REST endpoint, and can be implemented as a standalone application or (more conveniently) as an augmentation of one or more of the existing Layer-2 applications.</p>"},{"location":"weaver/getting-started/enabling-weaver-network/fabric/#procedural-overview","title":"Procedural Overview","text":"<p>A Hyperledger Fabric network is typically created in phases, in the following sequence:</p> <ol> <li>Development: This involves writing chaincode and Layer-2 applications. The chaincode's deployment name/ID and its transaction API must be designed first, but subsequent development of the two layers of applications can then proceed parallelly.</li> <li>Pre-Configuration: This involves creating a desired specification (as a set of configuration diles) of the network topology and the ledgers it maintains.</li> <li>Startup and Bootstrap: This is the launch phase, in which the network components and applications are started and bootstrapped (i.e., configured with initial state and operating rules).</li> </ol> <p>Assuming that the reader is familiar with this procedure, we will walk through the changes required in each phase to make your network ready for interoperation using Weaver components and code templates. This will involve code addition and adaptation, deployment of additional modules, additional configuration, and creation of additional ledger state records. The requirements and effort will vary with the mode of interoperation you wish to support in your Fabric network.</p>"},{"location":"weaver/getting-started/enabling-weaver-network/fabric/#development-phase","title":"Development Phase","text":"<p>A Fabric distributed application's business logic code spans two layers as illustrated in the network model.</p>"},{"location":"weaver/getting-started/enabling-weaver-network/fabric/#chaincode","title":"Chaincode","text":"<p>These are smart contracts embodied in code, managing business workflow state and digital assets.</p>"},{"location":"weaver/getting-started/enabling-weaver-network/fabric/#for-data-sharing","title":"For Data Sharing","text":"<p>No code changes are required for Weaver enablement, because data sharing involves:</p> <ul> <li>View packaging (and optionally, encryption) logic and access control logic in a source network, and</li> <li>View validation logic in a destination network</li> </ul> <p>This logic is standard and independent of smart contract, asset, and state, particulars. It is already implemented in the Fabric Interoperation Chaincode offered by Weaver. Hence you just need to deploy that chaincode to exercise data sharing from, or to, your application chaincode. Your application chaincode can be oblivious of the Fabric Interoperation Chaincode's workings and of the view request-response protocol.</p>"},{"location":"weaver/getting-started/enabling-weaver-network/fabric/#for-asset-exchange","title":"For Asset Exchange","text":"<p>To exchange an asset using Weaver, the asset's state on the ledger must be controlled in the following ways:</p> <ul> <li>Locked in favor of a party</li> <li>Claimed by the party to whom the asset is pledged</li> <li>Returned to the original owner if it is not claimed within a given timeframe</li> </ul> <p>In addition, the state of the asset (i.e., whether it is locked), and its current and targeted owners, must be determinable by looking at the ledger records.</p> <p>The bookkeeping logic required to maintain records of locks can be abstracted away from the particulars of a digital asset and its workflow. But as such assets and their properties (including ownership) can be, and are, encoded in an arbitrary number of ways, we cannot provide a one-size-fits all set of functions (like in the data sharing protocol) to exchange any kind of asset. Instead, we must rely on the application contract (chaincode) managing an asset, as it knows precisely what the asset's properties are and how they can be updated and queried on the ledger (channel).</p> <p>What Weaver offers, therefore, is the following:</p> <ul> <li>Lock management (bookkeeping) logic implemented in the Fabric Interoperation Chaincode that treats each asset as an abstract object and is agnostic of the assets' internals. This logic can be exercised in one of two ways:<ul> <li>Importing the <code>assetexchange</code> library from the Fabric Interoperation Chaincode into your application chaincode, or</li> <li>Invoking them within the Fabric Interoperation Chaincode using a chaincode-to-chaincode call.</li> </ul> </li> <li>A set of template functions with sample (and extensible) code that must be added to the application chaincode to exercise the above lock management functions.</li> </ul> <p>Below, we list the template functions with sample code that you, as a developer, must use and adapt within your chaincode, in either mode (library import or chaincode invocations).</p> Notes The instructions here apply only to chaincode implemented in Go, because Weaver presently offers only a Go version of the Fabric Interoperation Chaincode. <ul> <li>Using the <code>assetexchange</code> Library: This method doesn't require the <code>Fabric Interoperation Chaincode</code> to be installed. In your smart contract's <code>go.mod</code>, add the following in the <code>require</code> section (the sample below uses the current versions for dependency packages; update them to the latest versions offered by Cacti):   <pre><code>require(\n    ...\n    github.com/hyperledger/cacti/weaver/common/protos-go/v2 v2.0.0-rc.2\n    github.com/hyperledger/cacti/weaver/core/network/fabric-interop-cc/libs/assetexchange/v2 v2.0.0-rc.2\n    ...\n)\n</code></pre>   The following functions need to be added to your chaincode, and the smart contract class/type used below is called <code>SmartContract</code> (Note: the function signature, i.e. the name, arguments, and return values, need to be exactly what is given in the below samples; you can have additional code to manage asset state as per need):<ol> <li>LockAsset <pre><code>import (\n    ...\n    \"github.com/hyperledger/cacti/weaver/core/network/fabric-interop-cc/libs/assetexchange/v2\"\n)\nfunc (s *SmartContract) LockAsset(ctx contractapi.TransactionContextInterface, assetExchangeAgreementSerializedProto64 string, lockInfoSerializedProto64 string) (string, error) {\n    // Add some safety checks before calling LockAsset from library\n    // Caller of this chaincode is supposed to be the Locker and the owner of the asset being locked.\n    contractId, err := assetexchange.LockAsset(ctx, \"\", assetExchangeAgreementSerializedProto64, lockInfoSerializedProto64)\n    if err != nil {\n        return \"\", logThenErrorf(err.Error())\n    }\n    // Post proccessing of asset after LockAsset called like change status of the asset so that it can't be spent.\n    ...\n    return contractId, nil\n}\n</code></pre>    Here <code>assetExchangeAgreementSerializedProto64</code> is a serialized protobuf in Base64 encoded string of <code>AssetExchangeAgreement</code> protobuf structure, and can be used to extract details like asset id, type of asset and recipient. Check the structure definition here.    Similarly <code>lockInfoSerializedProto64</code> is a serialized protobuf in Base64 encoded string of <code>AssetLock</code> protobuf structure. Check the structure definition here.</li> <li>LockFungibleAsset <pre><code>func (s *SmartContract) LockFungibleAsset(ctx contractapi.TransactionContextInterface, fungibleAssetExchangeAgreementSerializedProto64 string, lockInfoSerializedProto64 string) (string, error) {\n    // Add some safety checks before calling LockFungibleAsset from library\n    // Caller of this chaincode is supposed to be the Locker and the owner of the asset being locked.\n    contractId, err := assetexchange.LockFungibleAsset(ctx, \"\", fungibleAssetExchangeAgreementSerializedProto64, lockInfoSerializedProto64)\n    if err != nil {\n        return \"\", logThenErrorf(err.Error())\n    }\n    // Post proccessing of asset after LockFungibleAsset called like reduce the amount of tokens owned by the locker, or mark it locked so that it can't be spent.\n    ...\n    return contractId, nil\n}\n</code></pre>    Here <code>fungibleAssetExchangeAgreementSerializedProto64</code> is a serialized protobuf in Base64 encoded string of <code>FungibleAssetExchangeAgreement</code> protobuf structure, and can be used to extract details like asset quantity, type of asset and recipient. Check the structure definition here.</li> <li>IsAssetLockedQueryUsingContractId <pre><code>func (s *SmartContract) IsAssetLockedQueryUsingContractId(ctx contractapi.TransactionContextInterface, contractId string) (bool, error) {\n    return assetexchange.IsAssetLockedQueryUsingContractId(ctx, contractId)\n}\n</code></pre></li> <li>ClaimAssetUsingContractId <pre><code>func (s *SmartContract) ClaimAssetUsingContractId(ctx contractapi.TransactionContextInterface, contractId, claimInfoSerializedProto64 string) (bool, error) {\n    // Note recipient will be the caller for this function\n    claimed := false\n    err := assetexchange.ClaimAssetUsingContractId(ctx, contractId, claimInfoSerializedProto64)\n    if err != nil {\n        return false, logThenErrorf(err.Error())\n    }\n    claimed = true\n    // After the above function call, update the owner of the asset with recipeint/caller\n    ...\n    return claimed, nil\n}\n</code></pre></li> <li>UnlockAssetUsingContractId <pre><code>func (s *SmartContract) UnlockAssetUsingContractId(ctx contractapi.TransactionContextInterface, contractId string) (bool, error) {\n    unlocked := false\n    err := assetexchange.UnlockAssetUsingContractId(ctx, contractId)\n    if err != nil {\n        return false, logThenErrorf(err.Error())\n    }\n    unlocked = true\n    ...\n    return true, nil\n}\n</code></pre></li> </ol> </li> </ul> <p>In addition, you should add the following extra utility functions to enable client applications to query and discover asset state:   <pre><code>func (s *SmartContract) GetHTLCHashByContractId(ctx contractapi.TransactionContextInterface, contractId string) (string, error) {\n    return assetexchange.GetHTLCHashByContractId(ctx, contractId)\n}\nfunc (s *SmartContract) GetHTLCHashPreImageByContractId(ctx contractapi.TransactionContextInterface, contractId string) (string, error) {\n    return assetexchange.GetHTLCHashPreImageByContractId(ctx, contractId)\n}\n</code></pre></p> <p>There is an alternative API to implement asset exchange using this library, which doesn't involve contract IDs. For details, see the Asset Exchange Library README.</p> <ul> <li>Using the <code>Fabric Interoperation Chaincode</code>: This method requires the Fabric Interoperation Chaincode to be installed on all peers of the channel, using a special chaincode ID (e.g., <code>interop</code>, which is what we will use later in this document). Your application chaincode needs to implement the interface <code>github.com/hyperledger/cacti/weaver/core/network/fabric-interop-cc/interfaces/asset-mgmt/v2</code>.   In your smart contract's <code>go.mod</code>, add the following in the <code>require</code> section (update the version to the latest Cacti version):   <pre><code>require(\n    ...\n    github.com/hyperledger/cacti/weaver/common/protos-go/v2 v2.0.0-rc.2\n    github.com/hyperledger/cacti/weaver/core/network/fabric-interop-cc/interfaces/asset-mgmt/v2 v2.0.0-rc.2\n    ...\n)\n</code></pre>   In the SmartContract class definition file, add the following code:   <pre><code>import (\n    ...\n    am \"github.com/hyperledger/cacti/weaver/core/network/fabric-interop-cc/interfaces/asset-mgmt/v2\"\n)\ntype SmartContract struct {\n    contractapi.Contract\n    amc am.AssetManagementContract\n}\n</code></pre>   The following functions need to be added to your chaincode (Note: the function signature, i.e. the name, arguments, and return values, need to be exactly what is given in the below samples; you can have additional code to manage asset state as per need):<ol> <li>LockAsset <pre><code>func (s *SmartContract) LockAsset(ctx contractapi.TransactionContextInterface, assetExchangeAgreementSerializedProto64 string, lockInfoSerializedProto64 string) (string, error) {\n    // Add some safety checks before calling LockAsset from library\n    // Caller of this chaincode is supposed to be the Locker and the owner of the asset being locked.\n    contractId, err := s.amc.LockAsset(ctx, \"\", assetExchangeAgreementSerializedProto64, lockInfoSerializedProto64)\n    if err != nil {\n        return \"\", logThenErrorf(err.Error())\n    }\n    // Post proccessing of asset after LockAsset called like change status of the asset so that it can't be spent.\n    ...\n    return contractId, nil\n}\n</code></pre>    Here <code>assetExchangeAgreementSerializedProto64</code> is a serialized protobuf in Base64 encoded string of <code>AssetExchangeAgreement</code> protobuf structure, and can be used to extract details like asset id, type of asset and recipient. Check the structure definition here.    Similarly <code>lockInfoSerializedProto64</code> is a serialized protobuf in Base64 encoded string of <code>AssetLock</code> protobuf structure. Check the structure definition here.</li> <li>LockFungibleAsset <pre><code>func (s *SmartContract) LockFungibleAsset(ctx contractapi.TransactionContextInterface, fungibleAssetExchangeAgreementSerializedProto64 string, lockInfoSerializedProto64 string) (string, error) {\n    // Add some safety checks before calling LockFungibleAsset from library\n    // Caller of this chaincode is supposed to be the Locker and the owner of the asset being locked.\n    contractId, err := s.amc.LockFungibleAsset(ctx, \"\", fungibleAssetExchangeAgreementSerializedProto64, lockInfoSerializedProto64)\n    if err != nil {\n        return \"\", logThenErrorf(err.Error())\n    }\n    // Post proccessing of asset after LockFungibleAsset called like reduce the amount of tokens owned by the locker, or mark it locked so that it can't be spent.\n    ...\n    return contractId, nil\n}\n</code></pre>    Here <code>fungibleAssetExchangeAgreementSerializedProto64</code> is a serialized protobuf in Base64 encoded string of <code>FungibleAssetExchangeAgreement</code> protobuf structure, and can be used to extract details like asset quantity, type of asset and recipient. Check the structure definition here.</li> <li>IsAssetLockedQueryUsingContractId <pre><code>func (s *SmartContract) IsAssetLockedQueryUsingContractId(ctx contractapi.TransactionContextInterface, contractId string) (bool, error) {\n    return s.amc.IsAssetLockedQueryUsingContractId(ctx, contractId)\n}\n</code></pre></li> <li>ClaimAssetUsingContractId <pre><code>func (s *SmartContract) ClaimAssetUsingContractId(ctx contractapi.TransactionContextInterface, contractId, claimInfoSerializedProto64 string) (bool, error) {\n    // Note recipient will be the caller for this function\n    claimed := false\n    err := s.amc.ClaimAssetUsingContractId(ctx, contractId, claimInfoSerializedProto64)\n    if err != nil {\n        return false, logThenErrorf(err.Error())\n    }\n    claimed = true\n    // After the above function call, update the owner of the asset with recipeint/caller\n    ...\n    return claimed, nil\n}\n</code></pre></li> <li>UnlockAssetUsingContractId <pre><code>func (s *SmartContract) UnlockAssetUsingContractId(ctx contractapi.TransactionContextInterface, contractId string) (bool, error) {\n    unlocked := false\n    err := s.amc.UnlockAssetUsingContractId(ctx, contractId)\n    if err != nil {\n        return false, logThenErrorf(err.Error())\n    }\n    unlocked = true\n    ...\n    return true, nil\n}\n</code></pre> In addition, you should add the following extra utility functions to enable client applications to query and discover asset state: <pre><code>func (s *SmartContract) GetHTLCHashByContractId(ctx contractapi.TransactionContextInterface, contractId string) (string, error) {\n    return s.amc.GetHTLCHashByContractId(ctx, contractId)\n}\nfunc (s *SmartContract) GetHTLCHashPreImageByContractId(ctx contractapi.TransactionContextInterface, contractId string) (string, error) {\n    return s.amc.GetHTLCHashPreImageByContractId(ctx, contractId)\n}\n</code></pre></li> </ol> </li> </ul>"},{"location":"weaver/getting-started/enabling-weaver-network/fabric/#for-asset-transfer","title":"For Asset Transfer","text":"<p>TBD</p>"},{"location":"weaver/getting-started/enabling-weaver-network/fabric/#client-or-layer-2-applications","title":"Client (or Layer-2) Applications","text":"<p>Weaver provides an SDK to help you adapt your applications to exercise the various interoperability modes. These are called out as Interoperation Helpers in the network model illustrated earlier. Your Fabric network's Layer-2 applications have business logic embedded in them that, broadly speaking, accept data from users and other external agents and invoke smart contracts using library functions and APIs offered by the Fabric SDK. When you use Weaver for network interoperability, other options can be added, namely requesting and accepting data from foreign networks, and triggering locks and claims for atomic exchanges spanning two networks. Weaver's Fabric Interoperation SDK (currently implemented both in Node.js and Golang) offers a library to exercise these options, supplementing the Fabric SDK. But this will involve modification to the application's business logic.</p> Notes The instructions here apply to applications implemented in Node.js (JavaScript and TypeScript), using the Weaver Node SDK for Fabric. We will add instructions later for Go applications using the Weaver Go SDK for Fabric. <p>To import and use the Weaver SDK, you need to add the following dependency to the <code>dependencies</code> section of your Node.js application's <code>package.json</code> file: <pre><code>\"@hyperledger/cacti-weaver-sdk-fabric\": \"latest\",\n</code></pre> (Instead of <code>latest</code>, you can select a particular version from the package website.)</p> <p>Before you run <code>npm install</code> to fetch the dependencies, make sure you create a personal access token with <code>read:packages</code> access in GitHub. Create an <code>.npmrc</code> file in the same folder as the <code>package.json</code> with the following contents:</p> <p><pre><code>@hyperledger:registry=https://npm.pkg.github.com/hyperledger\n//npm.pkg.github.com/:_authToken=&lt;personal-access-token&gt;\n</code></pre> Replace <code>&lt;personal-access-token&gt;</code> in this file with the token you created in GitHub.</p> <p>First, you must incorporate some code for Weaver's network administration, specifically identity management. Then, using the given sample code and examples, you can adapt your applications for each interoperability mode.</p>"},{"location":"weaver/getting-started/enabling-weaver-network/fabric/#for-identity-administration","title":"For Identity Administration","text":"<p>A Fabric network channel must share its security domain (or membership) configuration, i.e., its organizations' CA certificate chains, with a foreign network with which it seeks to interoperate. Each organization must run an IIN Agent for this purpose. The set of IIN Agents, a.k.a. the local membership must be recorded in the ledger before those agents can be operational. In your Fabric network application suite, one or more applications will exist for network administration; the following code snippet should be added in at least one of those applications to record local membership as a prerequisite for interoperability:   <pre><code>import { MembershipManager } from '@hyperledger/cacti-weaver-sdk-fabric'\n\nconst gateway = &lt;get-fabric-network-gateway-instance&gt;\n\ntry {\n    const response = await MembershipManager.createLocalMembership(\n        gateway,\n        members,        // list of all organization MSPIDs that are part of the channel\n        securityDomain, // name of the local network's security domain\n        channelName,    // Channel Name\n        contractName    // Fabric Interoperation Chaincode installation ID on the channel\n    )\n} catch (e) {\n    // On error try updating local membership\n    const response = await MembershipManager.updateLocalMembership(gateway, members, securityDomain, channelName, contractName)\n}\n</code></pre></p> <ul> <li><code>&lt;get-fabric-network-gateway-instance&gt;</code> should be replaced with standard (boilerplate) code to get a handle to your network's gateway. This requires a special wallet identity, namely one with a <code>network-admin</code> attribute indicating that the caller is a trusted network administrator who is authorized to record local memberships on the <code>channelName</code> channel.</li> <li><code>members</code> must consist of the list of organizational MSP IDs for the <code>channelName</code> channel.</li> </ul>"},{"location":"weaver/getting-started/enabling-weaver-network/fabric/#for-data-sharing_1","title":"For Data Sharing","text":"<p>Consider a scenario inspired by the global trade use case where a letter of credit (L/C) management business logic (chaincode <code>letterofcreditcc</code>) installed in the <code>tradefinancechannel</code> channel in the <code>trade-finance-network</code> network supports a transaction <code>RecordBillOfLading</code>, which validates and records a bill of lading (B/L) supplied by a user via a UI. Weaver will enable such a B/L to be fetched from a different network <code>trade-logistics-network</code> by querying the function <code>GetBillOfLading</code> exposed by the chaincode <code>shipmentcc</code> installed in the <code>tradelogisticschannel</code> channel.</p> <p>(In preparation, a suitable access control policy must be recorded on <code>tradelogisticschannel</code> in <code>trade-logistics-network</code>, and a suitable verification policy must be recorded on <code>tradefinancechannel</code> in <code>trade-finance-network</code>. We will see how to do this in the \"Startup and Boostrap\" section later.)</p> <p>You will need to insert some code in the Layer-2 application that accepts a B/L and submits a <code>RecordBillOfLading</code> transaction in <code>trade-finance-network</code>. (No code changes need to be made in any application in the other network.) The logic to accept a B/L should be replaced (or you can simply add an alternative) by a call to the <code>interopFlow</code> function offered by the cacti-weaver-sdk-fabric library (there's an equivalent library in Golang too). The following code sample illustrates this (the Golang equivalent is left to the reader): <pre><code>const ihelper = require('@hyperledger/cacti-weaver-sdk-fabric').InteroperableHelper;\nconst interopcc = &lt;handle-to-fabric-interop-chaincode&gt;;   // Use Fabric SDK functions: (new Gateway()).getNetwork(...).getContract(&lt;fabric-interop-chaincode-id&gt;)\nconst keyCert = await ihelper.getKeyAndCertForRemoteRequestbyUserName(&lt;wallet&gt;, &lt;user-id&gt;);      // Read key and certificate for &lt;user-id&gt; from wallet (get handle using Fabric SDK Wallets API)\n// Collect view addresses for relay requests in the context of an interop flow\ninteropJSONs.push({\n    NetworkID: 'trade-logistics-network',\n    RemoteEndpoint: &lt;trade-logistics-relay-url[:&lt;port&gt;],      // Replace with remote network's relay address and port\n    ChannelID: 'tradelogisticschannel',\n    ChaincodeID: 'shipmentcc',\n    ChaincodeFunc: 'GetBillOfLading',\n    ccArgs: [ &lt;shipment-reference&gt; ],     // Replace &lt;shipment-reference&gt; with a value that can be used to look up the right B/L\n    Sign: true\n});\nconst indices = [ 1 ];\n// Trigger an end-to-end interoperation (data sharing) protocol\n// Send a request to a foreign network via your relay, receive the response and submit a transaction to a local chaincode\nconst flowResponse = await ihelper.interopFlow(\n    interopcc,\n    'trade-finance-network',\n    {\n        channel: 'tradefinancechannel',\n        contractName: 'letterofcreditcc',\n        ccFunc: 'RecordBillOfLading',\n        ccArgs: [ &lt;shipment-reference&gt; , '' ]\n    },\n    &lt;org-msp-id&gt;,                         // Replace with this Layer-2 application's organization's MSP ID\n    &lt;trade-finance-relay-url&gt;[:&lt;port&gt;],   // Replace with local network's relay address and port\n    indices,\n    interopJSONs,\n    keyCert,\n    &lt;endorsingOrgs&gt;,        // List of orgs to submit transaction to local i.e. trade logistics network\n    false,                  // Boolean flag to indicate whether return without submit transaction to local i.e. trade logistics network\n    false,                  // Boolean flag indicating no TLS communication with relay\n    [],                     // Keep it empty when TLS is disabled\n    &lt;confidential-flag&gt;,    // Boolean flag to indicate whether to use to end-to-end encryption\n);\n// List of errors to check for\nif (!flowResponse.views || flowResponse.views.length === 0 || !flowResponse.result || flowResponse.views.length !== argIndices.length) {\n    throw &lt;error&gt;;\n}\n</code></pre> Let us understand this code snippet better. The structure in lines 20-25 specifies the local chaincode transaction that is to be triggered after remote data (view) has been requested and obtained via relays. The function <code>RecordBillOfLading</code> expects two arguments as specified in line 24: the first is the common shipment reference that is used by the letter of credit in <code>trade-finance-network</code> and the bill of lading in <code>trade-logistics-network</code>, and the second is the bill of lading contents. When the <code>interopFlow</code> function is called, this argument is left blank because it is supposed to be filled with contents obtained from a view request. The array list <code>indices</code>, which is passed as an argument to <code>interopFlow</code> therefore contains the index value <code>1</code> (line 14), indicating which argument ought to be substituted  with view data. The <code>interopJSONs</code> array correspondingly contains a list of view addresses that are to be supplied to the relay. The <code>&lt;confidential-flag&gt;</code> if set to <code>true</code> will enable end-to-end confidentiality, i.e. payload will be encrypted from <code>trade-finance-network</code>'s Weaver chaincode, and will be decrypted in SDK (i.e. Layer-2 client application) at <code>trade-logistics-network</code>, but relays and drivers in between will not be able to see the payload. By default this flag is set to <code>false</code>.</p> Notes A local chaincode invocation may require multiple view requests to different networks, which is why <code>indices</code> and <code>interopJSONs</code> are arrays; they therefore must have the same lengths. <p>The rest of the code ought to be self-explanatory. Values are hardcoded for explanation purposes, but you can refactor the above code by reading view addresses corresponding to chaincode invocations from a configuration file.</p> <p>Enabling TLS: By default, the TLS is set to false in <code>interopFlow</code>, i.e. disabled. But if you want to enable TLS, can pass additional parameters to the <code>interopFlow</code> function as follows: <pre><code>const flowResponse = await ihelper.interopFlow(\n    interopcc,\n    'trade-finance-network',\n    {\n        channel: 'tradefinancechannel',\n        contractName: 'letterofcreditcc',\n        ccFunc: 'RecordBillOfLading',\n        ccArgs: [ &lt;shipment-reference&gt; , '' ]\n    },\n    &lt;org-msp-id&gt;,                         // Replace with this Layer-2 application's organization's MSP ID\n    &lt;trade-finance-relay-url&gt;[:&lt;port&gt;],   // Replace with local network's relay address and port\n    indices,\n    interopJSONs,\n    keyCert,\n    &lt;endorsingOrgs&gt;,            // List of orgs to submit transaction to in trade logistics network\n    false,                  // Boolean flag to indicate whether return without submit transaction to local i.e. trade logistics network\n    true,                       // Boolean indication TLS is enabled.\n    &lt;tlsCACertPathsForRelay&gt;,   // list of CA certificate file paths\n);\n</code></pre></p>"},{"location":"weaver/getting-started/enabling-weaver-network/fabric/#for-asset-exchange_1","title":"For Asset Exchange","text":"<p>Let's take an example of asset exchange between <code>Alice</code> and <code>Bob</code>, where Bob wants to purchase an asset of type <code>Gold</code> with id <code>A123</code> from <code>Alice</code> in <code>BondNetwork</code> in exchange for <code>200</code> tokens of type <code>CBDC01</code> in <code>TokenNetwork</code>.</p> <p><code>Alice</code> needs to select a secret text (say <code>s</code>), and hash it (say <code>H</code>) using say <code>SHA512</code>, which will be used to lock her asset in <code>BondNetwork</code>. At the place in your application where an asset exchange is to be initiated, you need to add code to enable Alice to lock the non-fungible asset using hash <code>H</code> and timeout duration of 10 minutes: <pre><code>import { AssetManager, HashFunctions } from '@hyperledger/cacti-weaver-sdk-fabric'\n\nconst hash = HashFunctions.SHA512();    // Create Hash instance of one of the supported Hash Algorithm\nhash.setSerializedHashBase64(H);        // Set the Hash\nconst timeout = Math.floor(Date.now()/1000) + 10 * 60;\n\nconst bondContract = &lt;handle-to-fabric-application-chaincode-in-bond-network&gt;;\n\nconst result = await AssetManager.createHTLC(\n    bondContract,\n    \"Gold\",             // Asset ID\n    \"A123\",             // Asset Type\n    bobCertificate,     // Certificate of Bob in Bond Network\n    hash,                  // Hash generated by Alice using her secret s\n    timeout,            // Timeout in epoch for 10 mins from current time\n    null                // Optional callback function to be called after the asset is locked\n);\nlet bondContractId = result.result; // Unique ID for this asset exchange contract in BondNetwork\n</code></pre></p> Notes Note that 'Alice' and 'Bob' and the asset specifics can be parameterized in the above code, which can be reused for arbitrary asset exchange scenarios in your business workflow. The above code is only meant to be a sample. <p>Now <code>Bob</code> will lock his tokens in <code>TokenNetwork</code>. To lock the fungible asset using same hash <code>H</code> and timeout of 5 minutes (half the timeout duration used by Alice in <code>BondNetwork</code>), add the following code snippet in your application: <pre><code>const hash = HashFunctions.SHA512();    // Create Hash instance of one of the supported Hash Algorithm\nhash.setSerializedHashBase64(H);        // Set the Hash\nconst timeout = Math.floor(Date.now()/1000) + 5 * 60;\n\nconst tokenContract = &lt;handle-to-fabric-application-chaincode-in-token-network&gt;;\nconst result = await AssetManager.createFungibleHTLC(\n    tokenContract,\n    \"CBDC01\",               // Token ID\n    200,                    // Token Quantity\n    aliceCertificate,       // Certificate of Alice in Token Network\n    hash,                      // Hash H used by Alice in Bond Network\n    timeout,                // Timeout in epoch for 5 mins from current time\n    null                    // Optional callback function to be called after the asset is locked\n)\nconst tokenContractId = result.result // Unique ID for this asset exchange contract in TokenNetwork\n</code></pre></p> <p>Wherever the lock status of the asset is required in your application, you should insert a query function call as follows: <pre><code>const contract = &lt;handle-to-fabric-application-chaincode&gt;;\n// Below contractId is the ID obtained during lock\nconst isLocked = AssetManager.isAssetLockedInHTLCqueryUsingContractId(contract, contractId)\n</code></pre></p> <p>Wherever a participant (either 'Alice' or 'Bob' in this example) needs to claim a locked asset using the secret text (pre-image of hash) <code>s</code> in your application, insert the following code snippet (Note: typically one would insert this in event callback functions or in functions that are polling the ledger to monitor whether the asset is locked in favor of a given recipient): <pre><code>const hash = HashFunctions.SHA512();    // Create Hash instance of one of the supported Hash Algorithm\nhash.setPreimage(s)                     // Set Pre-Image s\nconst contract = &lt;handle-to-fabric-application-chaincode&gt;;\nconst claimSuccess = await AssetManager.claimAssetInHTLCusingContractId(\n    contract,\n    contractId,                         // contractId obtained during lock\n    hash\n)\n// return value claimSuccess is boolean indicating success or failure of claim\n</code></pre></p> <p>Wherever the asset must be unlocked in your application (typically, an event callback function triggered upon the expiration of the time lock), insert the following code snippet: <pre><code>const contract = &lt;handle-to-fabric-application-chaincode&gt;;\nconst reclaimSuccess = await AssetManager.reclaimAssetInHTLCusingContractId(\n    contract,\n    contractId                          // contractId obtained during lock\n)\n// return value 'reclaimSuccess' is a boolean indicating success or failure of reclaim\n</code></pre></p>"},{"location":"weaver/getting-started/enabling-weaver-network/fabric/#for-asset-transfer_1","title":"For Asset Transfer","text":"<p>TBD</p>"},{"location":"weaver/getting-started/enabling-weaver-network/fabric/#pre-configuration-phase","title":"Pre-Configuration Phase","text":"<p>Typically, pre-configuration in a Fabric network involves generating (after creating the channel specifications and policies):</p> <ul> <li>Channel artifacts: orderer genesis block, channel transaction, and anchor peer configurations from a <code>configtx.yaml</code> file (using Fabric's <code>configtxgen</code> tool)</li> <li>Crypto artifacts: keys and certificates for CAs, peers, orderers, and clients from a <code>crypto-config.yaml</code> file (using Fabric's <code>cryptogen</code> tool)</li> <li>Connection profiles: one for every network organization, which will be used by the organization's Layer-2 applications to connect to the network's peers and CAs</li> </ul> <p>No changes are required in this process to support any of the three interoperation modes using Weaver. The connection profiles generated above will be used by certain Weaver modules, as we will see later. The only additional step required is to generate special wallet identities for the following:</p> <ul> <li>Network administrator: one or more identities containing the <code>network-admin</code> attribute; only a user/application possessing this identity may record special (privileged) information regarding memberships and policies on the channel.</li> <li>Fabric Driver: one or more identities (for each deployed driver) containing the <code>relay</code> attribute; only a relay-driver combination possessing this identity may run data sharing-related operations on the deployed Fabric Interoperation Chaincode.</li> <li>IIN Agent: one or more identities (for each deployed agent) containing the <code>iin-agent</code> attribute: only an agent may submit foreign network membership records to the Fabric Interoperation Chaincode.</li> </ul> <p>Later we will see how the components possessing these identities are deployed.</p>"},{"location":"weaver/getting-started/enabling-weaver-network/fabric/#startup-and-bootstrap-phase","title":"Startup and Bootstrap Phase","text":"<p>After writing application code and creating the network configuration files, the components of a Fabric network (peers, CAs, and ordering service) are launched. In this section, we will list the additional tasks you, as a Fabric network administrator, must perform to make your network ready to interoperate.</p> <p>To launch a network using containerized components, you will typically use a Docker Compose or Kubernetes configuration file. No modifications are needed to the peers', orderers', and CAs' configurations. Sample instructions are given below for networks launched using Docker Compose; we leave it to the reader to adapt these to their custom launch processes.</p>"},{"location":"weaver/getting-started/enabling-weaver-network/fabric/#for-asset-exchange_2","title":"For Asset Exchange","text":"<p>The asset exchange mode currently requires only the Fabric Interoperation Chaincode module from Weaver. Relays, drivers, and IIN agents, are not necessary. In the future, we expect to make the asset exchange protocol moe automated using these components; the instructions here will be updated appropriately.</p>"},{"location":"weaver/getting-started/enabling-weaver-network/fabric/#install-the-fabric-interoperation-chaincode","title":"Install the Fabric Interoperation Chaincode","text":"<p>Install the Fabric Interoperation Chaincode in the relevant channel(s), i.e., those that run chaincodes that will be involved in asset exchanges. This is a Go module that can be fetched from <code>github.com/hyperledger/cacti/weaver/core/network/fabric-interop-cc/contracts/interop</code>. Following that, you an install it using the appropriate Fabric process: in Fabric v2, you will need to package, install, approve, and commit this module on the selected channels in your network.</p>"},{"location":"weaver/getting-started/enabling-weaver-network/fabric/#for-data-sharing-or-asset-transfer","title":"For Data Sharing or Asset Transfer","text":"<p>Both the data sharing and asset transfer modes require the Fabric Interoperation Chaincode, relays, drivers, and IIN agents, to be deployed.</p>"},{"location":"weaver/getting-started/enabling-weaver-network/fabric/#install-the-fabric-interoperation-chaincode_1","title":"Install the Fabric Interoperation Chaincode","text":"<p>Install the Fabric Interoperation Chaincode in the relevant channel(s), i.e., those that run chaincodess that will be involved in data sharing (and asset transfers, which require multiple data shares). This is a Go module that can be fetched from <code>github.com/hyperledger/cacti/weaver/core/network/fabric-interop-cc/contracts/interop</code>. Following that, you an install it using the appropriate Fabric process: in Fabric v2, you will need to package, install, approve, and commit this module on the selected channels in your network.</p>"},{"location":"weaver/getting-started/enabling-weaver-network/fabric/#launch-relay","title":"Launch Relay","text":"<p>You need to run one or more relays for network-to-network communication. Here we provide instructions to run one relay running in a Docker container, which is sufficient for data sharing. (Later, we will provide instructions to run multiple relays, which will be useful from a failover perspective.)</p> <p>Weaver provides a pre-built image for the relay. Before launching a container, you just need to customize its configuration for your Fabric network, which you can do by simply creating a folder (let's call it <code>relay_config</code>) and configuring the following files in it:</p> <ul> <li> <p><code>.env</code>: This sets suitable environment variables within the relay container. Copy the <code>.env.template</code> file from the repository and customize it for your purposes, as indicated in the below sample:   <pre><code>PATH_TO_CONFIG=./config.toml\nRELAY_NAME=&lt;\"name\" in config.toml&gt;\nRELAY_PORT=&lt;relay-server-port/\"port\" in config.toml&gt;\nEXTERNAL_NETWORK=&lt;docker-bridge-network&gt;\nDOCKER_IMAGE_NAME=ghcr.io/hyperledger/cacti-weaver-relay-server\nDOCKER_TAG=2.0.0-rc.2\n</code></pre></p> <ul> <li>The <code>PATH_TO_CONFIG</code> variable should point to the properties file typically named <code>config.toml</code> (you can name this whatever you wish). See further below for instructions to write this file.</li> <li>The <code>RELAY_NAME</code> variable specifies a unique name for this relay. It should match what's specified in the <code>config.toml</code> (more on that below).</li> <li>The <code>RELAY_PORT</code> variable specifies the port this relay server will listen on. It should match what's specified in the <code>config.toml</code> (more on that below).</li> <li>The <code>EXTERNAL_NETWORK</code> variable should be set to the name of your Fabric network.</li> <li>The <code>DOCKER_*</code> variables are used to specify the image on which the container will be built. Make sure you set <code>DOCKER_TAG</code> to the latest version you see on GitHub.</li> </ul> <p>For more details, see the Relay Docker README (\"Relay Server Image\" and \"Running With Docker Compose\" sections).</p> </li> <li> <p><code>config.toml</code>: This is the file specified in the <code>PATH_TO_CONFIG</code> variable in the <code>.env</code>. It specifies properties of this relay and the driver(s) it supports. A sample is given below:   <pre><code>name=&lt;relay-name&gt;\nport=&lt;relay-port&gt;\nhost=\"0.0.0.0\"\ndb_path=\"db/&lt;relay-name&gt;/requests\"\nremote_db_path=\"db/&lt;relay-name&gt;/remote_request\"\n\n# FOR TLS\ncert_path=\"credentials/fabric_cert.pem\"\nkey_path=\"credentials/fabric_key\"\ntls=&lt;true/false&gt;\n\n[networks]\n[networks.&lt;network-name&gt;]\nnetwork=\"&lt;driver-name&gt;\"\n\n[relays]\n[relays.&lt;foreign-relay-name&gt;]\nhostname=\"&lt;foreign-relay-hostname-or-ip-address&gt;\"\nport=\"&lt;foreign-relay-port&gt;\"\n\n[drivers]\n[drivers.&lt;driver-name&gt;]\nhostname=\"&lt;driver-hostname-or-ip-address&gt;\"\nport=\"&lt;driver-port&gt;\"\n</code></pre></p> <ul> <li><code>&lt;relay-name&gt;</code> should be a unique ID representing this relay; e.g., <code>my_network_relay</code>. It should match the <code>RELAY_NAME</code> value in <code>.env</code>.</li> <li><code>&lt;relay-port&gt;</code> is the port number the relay server will listen on. It should match the <code>RELAY_PORT</code> value in <code>.env</code>.</li> <li><code>db_path</code> and <code>remote_db_path</code> are used internally by the relay to store data. Replace <code>&lt;relay-name&gt;</code> with the same value set for the <code>name</code> parameter. (These can point to any filesystem paths in the relay's container.)</li> <li>If you set <code>tls</code> to <code>true</code>, the relay will enforce TLS communication. The <code>cert_path</code> and <code>key_path</code> should point to a Fabric TLS certificate and key respectively, such as those created using the <code>cryptogen</code> tool.</li> <li><code>&lt;network-name&gt;</code> is a unique identifier for your local network. You can set it to whatever value you wish.</li> <li><code>&lt;driver-name&gt;</code> refers to the driver used by this relay to respond to requests. This also refers to one of the drivers's specifications in the <code>drivers</code> section further below. In this code snippet, we have defined one driver. (The names in lines 14 and 22 must match.) In lines 23 and 24 respectively, you should specify the hostname and port for the driver (whose configuration we will handle later).</li> <li>The <code>relays</code> section specifies all foreign relays this relay can connect to. The <code>&lt;foreign-relay-name&gt;</code> value should be a unique ID for a given foreign relay, and this value will be used by your Layer-2 applications when constructing view addresses for data sharing requests. In lines 18 and 19, you should specify the hostname and port for the foreign relay.</li> <li>Enabling TLS:<ul> <li>You can make your relay accept TLS connections by specifying a TLS certificate file path and private key file path in <code>cert_path</code> and <code>key_path</code> respectively, and set <code>tls</code> to <code>true</code>.</li> <li>To communicate with a foreign relay using TLS, specify that relay's TLS CA certificate path in <code>tlsca_cert_path</code> (currently only one certificate can be configured) and set <code>tls</code> to <code>true</code> by extending that relay's section as follows (Note: this CA certificate should match the one specified in the <code>cert_path</code> property in the foreign relay's <code>config.toml</code> file):   <pre><code>[relays]\n[relays.&lt;foreign-relay-name&gt;]\nhostname=\"&lt;foreign-relay-hostname-or-ip-address&gt;\"\nport=\"&lt;foreign-relay-port&gt;\"\ntls=&lt;true|false&gt;\ntlsca_cert_path=\"&lt;relay-tls-ca-certificate-path&gt;\"\n</code></pre></li> <li>To communicate with a driver using TLS, specify the driver's TLS CA certificate in <code>tlsca_cert_path</code> (currently only one certificate can be configured) and set <code>tls</code> to <code>true</code> by extending that driver's section as follows (Note: this CA certificate must match the certificate used by the driver using the <code>DRIVER_TLS_CERT_PATH</code> property in its <code>.env</code> configuration file, which we will examine later):   <pre><code>[drivers]\n[drivers.&lt;driver-name&gt;]\nhostname=\"&lt;driver-hostname-or-ip-address&gt;\"\nport=\"&lt;driver-port&gt;\"\ntls=&lt;true|false&gt;\ntlsca_cert_path=\"&lt;driver-tls-ca-certificate-path&gt;\"\n</code></pre></li> </ul> </li> </ul> </li> </ul> Notes You can specify more than one foreign relay instance in the <code>relays</code> section. You can specify more than one driver instance in the <code>drivers</code> section. <ul> <li><code>docker-compose.yaml</code>: This specifies the properties of the relay container. You can use the file in the repository verbatim.</li> </ul> <p>To start the relay server, navigate to the folder containing the above files and run the following: <pre><code>docker compose up -d relay-server\n</code></pre></p>"},{"location":"weaver/getting-started/enabling-weaver-network/fabric/#launch-driver","title":"Launch Driver","text":"<p>You need to run one or more drivers through which your relay can interact with your Fabric network. Here we provide instructions to run one Fabric driver running in a Docker container, which is sufficient for data sharing. (Later, we will provide instructions to run multiple drivers, which will be useful both from a failover perspective and to interact with different subsets of your Fabric network, like private data collections.)</p> <p>Weaver provides a pre-built image for the Fabric driver. Before launching a container, you just need to customize its configuration for your Fabric network, which you can do by simply creating a folder (let's call it <code>driver_config</code>) and configuring the following files in it:</p> <ul> <li> <p><code>.env</code>: This sets suitable environment variables within the driver container. Copy the <code>.env.docker.template</code> file from the repository and customize it for your purposes, as indicated in the below sample:   <pre><code>CONNECTION_PROFILE=&lt;path_to_connection_profile&gt;\nDRIVER_CONFIG=./config.json\nRELAY_ENDPOINT=&lt;relay-hostname&gt;:&lt;relay-port&gt;\nNETWORK_NAME=&lt;network-name&gt;\nDRIVER_PORT=&lt;driver-server-port&gt;\nINTEROP_CHAINCODE=&lt;interop-chaincode-name&gt;\nEXTERNAL_NETWORK=&lt;docker-bridge-network&gt;\nTLS_CREDENTIALS_DIR=&lt;dir-with-tls-cert-and-key&gt;\nDOCKER_IMAGE_NAME=ghcr.io/hyperledger/cacti-weaver-driver-fabric\nDOCKER_TAG=2.0.0-rc.2\nDRIVER_TLS=&lt;true|false&gt;\nDRIVER_TLS_CERT_PATH=path_to_tls_cert_pem_for_driver\nDRIVER_TLS_KEY_PATH=path_to_tls_key_pem_for_driver\nRELAY_TLS=&lt;true|false&gt;\nRELAY_TLSCA_CERT_PATH=path_to_tls_ca_cert_pem_for_relay\n</code></pre></p> <ul> <li><code>&lt;path_to_connection_profile&gt;</code> should point to the path of a connection profile you generated in the \"Pre-Configuration\" section. A Fabric driver obtains client credentials from one of the organizations in your network, so pick an organization and point to the right connection profile.</li> <li>The <code>DRIVER_CONFIG</code> variable should point to the <code>config.json</code> (you can name this whatever you wish) specified below.</li> <li><code>&lt;relay-hostname&gt;</code> should be set to the hostname of the relay server machine and <code>&lt;relay-port&gt;</code> should match the <code>port</code> value in the relay's <code>config.toml</code> (see above).</li> <li>The <code>NETWORK_NAME</code> variable should be a unique ID referring to the Fabric network. It will be used to distinguish container names and wallet paths. (This setting is relevant in situations where a driver is used to query multiple network channels.)</li> <li>The <code>DRIVER_PORT</code> variable should be set to the port this driver will listen on.</li> <li>The <code>INTEROP_CHAINCODE</code> variable should be set to the ID of the Fabric Interop Chaincode installed on your Fabric network channel.</li> <li>The <code>EXTERNAL_NETWORK</code> variable should be set to the name of your Fabric network.</li> <li>Enabling TLS:<ul> <li>You can make your driver accept TLS connections by specifying <code>DRIVER_TLS</code> as <code>true</code> and specifying a TLS certificate file path and private key file path in <code>DRIVER_TLS_CERT_PATH</code> and <code>DRIVER_TLS_KEY_PATH</code> respectively. The same certificate should be specified in this driver's definition in the <code>drivers</code> section in the <code>config.toml</code> file of your relay in the <code>tlsca_cert_path</code> property (see the earlier section on relay configuration).</li> <li>To communicate with your network' relay using TLS (i.e., if the relay is TLS-enabled), specify that relay's TLS CA certificate path in <code>RELAY_TLSCA_CERT_PATH</code> (currently only one certificate can be configured) and set <code>RELAY_TLS</code> to <code>true</code>. This CA certificate should match the one specified in the <code>cert_path</code> property in the relay's <code>config.toml</code> file (see the earlier section on relay configuration):</li> <li>You can point to the folder in your host system containing the certificate and key using the <code>TLS_CREDENTIALS_DIR</code> variable. (This folder will be synced to the <code>/fabric-driver/credentials</code> folder in the Fabric Driver container as specified in the docker compose file.) Make sure you point to the right certificate and key file paths within the container using the <code>DRIVER_TLS_CERT_PATH</code>, <code>DRIVER_TLS_KEY_PATH</code>, and <code>RELAY_TLSCA_CERT_PATH</code> variables.</li> </ul> </li> </ul> </li> <li> <p><code>config.json</code>: This contains settings used to connect to a CA of a Fabric network organization and enroll a client. A sample is given below:   <pre><code>{\n    \"admin\":{\n        \"name\":\"admin\",\n        \"secret\":\"adminpw\"\n    },\n    \"relay\": {\n        \"name\":\"relay\",\n        \"affiliation\":\"&lt;affiliation&gt;\",\n        \"role\": \"client\",\n        \"attrs\": [{ \"name\": \"relay\", \"value\": \"true\", \"ecert\": true }]\n    },\n    \"mspId\":\"&lt;msp-id&gt;\",\n    \"caUrl\":\"&lt;ca-service-endpoint&gt;\"\n}\n</code></pre></p> <ul> <li>As in the <code>.env</code> configuration, you should pick an organization for the driver to associate with. The <code>admin</code> section specifies the registrar name and password (this should be familiar to any Fabric network administrator) used to enroll clients. Default values of <code>admin</code> and <code>adminpw</code> are specified above as examples, which you should replace with the right values configured in your network organization's CA.</li> <li><code>&lt;affiliation&gt;</code> should be what's specified in your organization's Fabric CA server configuration. The default is <code>org1.department1</code>, but you should look up the appropriate value from the CA server's configuration file.</li> <li><code>&lt;msp-id&gt;</code> should be set to the (or an) MSP ID of the selected organization.</li> <li><code>&lt;ca-service-endpoint&gt;</code> should be set to the CA server's endpoint. If you launched your CA server as a container from a docker compose file, this should be set to the container's service name.</li> </ul> </li> </ul> Notes If your connection profile already contains specifications for a CA server, you can leave the <code>&lt;ca-service-endpoint&gt;</code> value as a blank. <ul> <li><code>docker-compose.yaml</code>: This specifies the properties of the driver container. You can use the file in the repository verbatim.</li> </ul> <p>To start the driver, navigate to the folder containing the above files and run the following: <pre><code>docker compose up -d\n</code></pre></p>"},{"location":"weaver/getting-started/enabling-weaver-network/fabric/#launch-iin-agents","title":"Launch IIN Agents","text":"<p>You need to run one IIN Agent for each organization in the Fabric network channel you are enabling Weaver in. This agent runs a protocol with other organizations' agents and with targeted foreign networks' agents to sync and record foreign networks' memberships to the channel ledger.</p> <p>Weaver provides a pre-built image for the IIN Agent. Before launching a container, you just need to customize its configuration for your Fabric network organization, which you can do by simply creating a folder (let's call it <code>iin_agent_config_&lt;orgname&gt;</code>) and configuring the following files in it:</p> <ul> <li> <p><code>config.json</code>: This contains settings used to connect to a Fabric network organization and its CA (part of the organization's MSP). A sample is given below:   <pre><code>{\n    \"admin\":{\n        \"name\":\"admin\",\n        \"secret\":\"adminpw\"\n    },\n    \"agent\": {\n        \"name\":\"iin-agent\",\n        \"affiliation\":\"&lt;affiliation&gt;\",\n        \"role\": \"client\",\n        \"attrs\": [{ \"name\": \"iin-agent\", \"value\": \"true\", \"ecert\": true }]\n    },\n    \"mspId\":\"&lt;msp-id&gt;\",\n    \"ordererMspIds\": [&lt;list-of-orderer-msp-ids&gt;],\n    \"ccpPath\": \"&lt;path-to-connection-profile&gt;\",\n    \"walletPath\": \"\",\n    \"caUrl\": \"&lt;ca-service-endpoint&gt;\",\n    \"local\": \"false\"\n}\n</code></pre></p> </li> <li> <p><code>dnsconfig.json</code>: This specifies the list of known IIN agents of your network (i.e., belonging to other organizations) and of foreign networks. A sample DNS configuration file is given below:   <pre><code>{\n    \"&lt;securityDomainName1&gt;\": {\n        \"&lt;iin-agent1-name&gt;\": {\n            \"endpoint\": \"&lt;hostname:port&gt;\",\n            \"tls\": &lt;true/false&gt;,\n            \"tlsCACertPath\": \"&lt;cacert-path-or-empty-string&gt;\"\n        },\n        \"&lt;iin-agent2-name&gt;\": {\n            \"endpoint\": \"&lt;hostname:port&gt;\",\n            \"tls\": &lt;true/false&gt;,\n            \"tlsCACertPath\": \"&lt;cacert-path-or-empty-string&gt;\"\n        }\n    },\n    \"&lt;securityDomainName2&gt;\": {\n        \"&lt;iin-agent1-name&gt;\": {\n            \"endpoint\": \"&lt;hostname:port&gt;\",\n            \"tls\": &lt;true/false&gt;,\n            \"tlsCACertPath\": \"&lt;cacert-path-or-empty-string&gt;\"\n        },\n        \"&lt;iin-agent2-name&gt;\": {\n            \"endpoint\": \"&lt;hostname:port&gt;\",\n            \"tls\": &lt;true/false&gt;,\n            \"tlsCACertPath\": \"&lt;cacert-path-or-empty-string&gt;\"\n        }\n    }\n}\n</code></pre></p> <ul> <li>Each security domain (i.e., unique ledger, like a Fabric channel) scopes a set of JSON objects, each containing specifications of an IIN Agent. The key (<code>&lt;iin-agent1-name&gt;</code> for example) in each is the IIN Agent's name, which can be the organization's MSP ID (for a Fabric network). The value is another JSON object, containing an <code>endpoint</code> with a hostname and port for the agent.</li> <li>Enabling TLS: To communicate with a given IIN Agent using TLS (i.e., if that agent is TLS-enabled), specify <code>tls</code> as <code>true</code> and that agent's TLS CA certificate path in <code>tlsCACertPath</code> (currently only one certificate can be configured) within the JSON object corresponding to that agent. This CA certificate should match the one specified in that IIN Agent's <code>.env</code> file, whose configuration we will specify later.</li> </ul> </li> <li> <p><code>security-domain-config.json</code>: This config file contains list of security domain defined for the network and its members, i.e. it can be list of organizations or channel name. Sample security domain configuration file:   <pre><code>{\n    \"&lt;securityDomainName1&gt;\": \"&lt;channelName&gt;\",\n    \"&lt;securityDomainName2&gt;\": [\n        \"&lt;Org1MSPId&gt;\",\n        \"&lt;Org2MSPId&gt;\"\n    ]\n}\n</code></pre></p> </li> <li> <p><code>.env</code>: This sets suitable environment variables within the driver container. Copy the <code>.env.template</code> file from the repository and customize it for your purposes, as indicated in the below sample:   <pre><code>IIN_AGENT_PORT=&lt;iin-agent-server-port&gt;\nIIN_AGENT_TLS=&lt;true/false&gt;\nIIN_AGENT_TLS_CERT_PATH=&lt;path_to_tls_cert_pem_for_iin_agent&gt;\nIIN_AGENT_TLS_KEY_PATH=&lt;path_to_tls_key_pem_for_iin_agent&gt;\nMEMBER_ID=&lt;org-msp-id&gt;\nSECURITY_DOMAIN=network1\nDLT_TYPE=fabric\nCONFIG_PATH=./config.json\nDNS_CONFIG_PATH=./dnsconfig.json\nSECURITY_DOMAIN_CONFIG_PATH=./security-domain-config.json\nWEAVER_CONTRACT_ID=&lt;name-of-weaver-interop-chaincode-installed&gt;\nSYNC_PERIOD=&lt;repeated_auto_sync_interval&gt;\nAUTO_SYNC=&lt;true/false&gt;\nTLS_CREDENTIALS_DIR=&lt;dir-with-tls-cert-and-key&gt;\nDOCKER_IMAGE_NAME=ghcr.io/hyperledger/cacti-weaver-iin-agent\nDOCKER_TAG=&lt;iin-agent-docker-image-version&gt;\nEXTERNAL_NETWORK=&lt;docker-bridge-network&gt;\n</code></pre></p> <ul> <li><code>IIN_AGENT_ENDPOINT</code>: The endpoint at which IIN Agent server should listen. E.g.: <code>0.0.0.0:9500</code></li> <li><code>IIN_AGENT_TLS</code>: Set this to <code>true</code> to enable TLS on IIN Agent server</li> <li><code>IIN_AGENT_TLS_CERT_PATH</code>: Path to TLS certificate if TLS is enabled</li> <li><code>IIN_AGENT_TLS_KEY_PATH</code>: Path to TLS key if TLS is enabled</li> <li><code>MEMBER_ID</code>: Member Id for this IIN Agent. For fabric network, it should be the Organization's MSP ID</li> <li><code>SECURITY_DOMAIN</code>: Security domain to which this IIN Agent belongs</li> <li><code>DLT_TYPE</code>: To indicate the type of DLT for which this IIN Agent is running. E.g. <code>fabric</code></li> <li><code>CONFIG_PATH</code>: Path to ledger specific config file (explained in next subsection)</li> <li><code>DNS_CONFIG_PATH</code>: Path to DNS config file explained in previous sub sections</li> <li><code>SECURITY_DOMAIN_CONFIG_PATH</code>: Path to security domain config file explained in previous sub sections</li> <li><code>WEAVER_CONTRACT_ID</code>: Contract ID for DLT specific Weaver interoperation module installed on network</li> <li><code>SYNC_PERIOD</code>: Period at which auto synchronization of memberships from other security domains should happen</li> <li><code>AUTO_SYNC</code>: Set this to <code>true</code> to enable auto synchronization of memberships from other security domains</li> <li><code>DOCKER_TAG</code>: Set this to the desired version of the Weaver IIN Agent docker image</li> <li><code>EXTERNAL_NETWORK</code>: Set to the network name of your Fabric network.</li> <li>Enabling TLS:<ul> <li>Make your IIN Agent accept TLS connections by specifying <code>IIN_AGENT_TLS</code> as <code>true</code> and specifying a TLS certificate file path and private key file path in <code>IIN_AGENT_TLS_CERT_PATH</code> and <code>IIN_AGENT_TLS_KEY_PATH</code> respectively. The same certificate should be specified in this agent's JSON object in another agent's <code>dnsconfig.json</code> file under the appropriate security domain and IIN Agent ID scope.</li> <li>You can point to the folder in your host system containing the certificate and key using the <code>TLS_CREDENTIALS_DIR</code> variable. (This folder will be synced to the <code>/opt/iinagent/credentials</code> folder in the IIN Agent container as specified in the docker compose file.) Make sure you point to the right certificate and key file paths within the container using the <code>IIN_AGENT_TLS_CERT_PATH</code> and <code>IIN_AGENT_TLS_KEY_PATH</code> variables respectively.</li> </ul> </li> </ul> </li> <li> <p><code>docker-compose.yaml</code>: This specifies the properties of the IIN agent container. You can use the file in the repository verbatim.</p> </li> </ul> <p>Now to start the IIN agent, navigate to the folder containing the above files and run the following: <pre><code>docker compose up -d\n</code></pre></p> <p>Repeat the above steps to launch an IIN Agent for every other organization on your channnel, i.e., create similar configuration files in an organization-specific folder. Make sure you:</p> <ul> <li>Update the organization names in every relevant location in the <code>config.json</code>.</li> <li>Update <code>IIN_AGENT_ENDPOINT</code> and <code>MEMBER_ID</code> in the <code>.env</code>.</li> </ul>"},{"location":"weaver/getting-started/enabling-weaver-network/fabric/#ledger-initialization","title":"Ledger Initialization","text":"<p>To prepare your network for interoperation with a foreign network, you need to record the following to your network channel through the Fabric Interoperation Chaincode:</p> <ul> <li>Access control policies:   Let's take the example of the request made from <code>trade-finance-network</code> to <code>trade-logistics-network</code> for a B/L earlier in this document. <code>trade-logistics-network</code> can have a policy of the following form permitting access to the <code>GetBillOfLading</code> function from a client belonging to the <code>Exporter</code> organization in <code>trade-finance-network</code> as follows:   <pre><code>{\n    \"securityDomain\":\"trade-finance-network\",\n    \"rules\":\n        [\n            {\n                \"principal\":\"ExporterMSP\",\n                \"principalType\":\"ca\",\n                \"resource\":\"tradelogisticschannel:shipmentcc:GetBillOfLading:*\",\n                \"read\":true\n            }\n        ]\n}\n</code></pre>   In this sample, a single rule is specified for requests coming from <code>trade-finance-network</code>: it states that a <code>GetBillOfLading</code> query made to the <code>shipmentcc</code> contract installed on the <code>tradelogisticschannel</code> channel is permitted for a requestor possessing credentials certified by an MSP with the <code>ExporterMSP</code> identity. The <code>*</code> at the end indicates that any arguments passed to the function will pass the access control check.</li> </ul> <p>You need to record this policy rule on your Fabric network's channel by invoking either the <code>CreateAccessControlPolicy</code> function or the <code>UpdateAccessControlPolicy</code> function on the Fabric Interoperation Chaincode that is already installed on that channel; use the former if you are recording a set of rules for the given <code>securityDomain</code> for the first time and the latter to overwrite a set of rules recorded earlier. In either case, the chaincode function will take a single argument, which is the policy in the form of a JSON string (make sure you escape the double quotes before sending the request to avoid parsing errors). You can do this in one of two ways: (1) writing a small piece of code in Layer-2 that invokes the contract using the Fabric SDK Gateway API, or (2) running a <code>peer chaincode invoke</code> command from within a Docker container built on the <code>hyperledger/fabric-tools</code> image. Either approach should be familiar to a Fabric practitioner.</p> <ul> <li>Verification policies:   Taking the same example as above, an example of a verification policy for a B/L requested by the <code>trade-finance-network</code> from the <code>trade-logistics-network</code> is as follows:   <pre><code>{\n    \"securityDomain\":\"trade-logistics-network\",\n    \"identifiers\":\n        [\n            {\n                \"pattern\":\"tradelogisticschannel:shipmentcc:GetBillOfLading:*\",\n                \"policy\":\n                    {\n                        \"type\":\"Signature\",\n                        \"criteria\":\n                            [\n                                \"ExporterMSP\",\n                                \"CarrierMSP\"\n                            ]\n                    }\n            }\n        ]\n}\n</code></pre>   In this sample, a single verification policy rule is specified for data views coming from <code>trade-logistics-network</code>: it states that the data returned by the <code>GetBillOfLading</code> query made to the <code>shipmentcc</code> chaincode on the <code>tradelogisticschannel</code> channel requires as proof two signatures, one from a peer in the organization whose MSP ID is <code>ExporterMSP</code> and another from a peer in the organization whose MSP ID is <code>CarrierMSP</code>.</li> </ul> <p>You need to record this policy rule on your Fabric network's channel by invoking either the <code>CreateVerificationPolicy</code> function or the <code>UpdateVerificationPolicy</code> function on the Fabric Interoperation Chaincode that is already installed on that channel; use the former if you are recording a set of rules for the given <code>securityDomain</code> for the first time and the latter to overwrite a set of rules recorded earlier. In either case, the chaincode function will take a single argument, which is the policy in the form of a JSON string (make sure you escape the double quotes before sending the request to avoid parsing errors). As with the access control policy, you can do this in one of two ways: (1) writing a small piece of code in Layer-2 that invokes the contract using the Fabric SDK Gateway API, or (2) running a <code>peer chaincode invoke</code> command from within a Docker container built on the <code>hyperledger/fabric-tools</code> image. Either approach should be familiar to a Fabric practitioner.</p> Notes For any cross-network data request, make sure an access control policy is recorded in the source network (<code>trade-logistics-network</code> in the above example) and a corresponding verification policy is recorded in the destination network (<code>trade-finance-network</code> in the above example) before any relay request is triggered. <ul> <li>Local network security domain (membership) configuration:   Recall the code snippet added to your application in the \"Identity Administration\" section. Exercise that code snippet, exposed either through a function API or an HTTP endpoint, to record the initial local membership for the relevant network channels.</li> </ul> <p>Your Fabric network is now up and running with the necessary Weaver components, and your network's channel's ledger is bootstrapped with the initial configuration necessary for cross-network interactions!</p>"},{"location":"weaver/getting-started/enabling-weaver-network/overview/","title":"Enabling Cacti Weaver in Existing DLT Applications Overview","text":"<p>If you have an existing DLT network and application suite built on any of the following platforms, follow the appropriate link below to understand how to adapt it to use Cacti-Weaver capabilities for cross-network interactions.</p> <ul> <li>Hyperledger Fabric</li> <li>R3 Corda</li> <li>Hyperledger Besu</li> </ul>"},{"location":"weaver/getting-started/interop/asset-transfer/","title":"Asset Transfer","text":"<p>This document lists sample ways in which you can exercise the asset-transfer interoperation protocol on the test network launched earlier.</p> <p>Once the networks, relays, and drivers have been launched, and the ledgers bootstrapped, you can trigger the following interoperation flows corresponding to distinct asset-sharing combinations other combinations of DLTs will be supported soon):</p>"},{"location":"weaver/getting-started/interop/asset-transfer/#1-fabric-with-fabric","title":"1. Fabric with Fabric","text":"<p>One Fabric network transfers either a bond or some tokens owned by Alice to Bob in the other network</p> <p>Assuming that the <code>simpleassettransfer</code> chaincode has been deployed in both networks, run the following steps by navigating to the <code>samples/fabric/fabric-cli</code> folder (the Go CLI doesn't support asset transfer yet).</p>"},{"location":"weaver/getting-started/interop/asset-transfer/#transfer-or-recover-a-bond-non-fungible-asset","title":"Transfer or recover a bond (non-fungible) asset","text":"<ol> <li>Verify that <code>alice</code> owns bonds with ids <code>a03</code> and <code>a04</code> as follows:    <pre><code>./bin/fabric-cli chaincode query --user=alice mychannel simpleassettransfer ReadAsset '[\"bond01\",\"a03\"]' --local-network=network1\n./bin/fabric-cli chaincode query --user=alice mychannel simpleassettransfer ReadAsset '[\"bond01\",\"a04\"]' --local-network=network1\n</code></pre>    You should see a JSON structure corresponding to the bond being logged on the console in each case.</li> <li>Get <code>alice</code> in <code>network1</code> to pledge bond <code>a03</code> to <code>bob</code> in <code>network2</code> as follows (with a 1 hour timeout):    <pre><code>./bin/fabric-cli asset transfer pledge --source-network=network1 --dest-network=network2 --recipient=bob --expiry-secs=3600 --type=bond --ref=a03 --data-file=src/data/assetsForTransfer.json\n</code></pre>    You should see a message containing the unique ID of this pledge on the console as <code>Asset pledged with ID &lt;pledge-id&gt;</code> (<code>&lt;pledge-id&gt;</code> is a hexadecimal string).</li> <li>Get <code>bob</code> in <code>network2</code> to claim this bond asset as follows:    <pre><code>./bin/fabric-cli asset transfer claim --source-network=network1 --dest-network=network2 --user=bob --owner=alice --type='bond.fabric' --pledge-id=&lt;pledge-id&gt; --param=bond01:a03\n</code></pre></li> <li>Verify that <code>alice</code> in <code>network1</code> does not own this asset as follows:    <pre><code>./bin/fabric-cli chaincode query --user=alice mychannel simpleassettransfer ReadAsset '[\"bond01\",\"a03\"]' --local-network=network1\n</code></pre>    You should see an error message like <code>Error: the asset a03 does not exist</code>.</li> <li>Verify that <code>bob</code> in <code>network2</code> now owns this asset as follows:    <pre><code>./bin/fabric-cli chaincode query --user=bob mychannel simpleassettransfer ReadAsset '[\"bond01\",\"a03\"]' --local-network=network2\n</code></pre></li> <li>Now get <code>alice</code> in <code>network1</code> to pledge bond <code>a04</code> to <code>bob</code> in <code>network2</code> as follows (with a 1 minute timeout):    <pre><code>./bin/fabric-cli asset transfer pledge --source-network=network1 --dest-network=network2 --recipient=bob --expiry-secs=60 --type=bond --ref=a04 --data-file=src/data/assetsForTransfer.json\n</code></pre>    Wait for a minute as follows:    <pre><code>sleep 60\n</code></pre>    You should see a message containing the unique ID of this pledge on the console as <code>Asset pledged with ID &lt;pledge-id&gt;</code> (<code>&lt;pledge-id&gt;</code> is a hexadecimal string).</li> <li>Now get <code>bob</code> in <code>network2</code> to claim this bond asset as follows:    <pre><code>./bin/fabric-cli asset transfer claim --source-network=network1 --dest-network=network2 --user=bob --owner=alice --type='bond.fabric' --pledge-id=&lt;pledge-id&gt; --param=bond01:a04\n</code></pre>    This should fail as the pledge has already expired.</li> <li>Now get <code>alice</code> in <code>network1</code> to reclaim the asset as follows:    <pre><code>./bin/fabric-cli asset transfer reclaim --source-network=network1 --user=alice --type='bond.fabric' --pledge-id=&lt;pledge-id&gt; --param=bond01:a04\n</code></pre></li> <li>Verify that <code>alice</code> in <code>network1</code> owns this asset as follows:    <pre><code>./bin/fabric-cli chaincode query --user=alice mychannel simpleassettransfer ReadAsset '[\"bond01\",\"a04\"]' --local-network=network1\n</code></pre></li> <li>Verify that <code>bob</code> in <code>network2</code> does not own this asset as follows:    <pre><code>./bin/fabric-cli chaincode query --user=bob mychannel simpleassettransfer ReadAsset '[\"bond01\",\"a04\"]' --local-network=network2\n</code></pre>    You should see an error message like <code>Error: the asset a04 does not exist</code>.</li> </ol>"},{"location":"weaver/getting-started/interop/asset-transfer/#transfer-or-recover-token-fungible-assets","title":"Transfer or recover token (fungible) assets","text":"<ol> <li>Verify that <code>alice</code> in <code>network1</code> owns <code>10000</code> tokens as follows:    <pre><code>./scripts/getTokenBalance.sh network1 alice\n</code></pre></li> <li>Verify that <code>bob</code> in <code>network2</code> owns no tokens as follows:    <pre><code>./scripts/getTokenBalance.sh network2 bob\n</code></pre>    You should see an error message like <code>Error: owner does not have a wallet</code>.</li> <li>Get <code>alice</code> in <code>network1</code> to pledge 50 tokens to <code>bob</code> in <code>network2</code> as follows (with a 1 hour timeout):    <pre><code>./bin/fabric-cli asset transfer pledge --source-network=network1 --dest-network=network2 --recipient=bob --expiry-secs=3600 --type=token --units=50 --owner=alice --data-file=src/data/tokensForTransfer.json\n</code></pre>    You should see a message containing the unique ID of this pledge on the console as <code>Asset pledged with ID &lt;pledge-id&gt;</code> (<code>&lt;pledge-id&gt;</code> is a hexadecimal string).</li> <li>Get <code>bob</code> in <code>network2</code> to claim these tokens as follows (replace <code>&lt;pledge-id&gt;</code> with the above hexadecimal value):    <pre><code>./bin/fabric-cli asset transfer claim --source-network=network1 --dest-network=network2 --user=bob --owner=alice --type='token.fabric' --pledge-id=&lt;pledge-id&gt; --param=token1:50\n</code></pre></li> <li>Verify that <code>alice</code> in <code>network1</code> owns <code>9950</code> tokens (after losing <code>50</code>) as follows:    <pre><code>./scripts/getTokenBalance.sh network1 alice\n</code></pre></li> <li>Verify that <code>bob</code> in <code>network2</code> now owns <code>50</code> tokens as follows:    <pre><code>./scripts/getTokenBalance.sh network2 bob\n</code></pre></li> <li>Now get <code>alice</code> in <code>network1</code> to pledge 100 tokens to <code>bob</code> in <code>network2</code> as follows (with a 1 minute timeout):    <pre><code>./bin/fabric-cli asset transfer pledge --source-network=network1 --dest-network=network2 --recipient=bob --expiry-secs=60 --type=token --units=100 --owner=alice --data-file=src/data/tokensForTransfer.json\n</code></pre>    Wait for a minute as follows:    <pre><code>sleep 60\n</code></pre>    You should see a message containing the unique ID of this pledge on the console as <code>Asset pledged with ID &lt;pledge-id&gt;</code> (<code>&lt;pledge-id&gt;</code> is a hexadecimal string).</li> <li>Now get <code>bob</code> in <code>network2</code> to claim these tokens as follows (replace <code>&lt;pledge-id&gt;</code> with the above hexadecimal value):    <pre><code>./bin/fabric-cli asset transfer claim --source-network=network1 --dest-network=network2 --user=bob --owner=alice --type='token.fabric' --pledge-id=&lt;pledge-id&gt; --param=token1:100\n</code></pre>    This should fail as the pledge has already expired.</li> <li>Now get <code>alice</code> in <code>network1</code> to reclaim these tokens as follows:    <pre><code>./bin/fabric-cli asset transfer reclaim --source-network=network1 --user=alice --type='token.fabric' --pledge-id=&lt;pledge-id&gt; --param=token1:100\n</code></pre></li> <li>Verify that <code>alice</code> in <code>network1</code> still owns <code>9950</code> tokens (after losing <code>50</code>) as follows:    <pre><code>./scripts/getTokenBalance.sh network1 alice\n</code></pre></li> <li>Verify that <code>bob</code> in <code>network2</code> still owns only <code>50</code> tokens as follows:    <pre><code>./scripts/getTokenBalance.sh network2 bob\n</code></pre></li> </ol>"},{"location":"weaver/getting-started/interop/asset-transfer/#2-corda-with-corda","title":"2. Corda with Corda","text":"<p>One Corda network transfers either a bond or some tokens owned by the party <code>PartyA</code> (<code>CORDA_PORT=10006</code>) to the party <code>PartyA</code> (<code>CORDA_PORT=30006</code>) in the other network.</p>"},{"location":"weaver/getting-started/interop/asset-transfer/#transfer-or-recover-token-fungible-assets_1","title":"Transfer or recover token (fungible) assets","text":"<p>Assume that the CorDapp <code>cordaSimpleApplication</code> has been deployed in both networks.</p> <ul> <li>Navigate to the <code>weaver/samples/corda/corda-simple-application</code> folder in your clone of the Cacti repository.</li> <li> <p>Add <code>5</code> tokens of type <code>t1</code> to <code>PartyA</code> in <code>Corda_Network</code>:   <pre><code>NETWORK_NAME='Corda_Network' CORDA_PORT=10006 ./clients/build/install/clients/bin/clients issue-asset-state 5 t1\n</code></pre>   (check token balance for <code>PartyA</code> by running the command <code>CORDA_PORT=10006 ./clients/build/install/clients/bin/clients get-asset-states-by-type t1</code>)</p> </li> <li> <p>Let <code>PartyA</code> pledge these tokens in <code>Corda_Network</code> to be transferred to <code>PartyA</code> of <code>Corda_Network2</code> (pledge burns the tokens in the source/exporting network):   <pre><code>NETWORK_NAME='Corda_Network' CORDA_PORT=10006 ./clients/build/install/clients/bin/clients transfer pledge-asset --fungible --timeout=\"3600\" --import-network-id='Corda_Network2' --recipient='O=PartyA, L=London, C=GB' --param='t1:5'\n</code></pre>   Note the <code>pledge-id</code> displayed after successful execution of the command, which will be used in next steps. Let's denote it <code>&lt;pledge-id&gt;</code> which is a hexadecimal string (pledge details can be cross checked using the commands <code>CORDA_PORT=10006 ./clients/build/install/clients/bin/clients transfer is-asset-pledged -pid &lt;pledge-id&gt;</code> and <code>CORDA_PORT=10006  ./clients/build/install/clients/bin/clients transfer get-pledge-state -pid &lt;pledge-id&gt;</code>).</p> </li> <li> <p>Check the token asset balance for <code>PartyA</code> in <code>Corda_Network</code> by running the below command, and the output should not include the asset <code>t1:5</code> issued earlier.   <pre><code>CORDA_PORT=10006 ./clients/build/install/clients/bin/clients get-asset-states-by-type t1\n</code></pre></p> </li> <li>Let <code>PartyA</code> claim in <code>Corda_Network2</code> the tokens which are pledged in the Corda network <code>Corda_Network</code> by replacing <code>&lt;pledge-id&gt;</code> with the above hexadecimal value (claim issues the tokens in the destination/importing network):   <pre><code>NETWORK_NAME='Corda_Network2' CORDA_PORT=30006 ./clients/build/install/clients/bin/clients transfer claim-remote-asset --pledge-id='&lt;pledge-id&gt;' --locker='O=PartyA, L=London, C=GB' --transfer-category='token.corda' --export-network-id='Corda_Network' --param='t1:5' --import-relay-address='localhost:9082'\n</code></pre>   (the <code>linear-id</code>, which is displayed after successful execution of the above command, can be used to check the newly issued tokens for <code>PartyA</code> in <code>Corda_Network2</code> by running <code>CORDA_PORT=30006 ./clients/build/install/clients/bin/clients get-state-using-linear-id &lt;linear-id&gt;</code>; or simply check the token balance for <code>PartyA</code> by running the command <code>CORDA_PORT=30006 ./clients/build/install/clients/bin/clients get-asset-states-by-type t1</code> which should output <code>5</code> tokens of type <code>t1</code>)</li> </ul> <p>The above steps complete a successful asset transfer from the Corda network <code>Corda_Network</code> to the Corda network <code>Corda_Network2</code>. In addition to the above commands, following is an extra option.</p> <ul> <li>Let <code>PartyA</code> in <code>Corda_Network</code> try re-claim the token <code>t1:5</code> asset, which will succeed only if the asset was not claimed by <code>PartyA</code> in <code>Corda_Network2</code> and the pledge has expired:   <pre><code>NETWORK_NAME=Corda_Network CORDA_PORT=10006 ./clients/build/install/clients/bin/clients transfer reclaim-pledged-asset --pledge-id=&lt;pledge-id&gt; --export-relay-address='localhost:9081' --transfer-category='token.corda' --import-network-id='Corda_Network2' --param='t1:5'\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/interop/asset-transfer/#transfer-or-recover-bond-non-fungible-assets","title":"Transfer or recover bond (non-fungible) assets","text":"<p>Assume that the CorDapp <code>cordaSimpleApplication</code> has been deployed in both networks.</p> <ul> <li>Navigate to the <code>weaver/samples/corda/corda-simple-application</code> folder in your clone of the Cacti repository.</li> <li> <p>Add a bond asset with id <code>a10</code> and type <code>bond01</code> to <code>PartyA</code> in <code>Corda_Network</code>:   <pre><code>NETWORK_NAME=Corda_Network CORDA_PORT=10006 ./clients/build/install/clients/bin/clients bond issue-asset 'a10' 'bond01'\n</code></pre>   (check token balance for <code>PartyA</code> by running the command <code>CORDA_PORT=10006 ./clients/build/install/clients/bin/clients bond get-assets-by-type 'bond01'</code>)</p> </li> <li> <p>Let <code>PartyA</code> pledge these tokens in <code>Corda_Network</code> to be transferred to <code>PartyA</code> of <code>Corda_Network2</code> (pledge burns the tokens in the source/exporting network):   <pre><code>NETWORK_NAME=Corda_Network CORDA_PORT=10006 ./clients/build/install/clients/bin/clients transfer pledge-asset --timeout=\"3600\" --import-network-id='Corda_Network2' --recipient='O=PartyA, L=London, C=GB' --param='bond01:a10'\n</code></pre>   Note the <code>pledge-id</code> displayed after successful execution of the command, which will be used in next steps. Let's denote it <code>&lt;pledge-id&gt;</code> which is a hexadecimal string (pledge details can be cross checked using the commands <code>CORDA_PORT=10006 ./clients/build/install/clients/bin/clients transfer is-asset-pledged -pid &lt;pledge-id&gt;</code> and <code>CORDA_PORT=10006  ./clients/build/install/clients/bin/clients transfer get-pledge-state -pid &lt;pledge-id&gt;</code>).</p> </li> <li> <p>Check the bond asset balance for <code>PartyA</code> in <code>Corda_Network</code> by running the below command, and the output should not include the asset <code>bond01:a10</code> issued earlier.   <pre><code>CORDA_PORT=10006 ./clients/build/install/clients/bin/clients bond get-assets-by-type 'bond01'`\n</code></pre></p> </li> <li>Let <code>PartyA</code> in <code>Corda_Network2</code> claim the bond asset which is pledged in the Corda network <code>Corda_Network</code> by replacing <code>&lt;pledge-id&gt;</code> with the above hexadecimal value (claim issues the bond asset in the destination/importing network):   <pre><code>NETWORK_NAME=Corda_Network2 CORDA_PORT=30006 ./clients/build/install/clients/bin/clients transfer claim-remote-asset --pledge-id='&lt;pledge-id&gt;' --locker='O=PartyA, L=London, C=GB' --transfer-category='bond.corda' --export-network-id='Corda_Network' --param='bond01:a10' --import-relay-address='localhost:9082'\n</code></pre>   (the <code>linear-id</code>, which is displayed after successful execution of the above command, can be used to check the newly issued bond asset for <code>PartyA</code> in <code>Corda_Network2</code> by running <code>CORDA_PORT=30006 ./clients/build/install/clients/bin/clients bond get-asset-by-linear-id &lt;linear-id&gt;</code>; or simply check the bond asset balance for <code>PartyA</code> by running the command <code>CORDA_PORT=30006 ./clients/build/install/clients/bin/clients bond get-assets-by-type 'bond01'</code> which should output asset with id <code>a10</code> and type <code>bond01</code>)</li> </ul> <p>The above steps complete a successful asset transfer from the Corda network <code>Corda_Network</code> to the Corda network <code>Corda_Network2</code>. In addition to the above commands, following is an extra option.</p> <ul> <li>Let <code>PartyA</code> in <code>Corda_Network</code> try re-claim the bond asset <code>bond01:a10</code>, which will succeed only if the asset was not claimed by <code>PartyA</code> and the pledge has expired:   <pre><code>NETWORK_NAME=Corda_Network CORDA_PORT=10006 ./clients/build/install/clients/bin/clients transfer reclaim-pledged-asset --pledge-id=&lt;pledge-id&gt; --export-relay-address='localhost:9081' --transfer-category='bond.corda' --import-network-id='Corda_Network2' --param='bond01:a10'\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/interop/asset-transfer/#3-fabric-with-corda","title":"3. Fabric with Corda","text":"<p>A Fabric network transfers some tokens owned by <code>Alice</code> to <code>PartyA</code> (<code>CORDA_PORT=10006</code>) in a Corda network.</p>"},{"location":"weaver/getting-started/interop/asset-transfer/#transfer-or-recover-token-fungible-assets_2","title":"Transfer or recover token (fungible) assets","text":"<p>Assuming that the <code>simpleassettransfer</code> chaincode has been deployed in Fabric network <code>network1</code>, run the following steps related to Fabric by navigating to the <code>samples/fabric/fabric-cli</code> folder (the Go CLI doesn't support asset transfer yet).</p> <p>Similarly, assuming that the CorDapp <code>cordaSimpleApplication</code> has been deployed in the Corda network <code>Corda_Network</code>, run the following steps related to Corda by navigating to the <code>samples/corda/corda-simple-application</code> folder.</p> <ul> <li> <p>Verify that <code>alice</code> in <code>network1</code> owns <code>10000</code> tokens as follows:    <pre><code>./scripts/getTokenBalance.sh network1 alice\n</code></pre></p> </li> <li> <p>Get <code>alice</code> in <code>network1</code> to pledge 50 tokens to <code>PartyA</code> in <code>Corda_Network</code> as follows (with a 1 hour timeout):    <pre><code>./bin/fabric-cli asset transfer pledge --source-network='network1' --dest-network='Corda_Network' --recipient='O=PartyA, L=London, C=GB' --expiry-secs=3600 --type='token' --units=50 --owner=alice --data-file=src/data/tokensForTransfer.json\n</code></pre>    You should see a message containing the unique ID of this pledge on the console as <code>Asset pledged with ID &lt;pledge-id&gt;</code> (<code>&lt;pledge-id&gt;</code> is a hexadecimal string).</p> </li> <li> <p>Verify that <code>alice</code> in <code>network1</code> owns <code>9950</code> tokens (after losing <code>50</code>) as follows:    <pre><code>./scripts/getTokenBalance.sh network1 alice\n</code></pre></p> </li> <li> <p>Let <code>PartyA</code> claim in <code>Corda_Network</code> the tokens which are pledged in the Fabric network <code>network1</code> by replacing <code>&lt;pledge-id&gt;</code> with the above hexadecimal value (claim issues the tokens in the destination/importing network):   <pre><code>NETWORK_NAME=Corda_Network CORDA_PORT=10006 ./clients/build/install/clients/bin/clients transfer claim-remote-asset --pledge-id='&lt;pledge-id&gt;' --locker='alice' --transfer-category='token.fabric' --export-network-id='network1' --param='token1:50' --import-relay-address='localhost:9081'\n</code></pre>   (the <code>linear-id</code>, which is displayed after successful execution of the above command, can be used to check the newly issued tokens for <code>PartyA</code> in <code>Corda_Network</code> by running <code>CORDA_PORT=10006 ./clients/build/install/clients/bin/clients get-state-using-linear-id &lt;linear-id&gt;</code>; or simply check the token balance for <code>PartyA</code> by running the command <code>CORDA_PORT=10006 ./clients/build/install/clients/bin/clients get-asset-states-by-type token1</code> which should output <code>50</code> tokens of type <code>token1</code>)</p> </li> </ul> <p>The above steps complete a successful asset transfer from the Fabric network <code>network1</code> to the Corda network <code>Corda_Network</code>. Below demostrates re-claim of the tokens pledged in the Fabric network after the pledge expiry.</p> <ul> <li>Now get <code>alice</code> in <code>network1</code> to pledge 100 tokens to <code>PartyA</code> in <code>Corda_Network</code> as follows (with a 1 minute timeout):    <pre><code>./bin/fabric-cli asset transfer pledge --source-network='network1' --dest-network='Corda_Network' --recipient='O=PartyA, L=London, C=GB' --expiry-secs=60 --type=token --units=100 --owner=alice --data-file=src/data/tokensForTransfer.json\n</code></pre>    You should see a message containing the unique ID of this pledge on the console as <code>Asset pledged with ID &lt;pledge-id&gt;</code> (<code>&lt;pledge-id&gt;</code> is a hexadecimal string).</li> </ul> <p>Wait for a minute as follows:    <pre><code>sleep 60\n</code></pre></p> <ul> <li>Let <code>PartyA</code> in <code>Corda_Network</code> claim the tokens which are pledged in the Fabric network <code>network1</code> by replacing <code>&lt;pledge-id&gt;</code> with the above hexadecimal value (claim issues the tokens in the destination/importing network):    <pre><code>NETWORK_NAME=Corda_Network CORDA_PORT=10006 ./clients/build/install/clients/bin/clients transfer claim-remote-asset --pledge-id='&lt;pledge-id&gt;' --locker='alice' --transfer-category='token.fabric' --export-network-id='network1' --param='token1:100' --import-relay-address='localhost:9080'\n</code></pre>    This should fail as the pledge has already expired.</li> </ul> <p>(check the token balance for <code>PartyA</code> by running the command <code>CORDA_PORT=10006 ./clients/build/install/clients/bin/clients get-asset-states-by-type token1</code> which should still show <code>50</code> tokens of type <code>token1</code> but not <code>150</code>)</p> <ul> <li> <p>Now get <code>alice</code> in <code>network1</code> to reclaim these tokens as follows:    <pre><code>./bin/fabric-cli asset transfer reclaim --source-network='network1' --user='alice' --type='token.corda' --pledge-id=&lt;pledge-id&gt; --param=token1:100\n</code></pre></p> </li> <li> <p>Verify that <code>alice</code> in <code>network1</code> still owns <code>9950</code> tokens (after losing <code>50</code>) as follows:    <pre><code>./scripts/getTokenBalance.sh network1 alice\n</code></pre></p> </li> </ul>"},{"location":"weaver/getting-started/interop/asset-transfer/#4-corda-with-fabric","title":"4. Corda with Fabric","text":"<p>A Corda network transfers some tokens owned by <code>PartyA</code> (<code>CORDA_PORT=10006</code>) to <code>Alice</code> in a Fabric network.</p>"},{"location":"weaver/getting-started/interop/asset-transfer/#transfer-or-recover-token-fungible-assets_3","title":"Transfer or recover token (fungible) assets","text":"<p>Assuming that the CorDapp <code>cordaSimpleApplication</code> has been deployed in the Corda network <code>Corda_Network</code>, run the following steps related to Corda by navigating to the <code>samples/corda/corda-simple-application</code> folder.</p> <p>Similarly, assume that the <code>simpleassettransfer</code> chaincode has been deployed in Fabric network <code>network1</code>, run the following steps related to Fabric by navigating to the <code>samples/fabric/fabric-cli</code> folder (the Go CLI doesn't support asset transfer yet).</p> <ul> <li> <p>Add <code>5</code> tokens of type <code>token1</code> to <code>PartyA</code> in <code>Corda_Network</code>:   <pre><code>CORDA_PORT=10006 ./clients/build/install/clients/bin/clients issue-asset-state 5 token1\n</code></pre>   (check token balance for <code>PartyA</code> by running the command <code>CORDA_PORT=10006 ./clients/build/install/clients/bin/clients get-asset-states-by-type token1</code>)</p> </li> <li> <p>Let <code>PartyA</code> pledge (with a 1 hour timeout) these tokens in <code>Corda_Network</code> to be transferred to <code>Alice</code> of Fabric network <code>network1</code> (pledge burns the tokens in the source/exporting network):   <pre><code>CORDA_PORT=10006 ./clients/build/install/clients/bin/clients transfer pledge-asset --fungible --timeout=\"3600\" --import-network-id='network1' --recipient='alice' --param='token1:5'\n</code></pre>   Note the <code>pledge-id</code> displayed after successful execution of the command, which will be used in next steps. Let's denote it <code>&lt;pledge-id&gt;</code> which is a hexadecimal string (pledge details can be cross checked using the commands <code>CORDA_PORT=10006 ./clients/build/install/clients/bin/clients transfer is-asset-pledged -pid &lt;pledge-id&gt;</code> and <code>CORDA_PORT=10006  ./clients/build/install/clients/bin/clients transfer get-pledge-state -pid &lt;pledge-id&gt;</code>).</p> </li> <li> <p>Check the token asset balance for <code>PartyA</code> in <code>Corda_Network</code> by running the below command, and the output should not include the asset <code>token1:5</code> issued earlier.   <pre><code>CORDA_PORT=10006 ./clients/build/install/clients/bin/clients get-asset-states-by-type token1`\n</code></pre></p> </li> <li> <p>Verify that <code>alice</code> in <code>network1</code> owns <code>10000</code> tokens as follows:    <pre><code>./scripts/getTokenBalance.sh network1 alice\n</code></pre></p> </li> <li> <p>Get <code>alice</code> in <code>network</code> to claim these tokens as follows (replace <code>&lt;pledge-id&gt;</code> with the above hexadecimal value):    <pre><code>./bin/fabric-cli asset transfer claim --source-network='Corda_Network' --dest-network=network1 --user='alice' --owner='O=PartyA, L=London, C=GB' --type='token.corda' --pledge-id=&lt;pledge-id&gt; --param=token1:5\n</code></pre></p> </li> <li> <p>Verify that <code>alice</code> in <code>network</code> now owns <code>1050</code> tokens as follows:    <pre><code>./scripts/getTokenBalance.sh network1 alice\n</code></pre></p> </li> </ul> <p>The above steps complete a successful asset transfer from the Corda network <code>Corda_Network</code> to the Fabric network <code>network1</code>. In addition to the above commands, following is an extra option.</p> <ul> <li>Let <code>PartyA</code> in <code>Corda_Network</code> try re-claim the token <code>token1:5</code> asset, which will succeed only if the asset was not claimed by <code>alice</code> in Fabric network and the pledge has expired (replace <code>&lt;pledge-id&gt;</code> with the above hexadecimal value):   <pre><code>NETWORK_NAME=Corda_Network CORDA_PORT=10006 ./clients/build/install/clients/bin/clients transfer reclaim-pledged-asset --pledge-id=&lt;pledge-id&gt; --export-relay-address='localhost:9081' --transfer-category='token.fabric' --import-network-id='network1' --param='token1:5'\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/interop/data-sharing/","title":"Data Sharing","text":"<p>This document lists sample ways in which you can exercise the data-sharing interoperation protocol on the test network launched earlier.</p> <p>Once the networks, relays, and drivers have been launched, and the ledgers bootstrapped, you can trigger four different interoperation flows corresponding to distinct data-sharing combinations as follows:</p> <ol> <li>Corda to Corda: Either Corda network requests state and proof from another Corda network</li> <li>Corda to Fabric: The Corda network requests state and proof from either Fabric network</li> <li>Fabric to Corda: Either Fabric network requests state and proof from the Corda network</li> <li>Fabric to Fabric: One Fabric network requests state and proof from another Fabric network</li> </ol> <p>We assume that one of the following chaincodes have been deployed in either Fabric network you are testing with:</p> <ul> <li><code>simplestate</code></li> <li><code>simplestatewithacl</code></li> </ul>"},{"location":"weaver/getting-started/interop/data-sharing/#corda-to-corda","title":"Corda to Corda","text":"<p>To test the scenario where <code>Corda_Network</code> requests the value of the state (key) <code>H</code> from <code>Corda_Network2</code> and writes the value to a key <code>H</code> in its local state, do the following:</p> <ul> <li>(Make sure the following are running: <code>Corda_Network</code>, relay, and driver; <code>Corda_Network2</code>, relay, and driver)</li> <li>Navigate to the <code>weaver/samples/corda/corda-simple-application</code> folder in your clone of the Cacti repository.</li> <li> <p>Run the following:</p> <ul> <li>If Relays and Drivers are deployed in the host machine:<ul> <li>Without TLS:   <pre><code>NETWORK_NAME=Corda_Network CORDA_PORT=10006 ./clients/build/install/clients/bin/clients request-state --wkey=H localhost:9081 localhost:9082/Corda_Network2/localhost:30006#com.cordaSimpleApplication.flow.GetStateByKey:H\n</code></pre></li> <li>With TLS:   <pre><code>RELAY_TLS=true RELAY_TLSCA_CERT_PATHS=../../../core/relay/credentials/fabric_ca_cert.pem NETWORK_NAME=Corda_Network CORDA_PORT=10006 ./clients/build/install/clients/bin/clients request-state --wkey=H localhost:9081 localhost:9082/Corda_Network2/localhost:30006#com.cordaSimpleApplication.flow.GetStateByKey:H\n</code></pre></li> </ul> </li> <li>If Relays and Drivers are deployed in Docker containers:<ul> <li>Without TLS:   <pre><code>NETWORK_NAME=Corda_Network CORDA_PORT=10006 ./clients/build/install/clients/bin/clients request-state --wkey=H localhost:9081 relay-corda2:9082/Corda_Network2/corda_network2_partya_1:10003#com.cordaSimpleApplication.flow.GetStateByKey:H\n</code></pre></li> <li>With TLS:   <pre><code>RELAY_TLS=true RELAY_TLSCA_CERT_PATHS=../../../core/relay/credentials/docker/ca-cert.pem NETWORK_NAME=Corda_Network CORDA_PORT=10006 ./clients/build/install/clients/bin/clients request-state --wkey=H localhost:9081 relay-corda2:9082/Corda_Network2/corda_network2_partya_1:10003#com.cordaSimpleApplication.flow.GetStateByKey:H\n</code></pre></li> </ul> </li> </ul> </li> <li> <p>Query the value of the requested state using key <code>H</code> in <code>Corda_Network</code> by running the following command:   <pre><code>NETWORK_NAME=Corda_Network CORDA_PORT=10006 ./clients/build/install/clients/bin/clients get-state H\n</code></pre></p> </li> </ul> <p>To test the scenario where <code>Corda_Network2</code> requests the value of the state (key) <code>C</code> from <code>Corda_Network</code> and writes the value to a key <code>C</code> in its local state, do the following:</p> <ul> <li>(Make sure the following are running: <code>Corda_Network</code>, relay, and driver; <code>Corda_Network2</code>, relay, and driver)</li> <li>Navigate to the <code>weaver/samples/corda/corda-simple-application</code> folder in your clone of the Cacti repository.</li> <li> <p>Run the following:</p> <ul> <li>If Relays and Drivers are deployed in the host machine:<ul> <li>Without TLS:   <pre><code>NETWORK_NAME=Corda_Network2 CORDA_PORT=30006 ./clients/build/install/clients/bin/clients request-state --wkey=C localhost:9082 localhost:9081/Corda_Network/localhost:10006#com.cordaSimpleApplication.flow.GetStateByKey:C\n</code></pre></li> <li>With TLS:   <pre><code>RELAY_TLS=true RELAY_TLSCA_CERT_PATHS=../../../core/relay/credentials/fabric_ca_cert.pem NETWORK_NAME=Corda_Network2 CORDA_PORT=30006 ./clients/build/install/clients/bin/clients request-state --wkey=C localhost:9082 localhost:9081/Corda_Network/localhost:10006#com.cordaSimpleApplication.flow.GetStateByKey:C\n</code></pre></li> </ul> </li> <li>If Relays and Drivers are deployed in Docker containers:<ul> <li>Without TLS:   <pre><code>NETWORK_NAME=Corda_Network2 CORDA_PORT=30006 ./clients/build/install/clients/bin/clients request-state --wkey=C localhost:9082 relay-corda:9081/Corda_Network/corda_partya_1:10003#com.cordaSimpleApplication.flow.GetStateByKey:C\n</code></pre></li> <li>With TLS:   <pre><code>RELAY_TLS=true RELAY_TLSCA_CERT_PATHS=../../../core/relay/credentials/docker/ca-cert.pem NETWORK_NAME=Corda_Network2 CORDA_PORT=30006 ./clients/build/install/clients/bin/clients request-state --wkey=C localhost:9082 relay-corda:9081/Corda_Network/corda_partya_1:10003#com.cordaSimpleApplication.flow.GetStateByKey:C\n</code></pre></li> </ul> </li> </ul> </li> <li> <p>Query the value of the requested state, using the key <code>C</code> in <code>Corda_Network</code> by running the following command:   <pre><code>NETWORK_NAME=Corda_Network2 CORDA_PORT=30006 ./clients/build/install/clients/bin/clients get-state C\n</code></pre></p> </li> </ul>"},{"location":"weaver/getting-started/interop/data-sharing/#corda-to-fabric","title":"Corda to Fabric","text":"<p>To test the scenario where <code>Corda_Network</code> requests the value of the state (key) <code>a</code> from <code>network1</code> and writes the value to a key <code>a</code> in its local state, do the following:</p> <ul> <li>(Make sure the following are running: Corda network, relay, and driver; Fabric <code>network1</code>, relay, and driver)</li> <li>Navigate to the <code>weaver/samples/corda/corda-simple-application</code> folder in your clone of the Cacti repository.</li> <li> <p>Run the following:</p> <ul> <li>If Relays and Drivers are deployed in the host machine:<ul> <li>Without TLS:   <pre><code>NETWORK_NAME=Corda_Network CORDA_PORT=10006 ./clients/build/install/clients/bin/clients request-state --wkey=a localhost:9081 localhost:9080/network1/mychannel:simplestate:Read:a\n</code></pre></li> <li>With TLS:   <pre><code>RELAY_TLS=true RELAY_TLSCA_CERT_PATHS=../../../core/relay/credentials/fabric_ca_cert.pem NETWORK_NAME=Corda_Network CORDA_PORT=10006 ./clients/build/install/clients/bin/clients request-state --wkey=a localhost:9081 localhost:9080/network1/mychannel:simplestate:Read:a\n</code></pre></li> </ul> </li> <li>If Relays and Drivers are deployed in Docker containers:<ul> <li>Without TLS:   <pre><code>NETWORK_NAME=Corda_Network CORDA_PORT=10006 ./clients/build/install/clients/bin/clients request-state --wkey=a localhost:9081 relay-network1:9080/network1/mychannel:simplestate:Read:a\n</code></pre></li> <li>With TLS:   <pre><code>RELAY_TLS=true RELAY_TLSCA_CERT_PATHS=../../../core/relay/credentials/docker/ca-cert.pem NETWORK_NAME=Corda_Network CORDA_PORT=10006 ./clients/build/install/clients/bin/clients request-state --wkey=a localhost:9081 relay-network1:9080/network1/mychannel:simplestate:Read:a\n</code></pre></li> </ul> </li> </ul> </li> <li> <p>Query the value of the requested state (key) <code>a</code> in <code>Corda_Network</code> using the following:   <pre><code>NETWORK_NAME=Corda_Network CORDA_PORT=10006 ./clients/build/install/clients/bin/clients get-state a\n</code></pre></p> </li> </ul> <p>To test the scenario where <code>Corda_Network</code> requests the value of the state (key) <code>Arcturus</code> from <code>network2</code> and writes the value to a key <code>Arcturus</code> in its local state, do the following:</p> <ul> <li>(Make sure the following are running: Corda network, relay, and driver; Fabric <code>network2</code>, relay, and driver)</li> <li>Navigate to the <code>weaver/samples/corda/corda-simple-application</code> folder in your clone of the Cacti repository.</li> <li> <p>Run the following:</p> <ul> <li>If Relays and Drivers are deployed in the host machine:<ul> <li>Without TLS:   <pre><code>NETWORK_NAME=Corda_Network CORDA_PORT=10006 ./clients/build/install/clients/bin/clients request-state --wkey=Arcturus localhost:9081 localhost:9083/network2/mychannel:simplestate:Read:Arcturus\n</code></pre></li> <li>With TLS:   <pre><code>RELAY_TLS=true RELAY_TLSCA_CERT_PATHS=../../../core/relay/credentials/fabric_ca_cert.pem NETWORK_NAME=Corda_Network CORDA_PORT=10006 ./clients/build/install/clients/bin/clients request-state --wkey=Arcturus localhost:9081 localhost:9083/network2/mychannel:simplestate:Read:Arcturus\n</code></pre></li> </ul> </li> <li>If Relays and Drivers are deployed in Docker containers:<ul> <li>Without TLS:   <pre><code>NETWORK_NAME=Corda_Network CORDA_PORT=10006 ./clients/build/install/clients/bin/clients request-state --wkey=Arcturus localhost:9081 relay-network2:9083/network2/mychannel:simplestate:Read:Arcturus\n</code></pre></li> <li>With TLS:   <pre><code>RELAY_TLS=true RELAY_TLSCA_CERT_PATHS=../../../core/relay/credentials/docker/ca-cert.pem NETWORK_NAME=Corda_Network CORDA_PORT=10006 ./clients/build/install/clients/bin/clients request-state --wkey=Arcturus localhost:9081 relay-network2:9083/network2/mychannel:simplestate:Read:Arcturus\n</code></pre></li> </ul> </li> </ul> </li> <li> <p>Query the value of the requested state (key) <code>Arcturus</code> in <code>Corda_Network</code> using the following:   <pre><code>NETWORK_NAME=Corda_Network CORDA_PORT=10006 ./clients/build/install/clients/bin/clients get-state Arcturus\n</code></pre></p> </li> </ul> Notes You can test the above data transfer scenario with <code>Corda_Network2</code> instead of <code>Corda_Network</code> by changing the following in the <code>request-state</code> or <code>get-state</code> command:<ul><li>Network name environment variable:<ul><li><code>NETWORK_NAME=Corda_Network</code> to <code>NETWORK_NAME=Corda_Network2</code></li></ul></li><li>Corda node's RPC endpoint port environment variable:<ul><li><code>CORDA_PORT=10006</code> to <code>CORDA_PORT=30006</code></li></ul></li><li>Local relay address<ul><li><code>localhost:9081</code> to <code>localhost:9082</code> (host deployment of relays and drivers)</li><li><code>relay-corda2:9081</code> to <code>relay-corda2:9082</code> (Docker container deployment of relays and drivers)</li></ul></li></ul>"},{"location":"weaver/getting-started/interop/data-sharing/#fabric-to-corda","title":"Fabric to Corda","text":"<p>To test the scenario where <code>network1</code> requests the value of the state (key) <code>H</code> from <code>Corda_Network</code> and writes the value to a key <code>H</code> in its local state, do the following:</p> <ul> <li>(Make sure the following are running: Corda network, relay, and driver; Fabric <code>network1</code>, relay, and driver)</li> <li>Navigate to the <code>weaver/samples/fabric/fabric-cli</code> (for the Node.js version) or the <code>weaver/samples/fabric/go-cli</code> (for the Golang version) folder in your clone of the Cacti repository.</li> <li>(Make sure you have configured <code>fabric-cli</code> as per earlier instructions)</li> <li>Edit <code>chaincode.json</code>: in the <code>simplestate:Create:args</code> attribute, replace the argument <code>\"a\"</code> with <code>\"H\"</code> (this specifies the key to which the data from the remote view is to be written into); i.e.,:   <pre><code>\"args\": [\"a\", \"\"]\n</code></pre>   with   <pre><code>\"args\": [\"H\", \"\"]\n</code></pre></li> <li> <p>Run the following:</p> <ul> <li>If Relays and Drivers are deployed in the host machine:<ul> <li>Without TLS:   <pre><code>./bin/fabric-cli interop --local-network=network1 --sign=true --requesting-org=Org1MSP localhost:9081/Corda_Network/localhost:10006#com.cordaSimpleApplication.flow.GetStateByKey:H --debug=true\n</code></pre></li> <li>With TLS:   <pre><code>./bin/fabric-cli interop --local-network=network1 --sign=true --requesting-org=Org1MSP --relay-tls=true --relay-tls-ca-files=../../../core/relay/credentials/fabric_ca_cert.pem localhost:9081/Corda_Network/localhost:10006#com.cordaSimpleApplication.flow.GetStateByKey:H --debug=true\n</code></pre></li> </ul> </li> <li>If Relays and Drivers are deployed in Docker containers:<ul> <li>Without TLS:   <pre><code>./bin/fabric-cli interop --local-network=network1 --sign=true --requesting-org=Org1MSP relay-corda:9081/Corda_Network/corda_partya_1:10003#com.cordaSimpleApplication.flow.GetStateByKey:H --debug=true\n</code></pre></li> <li>With TLS:   <pre><code>./bin/fabric-cli interop --local-network=network1 --sign=true --requesting-org=Org1MSP --relay-tls=true --relay-tls-ca-files=../../../core/relay/credentials/docker/ca-cert.pem relay-corda:9081/Corda_Network/corda_partya_1:10003#com.cordaSimpleApplication.flow.GetStateByKey:H --debug=true\n</code></pre></li> </ul> </li> </ul> </li> <li> <p>Query the value of the requested state (key) <code>H</code> in <code>network1</code> using the following:   <pre><code>./bin/fabric-cli chaincode query mychannel simplestate read '[\"H\"]' --local-network=network1\n</code></pre></p> </li> </ul> <p>To test the scenario where <code>network2</code> requests the value of the state (key) <code>H</code> from <code>Corda_Network</code> and writes the value to a key <code>H</code> in its local state, do the following:</p> <ul> <li>(Make sure the following are running: Corda network, relay, and driver; Fabric <code>network2</code>, relay, and driver)</li> <li>Navigate to the <code>weaver/samples/fabric/fabric-cli</code> (for the Node.js version) or the <code>weaver/samples/fabric/go-cli</code> (for the Golang version) folder in your clone of the Cacti repository.</li> <li>(Make sure you have configured <code>fabric-cli</code> as per earlier instructions)</li> <li>Edit <code>chaincode.json</code>: in the <code>simplestate:Create:args</code> attribute, replace the argument <code>\"a\"</code> with <code>\"H\"</code> (this specifies the key to which the data from the remote view is to be written into); i.e.,:   <pre><code>\"args\": [\"a\", \"\"]\n</code></pre>   with   <pre><code>\"args\": [\"H\", \"\"]\n</code></pre></li> <li> <p>Run the following:</p> <ul> <li>If Relays and Drivers are deployed in the host machine:<ul> <li>Without TLS:   <pre><code>./bin/fabric-cli interop --local-network=network2 --sign=true --requesting-org=Org1MSP localhost:9081/Corda_Network/localhost:10006#com.cordaSimpleApplication.flow.GetStateByKey:H --debug=true\n</code></pre></li> <li>With TLS:   <pre><code>./bin/fabric-cli interop --local-network=network2 --sign=true --requesting-org=Org1MSP --relay-tls=true --relay-tls-ca-files=../../../core/relay/credentials/fabric_ca_cert.pem localhost:9081/Corda_Network/localhost:10006#com.cordaSimpleApplication.flow.GetStateByKey:H --debug=true\n</code></pre></li> </ul> </li> <li>If Relays and Drivers are deployed in Docker containers:<ul> <li>Without TLS:   <pre><code>./bin/fabric-cli interop --local-network=network2 --sign=true --requesting-org=Org1MSP relay-corda:9081/Corda_Network/corda_partya_1:10003#com.cordaSimpleApplication.flow.GetStateByKey:H --debug=true\n</code></pre></li> <li>With TLS:   <pre><code>./bin/fabric-cli interop --local-network=network2 --sign=true --requesting-org=Org1MSP --relay-tls=true --relay-tls-ca-files=../../../core/relay/credentials/docker/ca-cert.pem relay-corda:9081/Corda_Network/corda_partya_1:10003#com.cordaSimpleApplication.flow.GetStateByKey:H --debug=true\n</code></pre></li> </ul> </li> </ul> </li> <li> <p>Query the value of the requested state (key) <code>H</code> in <code>network2</code> using the following:   <pre><code>./bin/fabric-cli chaincode query mychannel simplestate read '[\"H\"]' --local-network=network2\n</code></pre></p> </li> </ul> Notes You can test the above data transfer scenario with <code>Corda_Network2</code> instead of <code>Corda_Network</code> by changing the following in the view address (last parameter in the <code>interop</code> command):<ul><li>Local relay address (prefix):<ul><li><code>localhost:9081</code> to <code>localhost:9082</code> (host deployment of relays and drivers)</li><li><code>relay-corda2:9081</code> to <code>relay-corda2:9082</code> (Docker container deployment of relays and drivers)</li></ul></li><li>Network name:<ul><li><code>Corda_Network</code> to <code>Corda_Network2</code></li></ul></li><li>Corda node's RPC endpoint:<ul><li><code>localhost:10006</code> to <code>localhost:30006</code> (host deployment of relays and drivers)</li><li><code>corda_partya_1:10003</code> to <code>corda_network2_partya_1:10003</code> (Docker container deployment of relays and drivers)</li></ul></li></ul>"},{"location":"weaver/getting-started/interop/data-sharing/#fabric-to-fabric","title":"Fabric to Fabric","text":"<p>To test the scenario where <code>network1</code> requests the value of the state (key) <code>Arcturus</code> from <code>network2</code> and writes the value to a key <code>Arcturus</code> in its local state, do the following:</p> <ul> <li>(Make sure the following are running: Fabric <code>network1</code>, relay, and driver; Fabric <code>network2</code>, relay, and driver)</li> <li>Navigate to the <code>weaver/samples/fabric/fabric-cli</code> (for the Node.js version) or the <code>weaver/samples/fabric/go-cli</code> (for the Golang version) folder in your clone of the Cacti repository.</li> <li>(Make sure you have configured <code>fabric-cli</code> as per earlier instructions)</li> <li>Edit <code>chaincode.json</code>: in the <code>simplestate:Create:args</code> attribute, replace the argument <code>\"a\"</code> with <code>\"Arcturus\"</code> (this specifies the key to which the data from the remote view is to be written into); i.e.,:   <pre><code>\"args\": [\"a\", \"\"]\n</code></pre>   with   <pre><code>\"args\": [\"Arcturus\", \"\"]\n</code></pre></li> <li>Run the following:<ul> <li>If Relays and Drivers are deployed in the host machine:<ul> <li>Without TLS:   <pre><code>./bin/fabric-cli interop --local-network=network1 --requesting-org=Org1MSP localhost:9083/network2/mychannel:simplestate:Read:Arcturus\n</code></pre></li> <li>With TLS:   <pre><code>./bin/fabric-cli interop --local-network=network1 --requesting-org=Org1MSP --relay-tls=true --relay-tls-ca-files=../../../core/relay/credentials/fabric_ca_cert.pem localhost:9083/network2/mychannel:simplestate:Read:Arcturus\n</code></pre></li> </ul> </li> <li>If Relays and Drivers are deployed in Docker containers:<ul> <li>Without TLS:   <pre><code>./bin/fabric-cli interop --local-network=network1 --requesting-org=Org1MSP relay-network2:9083/network2/mychannel:simplestate:Read:Arcturus\n</code></pre></li> <li>With TLS:   <pre><code>./bin/fabric-cli interop --local-network=network1 --requesting-org=Org1MSP --relay-tls=true --relay-tls-ca-files=../../../core/relay/credentials/docker/ca-cert.pem relay-network2:9083/network2/mychannel:simplestate:Read:Arcturus\n</code></pre></li> </ul> </li> </ul> </li> </ul> Notes If you wish to enable end-to-end confidentiality for this data sharing session, add the <code>--e2e-confidentiality=true</code> switch to any of the above commands. For example: <code>./bin/fabric-cli interop --local-network=network1 --requesting-org=Org1MSP --e2e-confidentiality=true localhost:9083/network2/mychannel:simplestate:Read:Arcturus</code> <ul> <li>Query the value of the requested state (key) <code>Arcturus</code> in <code>network1</code> using the following:   <pre><code>./bin/fabric-cli chaincode query mychannel simplestate read '[\"Arcturus\"]' --local-network=network1\n</code></pre></li> </ul> <p>To test the scenario where <code>network2</code> requests the value of the state (key) <code>a</code> from <code>network1</code> and writes the value to a key <code>a</code> in its local state, do the following:</p> <ul> <li>(Make sure the following are running: Fabric <code>network1</code>, relay, and driver; Fabric <code>network2</code>, relay, and driver)</li> <li>Navigate to the <code>weaver/samples/fabric/fabric-cli</code> (for the Node.js version) or the <code>weaver/samples/fabric/go-cli</code> (for the Golang version) folder in your clone of the Cacti repository.</li> <li>(Make sure you have configured <code>fabric-cli</code> as per earlier instructions)</li> <li>(There is no need to edit <code>chaincode.json</code> to change the key as the default argument <code>\"a\"</code> is what we intend to use in this data sharing use scenario.)</li> <li>Run the following:<ul> <li>If Relays and Drivers are deployed in the host machine:<ul> <li>Without TLS:   <pre><code>./bin/fabric-cli interop --local-network=network2 --requesting-org=Org1MSP localhost:9080/network1/mychannel:simplestate:Read:a\n</code></pre></li> <li>With TLS:   <pre><code>./bin/fabric-cli interop --local-network=network2 --requesting-org=Org1MSP --relay-tls=true --relay-tls-ca-files=../../../core/relay/credentials/fabric_ca_cert.pem localhost:9080/network1/mychannel:simplestate:Read:a\n</code></pre></li> </ul> </li> <li>If Relays and Drivers are deployed in Docker containers:<ul> <li>Without TLS:   <pre><code>./bin/fabric-cli interop --local-network=network2 --requesting-org=Org1MSP relay-network1:9080/network1/mychannel:simplestate:Read:a\n</code></pre></li> <li>With TLS:   <pre><code>./bin/fabric-cli interop --local-network=network2 --requesting-org=Org1MSP --relay-tls=true --relay-tls-ca-files=../../../core/relay/credentials/docker/ca-cert.pem relay-network1:9080/network1/mychannel:simplestate:Read:a:173\n</code></pre></li> </ul> </li> </ul> </li> </ul> Notes If you wish to enable end-to-end confidentiality for this data sharing session, add the <code>--e2e-confidentiality=true</code> switch to any of the above commands. For example: <code>./bin/fabric-cli interop --local-network=network2 --requesting-org=Org1MSP --e2e-confidentiality=true localhost:9080/network1/mychannel:simplestate:Read:a</code> <ul> <li>Query the value of the requested state (key) <code>a</code> in <code>network2</code> using the following:   <pre><code>./bin/fabric-cli chaincode query mychannel simplestate read '[\"a\"]' --local-network=network2\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/interop/overview/","title":"Testing Interoperation Modes Overview","text":"<p>To test any of the interoperability modes supported by Weaver in test networks that have already been launched and bootstrapped, follow the appropriate link below.</p> <ul> <li>Data Sharing</li> <li>Asset Exchange</li> <li>Asset Transfer</li> </ul>"},{"location":"weaver/getting-started/interop/asset-exchange/besu-besu/","title":"Asset Exchange: Besu with Besu","text":"<p>We divide this page into two sections, if you used default configuration in ledger initialization step, then go to section AliceERC721 with BobERC20, otherwise if you used hybrid tokens in <code>network</code>, then go to section AliceERC1155 with BobERC20</p> Notes The hash used in following steps can be replaced by any valid <code>SHA256</code> hash."},{"location":"weaver/getting-started/interop/asset-exchange/besu-besu/#aliceerc721-with-boberc20","title":"AliceERC721 with BobERC20","text":"<p>One Besu network transfers an non-fungible <code>AliceERC721</code> token with id <code>0</code> from Alice to Bob in exchange for a transfer of <code>10 BobERC20</code> tokens from Bob to Alice in the other network. We will use account <code>1</code> for Alice and account <code>2</code> for Bob in both networks.</p> <p>Run the following steps:</p> <ol> <li>Navigate to the <code>weaver/samples/besu/besu-cli</code> folder in your clone of the Cacti repository.</li> <li>Run the following to verify the status of the assets owned by <code>alice</code> and <code>bob</code> in the two networks:    <pre><code>./bin/besu-cli asset get-balance --network=network1 --account=1\n./bin/besu-cli asset get-balance --network=network1 --account=2\n./bin/besu-cli asset get-balance --network=network2 --account=1\n./bin/besu-cli asset get-balance --network=network2 --account=2\n</code></pre></li> <li>Generate Secret-Hash Pair using following command (prints hash in base64):   <pre><code>./bin/besu-cli hash --hash_fn=SHA256 secrettext\n</code></pre></li> <li>Run the following to trigger <code>alice</code> locking <code>AliceERC721</code> token with id <code>0</code> for <code>bob</code> in <code>network1</code> for 1 hour   <pre><code>./bin/besu-cli asset lock --network=network1 --sender_account=1 --recipient_account=2 --token_id=0 --asset_type=ERC721 --timeout=3600 --hash_base64=ivHErp1x4bJDKuRo6L5bApO/DdoyD/dG0mAZrzLZEIs=\n</code></pre>   Value set to <code>hash_base64</code> argument corresponds to what was generated in Step 3. Note the <code>contract-id</code> printed as output in above command. The output line containing <code>contract-id</code> (text in base64 after <code>Lock contract ID:</code>) would like this:   <pre><code>Lock contract ID: 48f59da2ac632117bf79b4aa986f5ece8a2439dc143d576965c17bc8275b0925\n</code></pre></li> <li>Run the following to verify <code>alice</code>'s lock, replacing <code>&lt;contract-id&gt;</code> with actual <code>contract-id</code>:  <pre><code>./bin/besu-cli asset is-locked --network=network1 --lock_contract_id=&lt;contract-id&gt;\n</code></pre></li> <li>Run the following to trigger <code>bob</code> locking <code>10</code> units of <code>BobERC20</code> tokens for <code>alice</code> in <code>network2</code> for 30 mins:  <pre><code>./bin/besu-cli asset lock --network=network2 --sender_account=2 --recipient_account=1 --amount=10 --timeout=1800 --hash_base64=ivHErp1x4bJDKuRo6L5bApO/DdoyD/dG0mAZrzLZEIs=\n</code></pre>  Note the <code>contract-id</code> again for this lock printed as output in above command. Let's refer it <code>&lt;contract-id-2&gt;</code> for this demonstration.</li> <li>Run the following to verify <code>bob</code>'s lock:  <pre><code>./bin/besu-cli asset is-locked --network=network2 --lock_contract_id=&lt;contract-id-2&gt;\n</code></pre></li> <li>Run the following to trigger <code>alice</code>'s claim for <code>10</code> units of <code>BobERC20</code> tokens locked by <code>bob</code> in <code>network2</code>:  <pre><code>./bin/besu-cli asset claim --network=network2 --recipient_account=1 --preimage=secrettext --lock_contract_id=&lt;contract-id-2&gt;\n</code></pre></li> <li>Run the following to trigger <code>bob</code>'s claim for <code>AliceERC721</code> NFT with id <code>0</code> locked by <code>alice</code> in <code>network1</code>:  <pre><code>./bin/besu-cli asset claim --network=network1 --recipient_account=2 --preimage=secrettext --token_id=0 --lock_contract_id=&lt;contract-id&gt;\n</code></pre></li> </ol> <p>The above steps complete a successful asset exchange between two Besu networks.  In addition to the above commands, following commands can be run if specified timeout has expired and the locked asset remains unclaimed.</p> <ul> <li> <p>If <code>alice</code> wants to unlock the asset, run the following to trigger <code>alice</code>'s re-claim for <code>AliceERC721</code> NFT with id <code>0</code> locked in <code>network1</code>:  <pre><code>./bin/besu-cli asset unlock --network=network1 --lock_contract_id=&lt;contract-id&gt; --sender_account=1 --token_id=0\n</code></pre></p> </li> <li> <p>If <code>bob</code> wants to unlock the token asset, run the following to trigger <code>bob</code>'s re-claim for <code>10 BobERC20</code> tokens locked in <code>network2</code>:  <pre><code>./bin/besu-cli asset unlock --network=network2 --lock_contract_id=&lt;contract-id-2&gt; --sender_account=2\n</code></pre></p> </li> </ul>"},{"location":"weaver/getting-started/interop/asset-exchange/besu-besu/#aliceerc1155-with-boberc20","title":"AliceERC1155 with BobERC20","text":"<p>One Besu network transfers an non-fungible <code>5 AliceERC1155</code> tokens with id <code>0</code> from Alice to Bob in exchange for a transfer of <code>50 BobERC20</code> tokens from Bob to Alice in the other network. We will use account <code>1</code> for Alice and account <code>2</code> for Bob in both networks.</p> <p>Run the following steps:</p> <ol> <li>Navigate to the <code>weaver/samples/besu/besu-cli</code> folder in your clone of the Cacti repository.</li> <li>Run the following to verify the status of the assets owned by <code>alice</code> and <code>bob</code> in the two networks:    <pre><code>./bin/besu-cli asset get-balance --network=network1 --account=1\n./bin/besu-cli asset get-balance --network=network1 --account=2\n./bin/besu-cli asset get-balance --network=network2 --account=1\n./bin/besu-cli asset get-balance --network=network2 --account=2\n</code></pre></li> <li>Generate Secret-Hash Pair using following command (prints hash in base64):   <pre><code>./bin/besu-cli hash --hash_fn=SHA256 secrettext\n</code></pre></li> <li>Run the following to trigger <code>alice</code> locking <code>5 AliceERC1155</code> token with id <code>0</code> for <code>bob</code> in <code>network1</code> for 1 hour   <pre><code>./bin/besu-cli asset lock --network=network1 --sender_account=1 --recipient_account=2 --amount=5 --token_id=0 --asset_type=ERC1155 --timeout=3600 --hash_base64=ivHErp1x4bJDKuRo6L5bApO/DdoyD/dG0mAZrzLZEIs=\n</code></pre>   Value set to <code>hash_base64</code> argument corresponds to what was generated in Step 3. Note the <code>contract-id</code> printed as output in above command. The output line containing <code>contract-id</code> (text in base64 after <code>Lock contract ID:</code>) would like this:   <pre><code>Lock contract ID: 48f59da2ac632117bf79b4aa986f5ece8a2439dc143d576965c17bc8275b0925\n</code></pre></li> <li>Run the following to verify <code>alice</code>'s lock, replacing <code>&lt;contract-id&gt;</code> with actual <code>contract-id</code>:  <pre><code>./bin/besu-cli asset is-locked --network=network1 --lock_contract_id=&lt;contract-id&gt;\n</code></pre></li> <li>Run the following to trigger <code>bob</code> locking <code>50</code> units of <code>BobERC20</code> tokens for <code>alice</code> in <code>network2</code>:  <pre><code>./bin/besu-cli asset lock --network=network2 --sender_account=2 --recipient_account=1 --amount=50 --timeout=3600 --hash_base64=ivHErp1x4bJDKuRo6L5bApO/DdoyD/dG0mAZrzLZEIs=\n</code></pre>  Note the <code>contract-id</code> again for this lock printed as output in above command. Let's refer it <code>&lt;contract-id-2&gt;</code> for this demonstration.</li> <li>Run the following to verify <code>bob</code>'s lock:  <pre><code>./bin/besu-cli asset is-locked --network=network2 --lock_contract_id=&lt;contract-id-2&gt;\n</code></pre></li> <li>Run the following to trigger <code>alice</code>'s claim for <code>50</code> units of <code>BobERC20</code> tokens locked by <code>bob</code> in <code>network2</code>:  <pre><code>./bin/besu-cli asset claim --network=network2 --recipient_account=1 --preimage=secrettext --lock_contract_id=&lt;contract-id-2&gt;\n</code></pre></li> <li>Run the following to trigger <code>bob</code>'s claim for <code>5 AliceERC1155</code> tokens with id <code>0</code> locked by <code>alice</code> in <code>network1</code>:  <pre><code>./bin/besu-cli asset claim --network=network1 --recipient_account=2 --preimage=secrettext --token_id=0 --lock_contract_id=&lt;contract-id&gt;\n</code></pre></li> </ol> <p>The above steps complete a successful asset exchange between two Besu networks.  In addition to the above commands, following commands can be run if specified timeout has expired and the locked asset remains unclaimed.</p> <ul> <li> <p>If <code>alice</code> wants to unlock the asset, run the following to trigger <code>alice</code>'s re-claim for <code>5 AliceERC1155</code> tokens with id <code>0</code> locked in <code>network1</code>:  <pre><code>./bin/besu-cli asset unlock --network=network1 --lock_contract_id=&lt;contract-id&gt; --sender_account=1 --token_id=0\n</code></pre></p> </li> <li> <p>If <code>bob</code> wants to unlock the token asset, run the following to trigger <code>bob</code>'s re-claim for <code>50 BobERC20</code> tokens locked in <code>network2</code>:  <pre><code>./bin/besu-cli asset unlock --network=network2 --lock_contract_id=&lt;contract-id-2&gt; --sender_account=2\n</code></pre></p> </li> </ul> <p>Run the following to verify the status of the assets owned by <code>alice</code> and <code>bob</code> in the two networks: <pre><code>./bin/besu-cli asset get-balance --network=network1 --account=1\n./bin/besu-cli asset get-balance --network=network1 --account=2\n./bin/besu-cli asset get-balance --network=network2 --account=1\n./bin/besu-cli asset get-balance --network=network2 --account=2\n</code></pre></p>"},{"location":"weaver/getting-started/interop/asset-exchange/corda-besu/","title":"Asset Exchange: Corda with Besu","text":"<p>We will demonstrate asset exchange of an <code>AliceERC721</code> NFT in Besu <code>network1</code> with <code>10</code> tokens on <code>Corda_Network</code>. For Besu commands, run from <code>weaver/weaver/samples/besu/besu-cli</code> folder, and for Corda commands, run from <code>samples/corda/corda-simple-application</code> folder, in your clone of the Cacti repository. Here <code>Alice</code> with account <code>1</code> and <code>Bob</code> with account <code>2</code> in Besu <code>network1</code> correspond to <code>PartyA</code> (<code>CORDA_PORT=10006</code>) and <code>PartyB</code> (<code>CORDA_PORT=10009</code>) in <code>Corda_Network</code> respectively. Following are the step-by-step asset exchange process:</p> <ol> <li>From corda client, generate secret-hash pair using following command (prints hash in base64):   <pre><code>./clients/build/install/clients/bin/clients utils hash --hash-fn=SHA256 -s secrettext\n</code></pre></li> <li>Run the following to verify the status of the tokens owned by <code>PartyA</code> and <code>PartyB</code> in the <code>Corda_Network</code> and <code>Corda_Network2</code>:   <pre><code>./scripts/getAssetStatus.sh 2\n</code></pre></li> <li>Run the following in <code>besu-cli</code>, to verify the status of the assets owned by <code>Alice</code> and <code>Bob</code> in the Besu networks:   <pre><code>./bin/besu-cli asset get-balance --network=network1 --account=1\n./bin/besu-cli asset get-balance --network=network1 --account=2\n</code></pre></li> <li> <p>Complete the asset exchange using following steps:</p> <ul> <li>Run the following to trigger <code>alice</code> locking <code>AliceERC721</code> token with id <code>0</code> for <code>bob</code> in <code>network1</code> for 1 hour   <pre><code>./bin/besu-cli asset lock --network=network1 --sender_account=1 --recipient_account=2 --token_id=0 --asset_type=ERC721 --timeout=3600 --hash_base64=ivHErp1x4bJDKuRo6L5bApO/DdoyD/dG0mAZrzLZEIs=\n</code></pre>   Note the <code>contract-id</code> printed as output in above command. The output line containing <code>contract-id</code> (text in base64 after <code>Lock contract ID:</code>) would like this:   <pre><code>Lock contract ID: 48f59da2ac632117bf79b4aa986f5ece8a2439dc143d576965c17bc8275b0925\n</code></pre></li> <li>Run the following to verify <code>alice</code>'s lock, replacing <code>&lt;contract-id&gt;</code> with actual <code>contract-id</code>:   <pre><code>./bin/besu-cli asset is-locked --network=network1 --lock_contract_id=&lt;contract-id&gt;\n</code></pre></li> <li>Run the following to trigger <code>PartyB</code> locking <code>50</code> units of token type <code>t1</code> for <code>PartyA</code> in <code>Corda_Network</code> for 30 mins:   <pre><code>CORDA_PORT=10009 ./clients/build/install/clients/bin/clients lock-asset --fungible --hashBase64=ivHErp1x4bJDKuRo6L5bApO/DdoyD/dG0mAZrzLZEIs= --timeout=1800 --recipient=\"O=PartyA,L=London,C=GB\" --param=t1:50\n</code></pre>   Note the <code>contract-id</code> displayed after successful execution of the command, will be used in next steps. The output containing <code>contract-id</code> would like this:   <pre><code>HTLC Lock State created with contract ID Right(b=10448674_80d2bee7-5a5d-45df-b14e-60bac4ba1bf3).\n</code></pre> <code>contract-id</code> is the alphanumeric text (with underscore and hyphens) after <code>b=</code> within parenthesis. Let's refer it <code>&lt;contract-id-2&gt;</code> for this demonstration.</li> <li>Run the following to verify <code>PartyB</code>'s lock (can be verified by both parties):   <pre><code>CORDA_PORT=10006 ./clients/build/install/clients/bin/clients is-asset-locked --contract-id=&lt;contract-id-2&gt;\n</code></pre></li> <li>Run the following to trigger <code>PartyA</code>'s claim for <code>50</code> units of token type <code>t1</code> locked by <code>PartyB</code> in <code>Corda_Network</code>:   <pre><code>CORDA_PORT=10006 ./clients/build/install/clients/bin/clients claim-asset --secret=secrettext --contract-id=&lt;contract-id-2&gt;\n</code></pre> <code>PartyB</code> can see its node's logs to get the revealed hash preimage, and use it to claim in the Besu network.</li> <li>Run the following to trigger <code>bob</code>'s claim for <code>AliceERC721</code> NFT with id <code>0</code> locked by <code>alice</code> in <code>network1</code>:   <pre><code>./bin/besu-cli asset claim --network=network1 --recipient_account=2 --preimage=secrettext --token_id=0 --lock_contract_id=&lt;contract-id&gt;\n</code></pre></li> </ul> <p>The above steps complete a successful asset exchange between two Besu networks.  In addition to the above commands, following commands can be run if specified timeout has expired and the locked asset remains unclaimed. - If <code>alice</code> wants to unlock the asset, run the following to trigger <code>alice</code>'s re-claim for <code>AliceERC721</code> NFT with id <code>0</code> locked in <code>network1</code>:   <pre><code>./bin/besu-cli asset unlock --network=network1 --lock_contract_id=&lt;contract-id&gt; --sender_account=1 --token_id=0\n</code></pre> - If <code>PartyB</code> wants to unlock the token asset, run the following to trigger unlock for <code>t1:50</code> locked in <code>Corda_Network</code>:   <pre><code>CORDA_PORT=10009 ./clients/build/install/clients/bin/clients unlock-asset --contract-id=&lt;contract-id&gt;\n</code></pre> 5. Run the following to verify the status of the tokens owned by <code>PartyA</code> and <code>PartyB</code> in the <code>Corda_Network</code> and <code>Corda_Network2</code>:   <pre><code>./scripts/getAssetStatus.sh 2\n</code></pre> 6. Run the following in <code>besu-cli</code>, to verify the status of the assets owned by <code>Alice</code> and <code>Bob</code> in the Besu networks:   <pre><code>./bin/besu-cli asset get-balance --network=network1 --account=1\n./bin/besu-cli asset get-balance --network=network1 --account=2\n</code></pre></p> </li> </ol>"},{"location":"weaver/getting-started/interop/asset-exchange/corda-corda/","title":"Asset Exchange: Corda with Corda","text":"<p>We will demonstrate asset exchange of a tokens in <code>Corda_Network</code> with tokens on <code>Corda_Network2</code>. Here <code>PartyA</code> (<code>CORDA_PORT=10006</code>) and <code>PartyB</code> (<code>CORDA_PORT=10009</code>) in <code>Corda_Network</code> correspond to <code>PartyA</code> (<code>CORDA_PORT=30006</code>) and <code>PartyB</code> (<code>CORDA_PORT=30009</code>) in <code>Corda_Network2</code> respectively. Following are the step-by-step asset exchange process:</p> Notes The hash used in following steps can be replaced by any valid <code>SHA256</code> hash. <ul> <li>Navigate to the <code>weaver/samples/corda/corda-simple-application</code> folder in your clone of the Cacti repository.</li> <li>Run the following to verify the status of the tokens owned by <code>PartyA</code> and <code>PartyB</code> in the <code>Corda_Network</code> and <code>Corda_Network2</code>:   <pre><code>./scripts/getAssetStatus.sh 2\n</code></pre></li> <li>Generate Secret-Hash Pair using following command (prints hash in base64):   <pre><code>./clients/build/install/clients/bin/clients utils hash --hash-fn=SHA256 -s secrettext\n</code></pre></li> <li>Run the following to trigger <code>PartyA</code> locking <code>30</code> units of token type <code>t1</code> for <code>PartyB</code> in <code>Corda_Network</code> for 60 mins:   <pre><code>CORDA_PORT=10006 ./clients/build/install/clients/bin/clients lock-asset --fungible --hashBase64=ivHErp1x4bJDKuRo6L5bApO/DdoyD/dG0mAZrzLZEIs= --timeout=3600 --recipient=\"O=PartyB,L=London,C=GB\" --param=t1:30\n</code></pre>   Note the <code>contract-id</code> displayed after successful execution of the command, will be used in next steps. The output containing <code>contract-id</code> would like this:   <pre><code>HTLC Lock State created with contract ID Right(b=10448674_80d2bee7-5a5d-45df-b14e-60bac4ba1bf3).\n</code></pre> <code>contract-id</code> is the alphanumeric text (with underscore and hyphens) after <code>b=</code> within parenthesis. Let's denote it <code>&lt;contract-id-1&gt;</code>.</li> <li>Run the following to verify <code>PartyA</code>'s lock (can be verified by both parties):   <pre><code>CORDA_PORT=10009 ./clients/build/install/clients/bin/clients is-asset-locked --contract-id=&lt;contract-id-1&gt;\n</code></pre></li> <li>Run the following to trigger <code>PartyB</code> locking <code>50</code> units of token type <code>t2</code> for <code>PartyA</code> in <code>Corda_Network2</code> for 30 mins:   <pre><code>CORDA_PORT=30009 ./clients/build/install/clients/bin/clients lock-asset --fungible --hashBase64=ivHErp1x4bJDKuRo6L5bApO/DdoyD/dG0mAZrzLZEIs= --timeout=1800 --recipient=\"O=PartyA,L=London,C=GB\" --param=t2:50\n</code></pre>   Note the <code>contract-id</code> displayed after successful execution of the command, will be used in next steps. Let's denote it <code>&lt;contract-id-2&gt;</code>.</li> <li>Run the following to verify <code>PartyB</code>'s lock (can be verified by both parties):   <pre><code>CORDA_PORT=30006 ./clients/build/install/clients/bin/clients is-asset-locked --contract-id=&lt;contract-id-2&gt;\n</code></pre></li> <li>Run the following to trigger <code>PartyA</code>'s claim for <code>50</code> units of token type <code>t2</code> locked by <code>PartyB</code> in <code>Corda_Network2</code>:   <pre><code>CORDA_PORT=30006 ./clients/build/install/clients/bin/clients claim-asset --secret=secrettext --contract-id=&lt;contract-id-2&gt;\n</code></pre> <code>PartyB</code> can see its node's logs to get the revealed hash preimage, and use it to claim the bond in the Fabric network.</li> <li>Run the following to trigger <code>PartyB</code>'s claim for <code>30</code> units of token type <code>t1</code> locked by <code>PartyA</code> in <code>Corda_Network</code>:   <pre><code>CORDA_PORT=10009 ./clients/build/install/clients/bin/clients claim-asset --secret=secrettext --contract-id=&lt;contract-id-1&gt;\n</code></pre></li> <li>Run the following to verify the status of the tokens owned by <code>PartyA</code> and <code>PartyB</code> in the <code>Corda_Network</code> and <code>Corda_Network2</code>:   <pre><code>./scripts/getAssetStatus.sh 2\n</code></pre></li> </ul> <p>The above steps complete a successful asset exchange between two Corda networks.  In addition to the above commands, following commands can be run if specified timeout has expired and the locked asset remains unclaimed.</p> <ul> <li>If <code>PartyA</code> wants to unlock the token <code>t1:30</code> asset, run the following to trigger <code>PartyA</code>'s re-claim in <code>Corda_Network</code>:   <pre><code>CORDA_PORT=10006 ./clients/build/install/clients/bin/clients unlock-asset --contract-id=&lt;contract-id-1&gt;\n</code></pre></li> <li>If <code>PartyB</code> wants to unlock the token <code>t2:50</code> asset, run the following to trigger <code>PartyB</code>'s re-claim in <code>Corda_Network2</code>:   <pre><code>CORDA_PORT=30009 ./clients/build/install/clients/bin/clients unlock-asset --contract-id=&lt;contract-id-2&gt;\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/interop/asset-exchange/fabric-besu/","title":"Asset Exchange: Fabric with Besu","text":"<p>We will demonstrate asset exchange of a bond in Fabric <code>network1</code> with <code>10 BobERC20</code> tokens on Besu <code>network2</code>. For Fabric commands, run from <code>weaver/samples/fabric/fabric-cli</code> folder, and for Besu commands, run from <code>weaver/samples/besu/besu-cli</code> folder, in your clone of the Cacti repository. Here <code>Alice</code> and <code>Bob</code> in Fabric <code>network1</code> correspond to account <code>1</code> and account <code>2</code> in Besu <code>network2</code> respectively. Following are the step-by-step asset exchange process:</p> Notes The hash used in following steps can be replaced by any valid <code>SHA256</code> hash. <ul> <li>From <code>fabric-cli</code>, generate secret-hash pair using following command (prints hash in base64):   <pre><code>./bin/fabric-cli hash --hash_fn=SHA256 secrettext\n</code></pre></li> <li>Run the following to verify the status of the bond assets owned by <code>alice</code> and <code>bob</code> in the Fabric network <code>network1</code> from <code>weaver/samples/fabric/fabric-cli</code> folder:  <pre><code>./scripts/getAssetStatus.sh\n</code></pre></li> <li>Run the following in <code>besu-cli</code>, to verify the status of the assets owned by <code>Alice</code> and <code>Bob</code> in the Besu network <code>network2</code>:   <pre><code>./bin/besu-cli asset get-balance --network=network2 --account=1\n./bin/besu-cli asset get-balance --network=network2 --account=2\n</code></pre></li> <li>Run the following to trigger <code>alice</code> locking <code>bond01:a03</code> for <code>bob</code> in <code>network1</code> for 60 mins:   <pre><code>./bin/fabric-cli asset exchange lock --timeout-duration=3600 --locker=alice --recipient=bob --hashBase64=ivHErp1x4bJDKuRo6L5bApO/DdoyD/dG0mAZrzLZEIs= --target-network=network1 --param=bond01:a03\n</code></pre></li> <li>Run the following to verify <code>alice</code>'s lock:   <pre><code>./bin/fabric-cli asset exchange is-locked --locker=alice --recipient=bob --target-network=network1 --param=bond01:a03\n</code></pre></li> <li> <p>Run the following to trigger <code>bob</code> locking <code>10</code> units of <code>BobERC20</code> tokens for <code>alice</code> in <code>network2</code> for 30 mins:   <pre><code>./bin/besu-cli asset lock --network=network2 --sender_account=2 --recipient_account=1 --amount=10 --timeout=1800 --hash_base64=ivHErp1x4bJDKuRo6L5bApO/DdoyD/dG0mAZrzLZEIs=\n</code></pre>   Note the <code>contract-id</code> printed as output in above command. The output line containing <code>contract-id</code> (text in base64 after <code>Lock contract ID:</code>) would like this:   <pre><code>Lock contract ID: 48f59da2ac632117bf79b4aa986f5ece8a2439dc143d576965c17bc8275b0925\n</code></pre>   Let's refer it <code>&lt;contract-id-2&gt;</code> for this demonstration.</p> </li> <li> <p>Run the following to verify <code>bob</code>'s lock:   <pre><code>./bin/besu-cli asset is-locked --network=network2 --lock_contract_id=&lt;contract-id-2&gt;\n</code></pre></p> </li> <li>Run the following to trigger <code>alice</code>'s claim for <code>10</code> units of <code>BobERC20</code> tokens locked by <code>bob</code> in <code>network2</code>:   <pre><code>./bin/besu-cli asset claim --network=network2 --recipient_account=1 --preimage=secrettext --lock_contract_id=&lt;contract-id-2&gt;\n</code></pre></li> <li>Run the following to trigger <code>bob</code>'s claim for <code>bond01:a03</code> locked by <code>alice</code> in <code>network1</code>:   <pre><code>./bin/fabric-cli asset exchange claim --recipient=bob --locker=alice --target-network=network1 --param=bond01:a03 --secret=secrettext\n</code></pre></li> <li>Run the following to verify the status of the bond assets owned by <code>alice</code> and <code>bob</code> in the Fabric network <code>network1</code> from <code>weaver/samples/fabric/fabric-cli</code> folder:    <pre><code>./scripts/getAssetStatus.sh\n</code></pre></li> <li>Run the following in <code>besu-cli</code>, to verify the status of the assets owned by <code>Alice</code> and <code>Bob</code> in the Besu network <code>network2</code>:   <pre><code>./bin/besu-cli asset get-balance --network=network2 --account=1\n./bin/besu-cli asset get-balance --network=network2 --account=2\n</code></pre></li> </ul> <p>The above steps complete a successful asset exchange between Fabric and Corda networks.  In addition to the above commands, following commands can be run if specified timeout has expired and the locked asset remains unclaimed.</p> <ul> <li>If <code>alice</code> wants to unlock the bond asset, run the following to trigger <code>alice</code>'s re-claim for <code>bond01:a03</code> locked in <code>network1</code>:   <pre><code>./bin/fabric-cli asset exchange unlock --locker=alice --recipient=bob --target-network=network1 --param=bond01:a03\n</code></pre></li> <li>If <code>bob</code> wants to unlock the token asset, run the following to trigger <code>bob</code>'s re-claim for <code>50 BobERC20</code> tokens locked in <code>network2</code>:   <pre><code>./bin/besu-cli asset unlock --network=network2 --lock_contract_id=&lt;contract-id-2&gt; --sender_account=2\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/interop/asset-exchange/fabric-corda/","title":"Asset Exchange: Fabric with Corda","text":"<p>We will demonstrate asset exchange of a bond in Fabric <code>network1</code> with tokens on <code>Corda_Network</code>. For Fabric commands, run from <code>weaver/samples/fabric/fabric-cli</code> folder, and for Corda commands, run from <code>weaver/samples/corda/corda-simple-application</code> folder, in your clone of the Cacti repository. Here <code>Alice</code> and <code>Bob</code> in Fabric <code>network1</code> correspond to <code>PartyA</code> (<code>CORDA_PORT=10006</code>) and <code>PartyB</code> (<code>CORDA_PORT=10009</code>) in <code>Corda_Network</code> respectively. Following are the step-by-step asset exchange process:</p> Notes The hash used in following steps can be replaced by any valid <code>SHA256</code> hash. <ul> <li>Run the following to verify the status of the bond assets owned by <code>alice</code> and <code>bob</code> in the Fabric network <code>network1</code> from <code>weaver/samples/fabric/fabric-cli</code> folder:  <pre><code>./scripts/getAssetStatus.sh\n</code></pre></li> <li>Run the following to verify the status of the assets owned by <code>PartyA</code> and <code>PartyB</code> in the <code>Corda_Network</code> from <code>weaver/samples/corda/corda-simple-application</code> folder:   <pre><code>./scripts/getAssetStatus.sh\n</code></pre></li> <li>Generate Secret-Hash Pair using following command (prints hash in base64):   <pre><code>./bin/fabric-cli hash --hash_fn=SHA256 secrettext\n</code></pre></li> <li>Run the following to trigger <code>alice</code> locking <code>bond01:a03</code> for <code>bob</code> in <code>network1</code> for 60 mins:   <pre><code>./bin/fabric-cli asset exchange lock --timeout-duration=3600 --locker=alice --recipient=bob --hashBase64=ivHErp1x4bJDKuRo6L5bApO/DdoyD/dG0mAZrzLZEIs= --target-network=network1 --param=bond01:a03\n</code></pre></li> <li>Run the following to verify <code>alice</code>'s lock:   <pre><code>./bin/fabric-cli asset exchange is-locked --locker=alice --recipient=bob --target-network=network1 --param=bond01:a03\n</code></pre></li> <li>Run the following to trigger <code>PartyB</code> locking <code>50</code> units of token type <code>t1</code> for <code>PartyA</code> in <code>Corda_Network</code> for 30 mins:   <pre><code>CORDA_PORT=10009 ./clients/build/install/clients/bin/clients lock-asset --fungible --hashBase64=ivHErp1x4bJDKuRo6L5bApO/DdoyD/dG0mAZrzLZEIs= --timeout=1800 --recipient=\"O=PartyA,L=London,C=GB\" --param=t1:50\n</code></pre>   Note the <code>contract-id</code> displayed after successful execution of the command, will be used in next steps. The output containing <code>contract-id</code> would like this:   <pre><code>HTLC Lock State created with contract ID Right(b=10448674_80d2bee7-5a5d-45df-b14e-60bac4ba1bf3).\n</code></pre> <code>contract-id</code> is the alphanumeric text (with underscore and hyphens) after <code>b=</code> within parenthesis.</li> <li>Run the following to verify <code>PartyB</code>'s lock (can be verified by both parties):   <pre><code>CORDA_PORT=10006 ./clients/build/install/clients/bin/clients is-asset-locked --contract-id=&lt;contract-id&gt;\n</code></pre></li> <li>Run the following to trigger <code>PartyA</code>'s claim for <code>50</code> units of token type <code>t1</code> locked by <code>PartyB</code> in <code>Corda_Network</code>:   <pre><code>CORDA_PORT=10006 ./clients/build/install/clients/bin/clients claim-asset --secret=secrettext --contract-id=&lt;contract-id&gt;\n</code></pre> <code>PartyB</code> can see its node's logs to get the revealed hash preimage, and use it to claim the bond in the Fabric network.</li> <li>Run the following to trigger <code>bob</code>'s claim for <code>bond01:a03</code> locked by <code>alice</code> in <code>network1</code>:   <pre><code>./bin/fabric-cli asset exchange claim --recipient=bob --locker=alice --target-network=network1 --param=bond01:a03 --secret=secrettext\n</code></pre></li> <li>Run the following to verify the status of the bond assets owned by <code>alice</code> and <code>bob</code> in the Fabric network <code>network1</code> from <code>weaver/samples/fabric/fabric-cli</code> folder:    <pre><code>./scripts/getAssetStatus.sh\n</code></pre></li> <li>Run the following to verify the status of the assets owned by <code>PartyA</code> and <code>PartyB</code> in the <code>Corda_Network</code> from <code>weaver/samples/corda/corda-simple-application</code> folder:   <pre><code>./scripts/getAssetStatus.sh\n</code></pre></li> </ul> <p>The above steps complete a successful asset exchange between Fabric and Corda networks.  In addition to the above commands, following commands can be run if specified timeout has expired and the locked asset remains unclaimed.</p> <ul> <li>If <code>alice</code> wants to unlock the bond asset, run the following to trigger <code>alice</code>'s re-claim for <code>bond01:a03</code> locked in <code>network1</code>:   <pre><code>./bin/fabric-cli asset exchange unlock --locker=alice --recipient=bob --target-network=network1 --param=bond01:a03\n</code></pre></li> <li>If <code>PartyB</code> wants to unlock the token asset, run the following to trigger unlock for <code>t1:50</code> locked in <code>Corda_Network</code>:   <pre><code>CORDA_PORT=10009 ./clients/build/install/clients/bin/clients unlock-asset --contract-id=&lt;contract-id&gt;\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/interop/asset-exchange/fabric-fabric/","title":"Asset Exchange: Fabric with Fabric","text":"<p>One Fabric network transfers a bond from Alice to Bob in exchange for a transfer of tokens from Bob to Alice in the other network Ensure that one of the following chaincodes have been deployed in both networks:</p> <ul> <li><code>simpleasset</code></li> <li><code>simpleassetandinterop</code></li> <li><code>simpleassettransfer</code></li> </ul> <p>Run the following steps:</p> Notes The hash used in following steps can be replaced by any valid <code>SHA256</code> hash. <ol> <li>Navigate to the <code>weaver/samples/fabric/fabric-cli</code> (for the Node.js version) or the <code>weaver/samples/fabric/go-cli</code> (for the Golang version) folder in your clone of the Cacti repository.</li> <li>Run the following to verify the status of the assets owned by <code>alice</code> and <code>bob</code> in the two networks:    <pre><code>./scripts/getAssetStatus.sh 2\n</code></pre></li> <li>Complete the asset exchange in either of the two different ways:<ul> <li>Using a single command:<ul> <li>Run the following to trigger exchange of bond <code>bond01:a03</code> owned by <code>alice</code> in <code>network1</code> with <code>100</code> units of tokens <code>token1</code> owned by <code>bob</code> in <code>network2</code>:   <pre><code>./bin/fabric-cli asset exchange-all --network1=network1 --network2=network2 --secret=secrettext --timeout-duration=100 alice:bond01:a03:bob:token1:100\n</code></pre></li> <li>To verify that <code>bob</code> now owns a bond in exchange for <code>alice</code> owning some tokens, run the following:   <pre><code>./scripts/getAssetStatus.sh 2\n</code></pre></li> </ul> </li> <li> <p>Using step-by-step commands:</p> <ul> <li>Generate Secret-Hash Pair using following command (prints hash in base64):   <pre><code>./bin/fabric-cli hash --hash_fn=SHA256 secrettext\n</code></pre></li> <li>Run the following to trigger <code>alice</code> locking <code>bond01:a03</code> for <code>bob</code> in <code>network1</code> <pre><code>./bin/fabric-cli asset exchange lock --timeout-duration=3600 --locker=alice --recipient=bob --hashBase64=ivHErp1x4bJDKuRo6L5bApO/DdoyD/dG0mAZrzLZEIs= --target-network=network1 --param=bond01:a03\n</code></pre></li> <li>Run the following to verify <code>alice</code>'s lock:   <pre><code>./bin/fabric-cli asset exchange is-locked --locker=alice --recipient=bob --target-network=network1 --param=bond01:a03\n</code></pre></li> <li>Run the following to trigger <code>bob</code> locking <code>100</code> units of <code>token1</code> for <code>alice</code> in <code>network2</code>:   <pre><code>./bin/fabric-cli asset exchange lock --fungible --timeout-duration=1800 --locker=bob --recipient=alice --hashBase64=ivHErp1x4bJDKuRo6L5bApO/DdoyD/dG0mAZrzLZEIs= --target-network=network2 --param=token1:100\n</code></pre>   Note the <code>contract-id</code> printed as output in above command. The output line containing <code>contract-id</code> (text in base64 after <code>Contract Id:</code>) would like this:   <pre><code>\u2139 Fungible Asset Locked with Contract Id: E0JZq8Z+eS//2Bt4WU0pU210MvNgDC2hdUT1RgszOq0=, preimage: null, hashvalue: ivHErp1x4bJDKuRo6L5bApO/DdoyD/dG0mAZrzLZEIs=\n</code></pre></li> <li>Run the following to verify <code>bob</code>'s lock:   <pre><code>./bin/fabric-cli asset exchange is-locked --fungible --locker=bob --recipient=alice --target-network=network2 --contract-id=&lt;contract-id&gt;\n</code></pre></li> <li>Run the following to trigger <code>alice</code>'s claim for <code>100</code> units of <code>token1</code> locked by <code>bob</code> in <code>network2</code>:   <pre><code>./bin/fabric-cli asset exchange claim --fungible --recipient=alice --target-network=network2 --contract-id=&lt;contract-id&gt; --secret=&lt;hash-pre-image&gt;\n</code></pre></li> <li>Run the following to trigger <code>bob</code>'s claim for <code>bond01:a03</code> locked by <code>alice</code> in <code>network1</code>:   <pre><code>./bin/fabric-cli asset exchange claim --recipient=bob --locker=alice --target-network=network1 --param=bond01:a03 --secret=&lt;hash-pre-image&gt;\n</code></pre></li> </ul> <p>The above steps complete a successful asset exchange between two Fabric networks.  In addition to the above commands, following commands can be run if specified timeout has expired and the locked asset remains unclaimed.</p> <ul> <li>If <code>alice</code> wants to unlock the bond asset, run the following to trigger <code>alice</code>'s re-claim for <code>bond01:a03</code> locked in <code>network1</code>:   <pre><code>./bin/fabric-cli asset exchange unlock --locker=alice --recipient=bob --target-network=network1 --param=bond01:a03\n</code></pre></li> <li>If <code>bob</code> wants to unlock the token asset, run the following to trigger <code>bob</code>'s re-claim for <code>token1:100</code> locked in <code>network2</code>:   <pre><code>./bin/fabric-cli asset exchange unlock --fungible --locker=bob --target-network=network2 --contract-id=&lt;contract-id&gt;\n</code></pre></li> </ul> </li> </ul> </li> </ol>"},{"location":"weaver/getting-started/interop/asset-exchange/overview/","title":"Asset Exchange","text":"<p>This document lists sample ways in which you can exercise the asset-exchange interoperation protocol on the test network launched earlier.</p> <p>For this scenario, you only need the networks to be running with the appropriate contracts deployed and the ledgers bootstrapped. You do not need to run relays, drivers and IIN agents. You can run the following combinations of exchanges (other combinations of DLTs will be supported soon).</p> <ul> <li>Fabric with Fabric</li> <li>Fabric with Corda</li> <li>Fabric with Besu</li> <li>Corda with Corda</li> <li>Corda with Besu</li> <li>Besu with Besu</li> </ul>"},{"location":"weaver/getting-started/test-network/advanced-configuration/","title":"Advanced Configuration","text":"<p>You can configure the different components of the test network to use non-default parameter values for various settings (such as host names or port numbers). Here is a list of configurations you can tweak, classified by the DLT type.</p>"},{"location":"weaver/getting-started/test-network/advanced-configuration/#corda","title":"Corda","text":""},{"location":"weaver/getting-started/test-network/advanced-configuration/#relay","title":"Relay","text":"<p>To run the relay on a different port from the default (<code>9081</code>), do the following:</p> <ul> <li>Navigate to the <code>weaver/core/relay</code> folder in your clone of the Cacti repository.</li> <li>Update the <code>port</code> field in <code>config/Corda_Relay.toml</code>.</li> <li>To ensure that the relay of <code>network1</code> can communicate with this relay, update the <code>port</code> field in the <code>relays.Corda_Relay</code> section in <code>config/Fabric_Relay.toml</code> with the same value.</li> <li>To ensure that the relay of <code>network2</code> can communicate with this relay, update the <code>port</code> field in the <code>relays.Corda_Relay</code> section in <code>config/Fabric_Relay2.toml</code> with the same value.</li> <li>(You can update host names in similar locations, by adjusting the <code>hostname</code> field.)</li> <li>When you attempt a Fabric to Corda interoperation flow, use the new host name or port (instead of <code>localhost:9081</code>).</li> </ul>"},{"location":"weaver/getting-started/test-network/advanced-configuration/#driver","title":"Driver","text":"<p>To run the driver on a different port from the default (<code>9099</code>), do the following:</p> <ul> <li>Navigate to the <code>weaver/core/drivers/corda-driver</code> folder in your clone of the Cacti repository.</li> <li>Set the environment variable <code>DRIVER_PORT</code> appropriately while running the executable as follows:   <pre><code>DRIVER_PORT=&lt;port&gt; ./build/install/corda-driver/bin/corda-driver\n</code></pre></li> </ul> <p>To ensure that the relay can connect to this driver:</p> <ul> <li>Navigate to the <code>weaver/core/relay</code> folder in your clone of the Cacti repository.</li> <li>Update the <code>port</code> field in the <code>drivers.Corda</code> section in <code>config/Corda_Relay.toml</code> with the same value.</li> </ul>"},{"location":"weaver/getting-started/test-network/advanced-configuration/#network","title":"Network","text":"Notes In our sample setup, all the Corda nodes must be running on the same machine (<code>localhost</code> or some other) for seamless communication. <p>To change the ports the Corda nodes are listening on, do the following:</p> <ul> <li>Navigate to the <code>weaver/tests/network-setups/corda</code> folder in your clone of the Cacti repository.</li> <li>Update the exposed ports in <code>docker-compose.yml</code> (defaults are <code>10003</code> for the <code>notary</code> container and <code>10006</code> for the <code>partya</code> container).</li> <li>Navigate to the <code>weaver/samples/corda/corda-simple-application</code> folder in your clone of the Cacti repository.</li> <li>Update the <code>CORDA_HOST</code> (default is <code>localhost</code>) and <code>CORDA_PORT</code> (default is <code>10006</code>) environment variables on your host machine to reflect the above update, or run the client bootstrapping script as follows:   <pre><code>CORDA_HOST=&lt;hostname&gt; CORDA_PORT=&lt;port&gt; make initialise-vault\n</code></pre></li> <li>When you attempt a Fabric to Corda interoperation flow, use the new host name and port values as in the following example (<code>network1</code> requesting <code>Corda_Network</code>):   <pre><code>./bin/fabric-cli interop --local-network=network1 --requesting-org=org1.network1.com localhost:9081/Corda_Network/&lt;CORDA_HOST&gt;:&lt;CORDA_PORT&gt;#com.cordaSimpleApplication.flow.GetStateByKey:H`\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/advanced-configuration/#client-application","title":"Client Application","text":"<p>The config files used to initialise the network's verification policies, access control policies, and security group info, contain the address (host name and port) of the Corda node.</p> <p>To update the address of the Corda node, do the following:</p> <ul> <li>Navigate to the <code>weaver/samples/corda/corda-simple-application</code> folder in your clone of the Cacti repository.</li> <li>Edit the <code>rules --&gt; resource</code> field in line 7 in <code>clients/src/main/resources/config/FabricNetworkAccessControlPolicy.json</code> by replacing <code>localhost:10006</code> with <code>&lt;CORDA_HOST&gt;:&lt;CORDA_PORT&gt;</code> as specified in the previous section.</li> </ul>"},{"location":"weaver/getting-started/test-network/advanced-configuration/#fabric","title":"Fabric","text":""},{"location":"weaver/getting-started/test-network/advanced-configuration/#relay_1","title":"Relay","text":"<p>To run the relay on a different port from the default (<code>9080</code> for <code>network1</code> and <code>9083</code> for <code>network2</code>), do the following:</p> <ul> <li>Navigate to the <code>weaver/core/relay</code> folder in your clone of the Cacti repository.</li> <li>Update the <code>port</code> field in <code>config/Fabric_Relay.toml</code> (for <code>network1</code>) or <code>config/Fabric_Relay2.toml</code> (for <code>network2</code>).</li> <li>To ensure Fabric-Fabric relay communication, update the foreign relay port in the <code>port</code> field in the <code>relays.Fabric_Relay</code> section in either of the above files.</li> <li>To ensure that the Corda network's relay can communicate with this relay, update the <code>port</code> field in the <code>relays.Fabric_Relay</code> section in <code>config/Corda_Relay.toml</code>.</li> <li>(You can update host names in similar locations, by adjusting the <code>hostname</code> field.)</li> <li>When you attempt a Fabric to Fabric or Corda to Fabric interoperation flow, use the new host name or port (instead of <code>localhost:9081</code> or <code>localhost:9083</code>).</li> <li>Navigate to the <code>weaver/core/drivers/fabric-driver</code> folder in your clone of the Cacti repository.</li> <li>Update the <code>RELAY_ENDPOINT</code> variable in <code>.env</code> or specify <code>RELAY_ENDPOINT=&lt;hostname&gt;:&lt;port&gt;</code> in the command line while running the driver using <code>npm run dev</code>.</li> <li>Navigate to the <code>weaver/samples/fabric/fabric-cli</code> folder in your clone of the Cacti repository.</li> <li>Update the <code>relayEndpoint</code> variables appropriately.</li> </ul>"},{"location":"weaver/getting-started/test-network/advanced-configuration/#driver_1","title":"Driver","text":"<p>The <code>fabric-driver</code> configuration can be controlled by environment variables either set in <code>.env</code> in the <code>weaver/core/drivers/fabric-driver</code> folder (or a copy if you created one) in your clone of the Cacti repository or passed in the command line when you run <code>npm run dev</code> to start the driver. The relevant variables you can control when you make any change to the setup are:</p> <ul> <li><code>CONNECTION_PROFILE</code>: this is the path to the connection profile. If you make changes to the network or use a different one, create a new connection profile and point to it using this variable.</li> <li><code>RELAY_ENDPOINT</code>: this is the endpoint of the relay (hostname and port), and you can adjust it as described in the previous section; this is where the relay will be listening for incoming requests and from where the relay will channel foreign requests as well.</li> <li><code>DRIVER_ENDPOINT</code>: this is the hostname and port the driver itself will bind to, and you can change it from the default (<code>localhost:9090</code> for <code>network1</code> and <code>localhost:9095</code> for <code>network2</code>) as per your need</li> </ul>"},{"location":"weaver/getting-started/test-network/advanced-configuration/#fabric-cli","title":"Fabric CLI","text":"<p>You can adjust settings for <code>fabric-cli</code> in the <code>.env</code> and <code>config.json</code> (in the <code>weaver/samples/fabric/fabric-cli</code> folder in your clone of the Cacti repository) as described earlier.</p> <p>Important environment variables (in <code>.env</code>) are:</p> <ul> <li><code>DEFAULT_CHANNEL</code>: this is the name of the channel the CLI will interact with. If you build a new channel or network, update the channel name here.</li> <li><code>DEFAULT_CHAINCODE</code>: this is the name of the interoperaton chaincode the CLI will submit transactions and queries to for policy and security group bootstrapping. If you wish to test with a modified interoperation chaincode with a different name, update this value.</li> <li><code>MEMBER_CREDENTIAL_FOLDER</code>: as described earlier, this is an absolute path that points to policies and security group info associated with foreign networks. You can adjust this info for the existing three networks or add credentials for another network you wish to test interoperation flows with.</li> <li><code>LOCAL</code>: this is a boolean, indicating whether the network to connect to is running on (and as) <code>localhost</code></li> <li><code>DEFAULT_APPLICATION_CHAINCODE</code>: this is the name of the application chaincode which maintains information that can be shared (with proof) with other networks upon request using interoperation. You may write and deploy your own chaincode and use its name here instead of the default <code>simplestate</code>.</li> <li><code>CONFIG_PATH</code>: this points to the JSON file containing the configurations of all the Fabric networks that need to be configured using the <code>fabric-cli</code>.</li> </ul> <p>The <code>config.json</code> (which can have a different name as long as you add the right reference to <code>.env</code> and configure <code>fabric-cli</code> suitably) has the following structure (it can have any number of networks specified):</p> <pre><code>{\n  \"network1\": {\n    \"connProfilePath\": \"\",\n    \"relayEndpoint\": \"\"\n  },\n  \"network2\": {\n    \"connProfilePath\": \"\",\n    \"relayEndpoint\": \"\"\n  }\n}\n</code></pre> <ul> <li><code>connProfilePath</code>: absolute path of the network's connection profile</li> <li><code>relayEndpoint</code>: hostname and port of the particular network's relay (make sure you sync this with any changes made to that relay's configuration)</li> </ul>"},{"location":"weaver/getting-started/test-network/ledger-initialization/","title":"Ledger Initialization","text":"<p>Once the two Fabric networks and the Corda network are up and running along with their associated relays and drivers, we must initialize states in those networks to prepare them for interoperation. For the Fabric networks, this involves recording state in the channel ledgers, and for the Corda network, in the nodes' vaults. The configuration and bootstrapping takes different form depending on what interoperability mode you wish to test.</p>"},{"location":"weaver/getting-started/test-network/ledger-initialization/#preparation-for-data-sharing","title":"Preparation for Data Sharing","text":"<p>Follow the below instructions to prepare your networks for data sharing tests.</p>"},{"location":"weaver/getting-started/test-network/ledger-initialization/#initializing-the-fabric-networks","title":"Initializing the Fabric Networks","text":"<p>We use the Fabric CLI (<code>fabric-cli</code>) built earlier (in <code>weaver/samples/fabric/fabric-cli</code> for the Node.js version and <code>weaver/samples/fabric/go-cli</code> for the Golang version) for this purpose.</p>"},{"location":"weaver/getting-started/test-network/ledger-initialization/#configuring-the-fabric-cli","title":"Configuring the Fabric CLI","text":"<p>During bootstrap, the ledgers in both <code>network1</code> and <code>network2</code> must be populated with the following information scoped by the interoperation chaincode:</p> <ul> <li>Access control policies governing requests from foreign networks</li> <li>Security group info for foreign networks (i.e., identities of network units and their membership providers' certificate chains)</li> <li>Verification policies for proofs supplied by foreign networks</li> </ul> <p>Knowledge of foreign networks that must be configured in this stage is as follows:</p> <ul> <li><code>network1</code> has policies and security group info for <code>network2</code> and <code>Corda_Network</code></li> <li><code>network2</code> has policies and security group info for <code>network1</code> and <code>Corda_Network</code></li> </ul> <p>(<code>Corda_Network</code> will be launched later.) The ledgers must also be populated with sample key-value pairs for testing interoperation flows, scoped by the sample application chaincode.</p> <p>Prepare <code>fabric-cli</code> for configuration suitably as follows.</p> <ul> <li>Navigate to the <code>weaver/samples/fabric/fabric-cli</code> (for the Node.js version) or the <code>weaver/samples/fabric/go-cli</code> (for the Golang version) folder.</li> <li>Create a <code>config.json</code> file by copying the <code>config.template.json</code> and setting (or adding or removing) suitable values:<ul> <li>For each network, the relay port and connection profile paths are specified using the keys <code>relayPort</code> and <code>connProfilePath</code> respectively.<ul> <li>Replace <code>&lt;PATH-TO-WEAVER&gt;</code> with the absolute path location of the <code>weaver</code> folder within your Cacti repository clone.</li> <li>Otherwise, leave the default values unchanged.</li> </ul> </li> </ul> </li> <li>Create a <code>chaincode.json</code> file by copying the <code>chaincode.json.template</code> and leaving the default values unchanged. This file specified the arguments of the transaction to be locally invoked after fetching a remote view.</li> <li>Create a <code>.env</code> file by copying <code>.env.template</code> and setting the following parameter values:<ul> <li>If Relays and Drivers are deployed in the host machine:   <pre><code>MEMBER_CREDENTIAL_FOLDER=&lt;PATH-TO-WEAVER&gt;/samples/fabric/fabric-cli/src/data/credentials\nDEFAULT_APPLICATION_CHAINCODE=&lt;chaincode-name&gt;\nDEFAULT_APPLICATION_FUNC=&lt;function-name&gt;\nCONFIG_PATH=./config.json\nCHAINCODE_PATH=./chaincode.json\n</code></pre></li> <li>If Relays and Drivers are deployed in the Docker containers:   <pre><code>MEMBER_CREDENTIAL_FOLDER=&lt;PATH-TO-WEAVER&gt;/samples/fabric/fabric-cli/src/data/credentials_docker\nDEFAULT_APPLICATION_CHAINCODE=&lt;chaincode-name&gt;\nDEFAULT_APPLICATION_FUNC=&lt;function-name&gt;\nCONFIG_PATH=./config.json\nCHAINCODE_PATH=./chaincode.json\n</code></pre></li> <li>In each case, replace <code>&lt;PATH-TO-WEAVER&gt;</code> with the absolute path location of the <code>weaver</code> folder within your Cacti repository clone and <code>&lt;chaincode-name&gt;</code> with the name of the deployed chaincode, either <code>simplestate</code> or <code>simplestatewithacl</code>.</li> <li>If <code>simplestate</code> is deployed, set <code>&lt;function-name&gt;</code> to <code>Create</code>, and if <code>simplestatewithacl</code> if deployed, set <code>&lt;function-name&gt;</code> to <code>CreateFromRemote</code>.</li> <li>Leave the default values unchanged for the other parameters.</li> </ul> </li> <li>Run the following command:   <pre><code>./bin/fabric-cli env set-file ./.env\n</code></pre></li> </ul> Notes If the <code>CONFIG_PATH</code> environment variable is omitted from <code>.env</code>, then you must also run:<code>./bin/fabric-cli config set-file ./config.json</code>"},{"location":"weaver/getting-started/test-network/ledger-initialization/#bootstrapping-network-and-application-state","title":"Bootstrapping Network and Application State","text":"<p>Finally, to prepare both <code>network1</code> and <code>network2</code> for interoperation, run:</p> <pre><code>./bin/fabric-cli configure all network1 network2\n</code></pre> <p>If Fabric networks were launched with 2 organizations, run: <pre><code>./bin/fabric-cli configure all network1 network2 --num-orgs=2\n</code></pre></p> <p>Instead, if you launched only one of the two Fabric networks, run the following after replacing <code>&lt;network-id&gt;</code> with either <code>network1</code> or <code>network2</code>, and <code>&lt;1/2&gt;</code> with number of organizations in the network: <pre><code>./bin/fabric-cli configure all &lt;network-id&gt; --num-orgs=&lt;1/2&gt;\n</code></pre></p> <p>Wait for at least 5 minutes before moving on to the next step (testing interoperability modes) to allow the networks' IIN Agents to sync their respective memberships (which occur after every 5 minutes by default).</p> <p>Optionally, fabric-cli can be used to trigger sync manually by running following command:  <pre><code>./bin/fabric-cli configure membership --local-network=network1 --target-network=network2 --iin-agent-endpoint=localhost:9500\n</code></pre> This command syncs <code>network2</code>'s membership (target-network) in <code>network1</code> (local-network) using IIN Agent of <code>Org1MSP</code> as initiator. Similarly <code>network1</code>'s membership can be synced to <code>network2</code>'s ledger by running: <pre><code>./bin/fabric-cli configure membership --local-network=network2 --target-network=network1 --iin-agent-endpoint=localhost:9501\n</code></pre> Wait for 20-30 seconds after above commands to allow IIN Agents to finish the sync.</p>"},{"location":"weaver/getting-started/test-network/ledger-initialization/#initializing-the-corda-networks","title":"Initializing the Corda Networks","text":"<p>Once the Corda networks are launched, the client applications (built earlier) needs to be exercised to generate network (ledger) state in preparation to test interoperation flows.</p>"},{"location":"weaver/getting-started/test-network/ledger-initialization/#bootstrapping-networks-and-application-states","title":"Bootstrapping Networks and Application States","text":"<p>Just as we did for either Fabric network, the Corda network ledger (or vault on each node) must be initialized with access control policies, verification policies, and security group information for the two Fabric networks. Further, sample key-value pairs need to be recorded so we can later share them with a Fabric network via an interoperation flow.</p> <p>Bootstrap the Corda networks and application states as follows (the following instructions will initialize either or both Corda networks, depending on which of those are up and running):</p> <ul> <li>Navigate to the <code>weaver/samples/corda/corda-simple-application</code> folder.</li> <li>Run the following: <ul> <li>If Relays and Drivers are deployed in the host machine:   <pre><code>make initialise-vault\n</code></pre></li> <li>If Relays and Drivers are deployed in the Docker containers:   <pre><code>make initialise-vault-docker\n</code></pre> Even upon successful execution (as indicated by the console output), you may see errors of the following form: <pre><code>[ERROR] 07:51:17.206 [epollEventLoopGroup-19-1] client.exceptionCaught - AMQ214015: Failed to execute connection life cycle listener\njava.util.concurrent.RejectedExecutionException: Task org.apache.activemq.artemis.utils.actors.ProcessorBase$$Lambda$34/681158875@666df796 rejected from java.util.concurrent.ThreadPoolExecutor@236f653f[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 6]\n       at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063) ~[?:1.8.0_402]\n..........\n</code></pre> You can ignore these as they are transient errors that don't impact the operations.</li> </ul> </li> </ul>"},{"location":"weaver/getting-started/test-network/ledger-initialization/#next-steps","title":"Next Steps","text":"<p>The test networks are now configured and their ledgers are initialized. You can now run the data sharing flows.</p>"},{"location":"weaver/getting-started/test-network/ledger-initialization/#preparation-for-asset-exchange","title":"Preparation for Asset Exchange","text":"<p>Follow the below instructions to prepare your networks for asset exchange tests.</p>"},{"location":"weaver/getting-started/test-network/ledger-initialization/#initializing-the-fabric-networks_1","title":"Initializing the Fabric Networks","text":"<p>We use the Fabric CLI (<code>fabric-cli</code>) built earlier (in <code>weaver/samples/fabric/fabric-cli</code> for the Node.js version and <code>weaver/samples/fabric/go-cli</code> for the Golang version) for this purpose.</p>"},{"location":"weaver/getting-started/test-network/ledger-initialization/#configuring-the-fabric-cli_1","title":"Configuring the Fabric CLI","text":"<p>The ledgers must be populated with sample key-value pairs for testing interoperation flows, scoped by the sample application chaincode.</p> <p>Prepare <code>fabric-cli</code> for configuration suitably as follows.</p> <ul> <li>Navigate to the <code>weaver/samples/fabric/fabric-cli</code> (for the Node.js version) or the <code>weaver/samples/fabric/go-cli</code> (for the Golang version) folder.</li> <li>Create a <code>config.json</code> file by copying the <code>config.template.json</code> and setting (or adding or removing) suitable values:<ul> <li>For each network, the relay port and connection profile paths are specified using the keys <code>relayPort</code> and <code>connProfilePath</code> respectively.<ul> <li>Replace <code>&lt;PATH-TO-WEAVER&gt;</code> with the absolute path location of the <code>weaver</code> folder within your Cacti repository clone.</li> <li>Set the <code>chaincode</code> attribute in each network to the deployed chaincode name (<code>simpleasset</code> or <code>simpleassetandinterop</code> or <code>simpleassettransfer</code>).</li> <li>Otherwise, leave the default values unchanged.</li> </ul> </li> </ul> </li> <li>Create a <code>.env</code> file by copying <code>.env.template</code> and setting following parameter values:<ul> <li>If Relays and Drivers are deployed in the host machine:   <pre><code>MEMBER_CREDENTIAL_FOLDER=&lt;PATH-TO-WEAVER&gt;/samples/fabric/fabric-cli/src/data/credentials\nCONFIG_PATH=./config.json\n</code></pre></li> <li>If Relays and Drivers are deployed in the Docker containers:   <pre><code>MEMBER_CREDENTIAL_FOLDER=&lt;PATH-TO-WEAVER&gt;/samples/fabric/fabric-cli/src/data/credentials_docker\nCONFIG_PATH=./config.json\n</code></pre></li> <li>In each case, replace <code>&lt;PATH-TO-WEAVER&gt;</code> with the absolute path location of the <code>weaver</code> folder within your Cacti repository clone.</li> <li>Leave the default values unchanged for the other parameters.</li> </ul> </li> <li>Run the following command:   <pre><code>./bin/fabric-cli env set-file ./.env\n</code></pre></li> </ul> Notes If the <code>CONFIG_PATH</code> environment variable is omitted from <code>.env</code>, then you must also run:<code>./bin/fabric-cli config set-file ./config.json</code>"},{"location":"weaver/getting-started/test-network/ledger-initialization/#bootstrapping-network-and-application-state_1","title":"Bootstrapping Network and Application State","text":"<p>Finally, to prepare both <code>network1</code> and <code>network2</code> for interoperation, run:</p> <pre><code>./scripts/initAsset.sh\n</code></pre>"},{"location":"weaver/getting-started/test-network/ledger-initialization/#initializing-the-corda-networks_1","title":"Initializing the Corda Networks","text":"<p>Corda Network needs to be initialized with assets for asset-exchange to be performed: Bootstrap the Corda network and application states as follows:</p> <ul> <li>Navigate to the <code>weaver/samples/corda/corda-simple-application</code> folder.</li> <li>Run the following: <ul> <li>For <code>cordaSimpleApplication</code> app, run:   <pre><code>./scripts/initAsset.sh\n</code></pre></li> </ul> </li> </ul>"},{"location":"weaver/getting-started/test-network/ledger-initialization/#initializing-the-besu-networks","title":"Initializing the Besu Networks","text":"<p>Let's assume that <code>network1</code> can either manage NFT <code>AliceERC721</code> or Hybrid <code>AliceERC1155</code> tokens, while <code>network2</code> manages fungible <code>BobERC20</code> tokens. Here we use account <code>1</code> for Alice and account <code>2</code> for Bob in both neworks. To prepare Besu networks for asset exchange, navigate to the <code>weaver/samples/besu/besu-cli</code> and then follow the steps in next subsections.</p>"},{"location":"weaver/getting-started/test-network/ledger-initialization/#configuring-the-besu-cli","title":"Configuring the Besu-CLI","text":"<p>Create a <code>config.json</code> file by copying the <code>config.template.json</code>, keep the default values for managing <code>AliceERC721</code> tokens in <code>network1</code> and <code>BobERC20</code> tokens in <code>network2</code>. If you want to change the token type used in the <code>network1</code> to Hybrid <code>AliceERC1155</code> tokens, in <code>config.json</code> update <code>tokenContract</code> field with value <code>\"../simpleasset/build/contracts/AliceERC1155.json\".</code></p>"},{"location":"weaver/getting-started/test-network/ledger-initialization/#bootstrapping-network-and-application-state_2","title":"Bootstrapping Network and Application State","text":"<p>Finally, to prepare both <code>network1</code> and <code>network2</code> for interoperation, run:</p> <ul> <li>If you wish to test the default exchange (ERC-20 tokens for ERC-721 tokens), run::   <pre><code>./scripts/initAsset.sh\n</code></pre>   This will issue <code>100 BobERC20</code> tokens to each account in <code>network2</code> and <code>AliceERC721</code> token with id <code>0</code> to <code>Alice</code> and id <code>1</code> to <code>Bob</code> in <code>network1</code>.</li> <li>Instead, if you wish to test Alice's exchange of ERC-1155 tokens for Bob's ERC-20 tokens, run:   <pre><code>./scripts/initAsset.sh hybrid\n</code></pre>   This will issue <code>100 BobERC20</code> tokens to each account in <code>network2</code> and <code>100 AliceERC1155</code> tokens with id <code>0</code> to <code>Alice</code> and id <code>1</code> to <code>Bob</code> in <code>network1</code>.</li> </ul>"},{"location":"weaver/getting-started/test-network/ledger-initialization/#next-steps_1","title":"Next Steps","text":"<p>The test networks are now configured and their ledgers are initialized. You can now run the asset exchange flows.</p>"},{"location":"weaver/getting-started/test-network/ledger-initialization/#preparation-for-asset-transfer","title":"Preparation for Asset Transfer","text":"<p>Follow the below instructions to prepare your networks for asset transfer tests.</p>"},{"location":"weaver/getting-started/test-network/ledger-initialization/#initializing-the-fabric-networks_2","title":"Initializing the Fabric Networks","text":"<p>We use the Fabric CLI (<code>fabric-cli</code>) built earlier (in <code>weaver/samples/fabric/fabric-cli</code> for the Node.js version and <code>weaver/samples/fabric/go-cli</code> for the Golang version) for this purpose.</p>"},{"location":"weaver/getting-started/test-network/ledger-initialization/#configuring-the-fabric-cli_2","title":"Configuring the Fabric CLI","text":"<p>During bootstrap, the ledgers in both <code>network1</code> and <code>network2</code> must be populated with the following information scoped by the interoperation chaincode:</p> <ul> <li>Access control policies governing requests from foreign networks</li> <li>Security group info for foreign networks (i.e., identities of network units and their membership providers' certificate chains)</li> <li>Verification policies for proofs supplied by foreign networks</li> </ul> <p>Knowledge of foreign networks that must be configured in this stage is as follows:</p> <ul> <li><code>network1</code> has policies and security group info for <code>network2</code> and <code>Corda_Network</code></li> <li><code>network2</code> has policies and security group info for <code>network1</code> and <code>Corda_Network</code></li> </ul> <p>(The Corda sample application doesn't support asset transfer yet, but there is no harm in including it above.) The ledgers must also be populated with sample key-value pairs for testing interoperation flows, scoped by the sample application chaincode.</p> <p>Prepare <code>fabric-cli</code> for configuration suitably as follows.</p> <ul> <li>Navigate to the <code>weaver/samples/fabric/fabric-cli</code> folder (the Go CLI doesn't support asset transfer yet).</li> <li>Create a <code>config.json</code> file by copying the <code>config.template.json</code> and setting (or adding or removing) suitable values:<ul> <li>For each network, the relay port and connection profile paths are specified using the keys <code>relayPort</code> and <code>connProfilePath</code> respectively.<ul> <li>Replace <code>&lt;PATH-TO-WEAVER&gt;</code> with the absolute path location of the <code>weaver</code> folder within your Cacti repository clone.</li> <li>Set the <code>chaincode</code> attribute in each network to <code>simpleassettransfer</code>.</li> <li>Set the <code>aclPolicyPrincipalType</code> attribute in <code>network2</code> to <code>ca</code>.</li> <li>Otherwise, leave the default values unchanged.</li> </ul> </li> </ul> </li> <li>Create <code>remote-network-config.json</code> file by copying <code>remote-network-config.json.template</code>. Use default values if relays and drivers are deployed in the host machine; else if they are deployed in Docker, update as follows:<ul> <li>Update value for <code>relayEndpoint</code> for <code>network1</code> as <code>relay-network1:9080</code>.</li> <li>Update value for <code>relayEndpoint</code> for <code>network2</code> as <code>relay-network2:9083</code>.</li> <li>Update value for <code>relayEndpoint</code> for <code>Corda_Network</code> as <code>relay-corda:9081</code>.</li> <li>Update value for <code>relayEndpoint</code> for <code>Corda_Network2</code> as <code>relay-corda2:9082</code>.</li> <li>Update value for <code>partyEndPoint</code> for <code>Corda_Network</code> as <code>corda_partya_1:10003</code>.</li> <li>Update value for <code>partyEndPoint</code> for <code>Corda_Network2</code> as <code>corda_network2_partya_1:10003</code>.</li> </ul> </li> <li>Create <code>chaincode.json</code> file by copying <code>chaincode.json.template</code>. Keep the default values unchanged.</li> <li>Create a <code>.env</code> file by copying <code>.env.template</code> and setting the following parameter values:<ul> <li>If Relays and Drivers are deployed in the host machine:   <pre><code>MEMBER_CREDENTIAL_FOLDER=&lt;PATH-TO-WEAVER&gt;/samples/fabric/fabric-cli/src/data/credentials\nDEFAULT_APPLICATION_CHAINCODE=simpleassettransfer\nCONFIG_PATH=./config.json\nREMOTE_CONFIG_PATH=./remote-network-config.json\nCHAINCODE_PATH=./chaincode.json\n</code></pre></li> <li>If Relays and Drivers are deployed in the Docker containers:   <pre><code>MEMBER_CREDENTIAL_FOLDER=&lt;PATH-TO-WEAVER&gt;/samples/fabric/fabric-cli/src/data/credentials_docker\nDEFAULT_APPLICATION_CHAINCODE=simpleassettransfer\nCONFIG_PATH=./config.json\nREMOTE_CONFIG_PATH=./remote-network-config.json\nCHAINCODE_PATH=./chaincode.json\n</code></pre></li> <li>In each case, replace <code>&lt;PATH-TO-WEAVER&gt;</code> with the absolute path location of the <code>weaver</code> folder within your Cacti repository clone.</li> <li>Leave the default values unchanged for the other parameters.</li> </ul> </li> <li>Run the following command:   <pre><code>./bin/fabric-cli env set-file ./.env\n</code></pre></li> </ul> Notes If the <code>CONFIG_PATH</code> environment variable is omitted from <code>.env</code>, then you must also run:<code>./bin/fabric-cli config set-file ./config.json</code>"},{"location":"weaver/getting-started/test-network/ledger-initialization/#bootstrapping-network-and-application-state_3","title":"Bootstrapping Network and Application State","text":"<p>Create appropriate access control and verification policies for <code>network1</code> and <code>network2</code> by running:</p> <pre><code>./bin/fabric-cli configure create all --local-network=network1\n./bin/fabric-cli configure create all --local-network=network2\n</code></pre> <p>Load access control and verification policies onto the ledgers of <code>network1</code> and <code>network2</code> by running (replace <code>&lt;1/2&gt;</code> with number of organizations in the network):</p> <pre><code>./bin/fabric-cli configure network --local-network=network1 --num-orgs=&lt;1/2&gt;\n./bin/fabric-cli configure network --local-network=network2 --num-orgs=&lt;1/2&gt;\n</code></pre> <p>Wait for at least 5 minutes before moving on to the next step (testing interoperability modes) to allow the networks' IIN Agents to sync their respective memberships (which occur after every 5 minutes by default).</p> <p>Optionally, fabric-cli can be used to trigger sync manually by running following command:  <pre><code>./bin/fabric-cli configure membership --local-network=network1 --target-network=network2 --iin-agent-endpoint=localhost:9500\n</code></pre> This command syncs <code>network2</code>'s membership (target-network) in <code>network1</code> (local-network) using IIN Agent of <code>Org1MSP</code> as initiator. Similarly <code>network1</code>'s membership can be synced to <code>network2</code>'s ledger by running: <pre><code>./bin/fabric-cli configure membership --local-network=network2 --target-network=network1 --iin-agent-endpoint=localhost:9501\n</code></pre> Wait for 20-30 seconds after above commands to allow IIN Agents to finish the sync.</p> <p>Initialize bond and token asset states and ownerships on the <code>network1</code> ledger by running the following (this step will also create a user <code>alice</code> in <code>network1</code> and a user <code>bob</code> in <code>network2</code>):</p> <pre><code>./scripts/initAssetsForTransfer.sh\n</code></pre>"},{"location":"weaver/getting-started/test-network/ledger-initialization/#initializing-the-corda-networks_2","title":"Initializing the Corda Networks","text":"<p>Once the Corda networks (<code>Corda_Network</code> and <code>Corda_Network2</code>) are launched, the client applications (built earlier) needs to be exercised to generate ledger state in both exporting/source and importing/destination networks in preparation to test asset transfer interoperation flows.</p>"},{"location":"weaver/getting-started/test-network/ledger-initialization/#bootstrapping-networks-and-application-states_1","title":"Bootstrapping Networks and Application States","text":"<p>The Corda network ledger (or vault on each node) must be initialized with access control policies, verification policies, and security group information for the other networks (two Fabric networks and other Corda network).</p> <p>Bootstrap the Corda networks and application states as follows (the following instructions will initialize either or both Corda networks, depending on which of those are up and running):</p> <ul> <li>Navigate to the <code>weaver/samples/corda/corda-simple-application</code> folder.</li> <li>Run the following:   <pre><code>cp clients/src/main/resources/config/remote-network-config.json.template clients/src/main/resources/config/remote-network-config.json\n</code></pre>   Use default values in <code>remote-network-config.json</code> if relays and drivers are deployed in the host machine; else if they are deployed in Docker, update as follows:<ul> <li>Update value for <code>relayEndpoint</code> for <code>network1</code> as <code>relay-network1:9080</code>.</li> <li>Update value for <code>relayEndpoint</code> for <code>network2</code> as <code>relay-network2:9083</code>.</li> <li>Update value for <code>relayEndpoint</code> for <code>Corda_Network</code> as <code>relay-corda:9081</code>.</li> <li>Update value for <code>relayEndpoint</code> for <code>Corda_Network2</code> as <code>relay-corda2:9082</code>.</li> <li>Update value for <code>partyEndPoint</code> for <code>Corda_Network</code> as <code>corda_partya_1:10003</code>.</li> <li>Update value for <code>partyEndPoint</code> for <code>Corda_Network2</code> as <code>corda_network2_partya_1:10003</code>.</li> </ul> </li> <li>Run the following: <ul> <li>If Relays and Drivers are deployed in the host machine:   <pre><code>make initialise-vault-asset-transfer\n</code></pre></li> <li>If Relays and Drivers are deployed in the Docker containers:   <pre><code>make initialise-vault-asset-transfer-docker\n</code></pre> Even upon successful execution (as indicated by the console output), you may see errors of the following form: <pre><code>[ERROR] 07:51:17.206 [epollEventLoopGroup-19-1] client.exceptionCaught - AMQ214015: Failed to execute connection life cycle listener\njava.util.concurrent.RejectedExecutionException: Task org.apache.activemq.artemis.utils.actors.ProcessorBase$$Lambda$34/681158875@666df796 rejected from java.util.concurrent.ThreadPoolExecutor@236f653f[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 6]\n       at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063) ~[?:1.8.0_402]\n..........\n</code></pre> You can ignore these as they are transient errors that don't impact the operations.</li> </ul> </li> </ul>"},{"location":"weaver/getting-started/test-network/ledger-initialization/#next-steps_2","title":"Next Steps","text":"<p>The test networks are now configured and their ledgers are initialized. You can now run the asset transfer flows.</p>"},{"location":"weaver/getting-started/test-network/overview/","title":"Component Overview","text":"<p>Weaver offers a basic test network launching capability, both to demonstrate interoperation modes and to serve as a testbed for development and prototyping. Different modes (or scenarios) require different sets of components, but collectively you will need to run the following:</p> <ul> <li>Fabric testnet - A pair of basic Fabric networks for testing interop flows</li> <li>Corda testnet - A pair of basic Corda networks for testing interop flows</li> <li>Besu testnet - A pair of basic Besu networks for testing interop flows</li> <li>Relay - The server module and protocol for cross-DLT interoperability. An instance of this is needed for every Fabric and Corda network</li> <li>Fabric driver - Driver used by the Fabric networks relay to communicate with the Fabric testnet</li> <li>Corda driver - Driver used by the Corda networks relay to communicate with the Corda testnet</li> <li>Fabric Interop chaincode - The Fabric interoperability contracts handle the dual process of servicing requests for views from external networks, and verifying requested views for integrity</li> <li>Corda interop app CorDapp used to handle interop duties between the relay and the application</li> <li>Besu interop contract Solidity smart contract(s) used to handle interop duties for a Besu network</li> <li>Fabric client - Fabric client used to trigger interop flows initiated from the Fabric side and to manage Fabric state</li> <li>Corda client app - CorDapp and client used to trigger interop flows initiated from the Corda side and to manage Corda state</li> <li>Besu sample application - A sample application for asset exchange across two besu networks using HTLC</li> <li>Besu client app - Besu client used to interact with the contracts deployed on the Besu testnet</li> </ul> <p>You can launch these components in one of several different ways:</p> <ul> <li>Setup with Locally Built Weaver Components:<ul> <li>Deployed on Host Machine: Build the above components purely from your local clone of the Weaver code repository. If you wish to experiment with source code modifications, this is the right option to choose.</li> <li>Deployed in Docker containers: This is similar to the above option, except with relays and drivers launched in Docker containers rather than in the host.</li> </ul> </li> <li>Setup with Imported Weaver Components:<ul> <li>Deployed on Host Machine: Import pre-built Weaver components from GitHub Packages instead of building them locally. If you wish to see how Weaver works using pre-tested components and without, choose this option.</li> <li>Deployed in Docker containers: This is similar to the above option, except with relays and drivers launched in Docker containers rather than in the host.</li> </ul> </li> </ul> <p>After setting up and launching the components, you must initialize the network by following steps in Ledger Initialization. Then you can test the following interoperation modes:</p> <ul> <li>Data Sharing among Fabric and Corda networks</li> <li>Asset Exchange among Fabric, Corda, and Besu networks</li> <li>Asset Transfer between Fabric networks</li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local-docker/","title":"Setup with Locally Built Dockerized Weaver Components","text":"<p>In this document, we detail the steps using which you can bring up networks using the default configuration settings and by fetching pre-built Weaver interoperation modules, SDK libraries, and relay docker image, drivers docker images from GitHub Package repositories. To customize these settings (e.g., hostnames, ports), refer to the Advanced Configuration page.</p> Notes All components are run within Docker containers, except client applications. <p>Follow the instructions below to build and run components followed by interoperation flows. These instructions have been tested on Ubuntu Linux (bash shell) and Mac OS. In general, they should work on any system and shell as long as the various dependencies have been installed and configured.</p>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#prerequisites","title":"Prerequisites","text":""},{"location":"weaver/getting-started/test-network/setup-local-docker/#software","title":"Software","text":"<p>Before starting, make sure you have the following software installed on your host machine:</p> <ul> <li>Curl: install using package manager, like <code>apt</code> on Debian/Ubuntu Linux</li> <li>Git: sample instructions</li> <li>Docker: sample instructions (Latest version)</li> <li>Docker-Compose: sample instructions (Version 2 or higher)</li> <li>Golang: sample instructions (Version 1.16 or higher)</li> <li>Java (JDK and JRE): sample instructions (Version 8)</li> <li>Node.js and NPM: sample instructions (Version 16 Supported)</li> <li>Yarn: sample instructions</li> <li> <p>Protoc (Protobuf compiler): Golang should already be installed and configured.</p> <ul> <li>Default method: Run the following with <code>sudo</code> if necessary. This will install both the protobuf compiler and the Go code generator plugins.   <pre><code>apt-get install protobuf-compiler\ngo install google.golang.org/protobuf/cmd/protoc-gen-go\ngo install google.golang.org/grpc/cmd/protoc-gen-go-grpc\n</code></pre></li> <li>If the above method installs an older version of <code>protoc</code> (check using <code>protoc --version</code>), say below 3.12.x, you should download pre-compiled binaries instead. (With an older version, you may see errors while attempting to launch and setup the Fabric networks).   <pre><code>sudo apt-get remove protobuf-compiler\ncurl -LO https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-linux-x86_64.zip\nsudo apt-get install unzip\nunzip protoc-3.15.6-linux-x86_64.zip -d &lt;some-folder-path&gt;\nexport PATH=\"$PATH:&lt;some-folder-path&gt;/bin\"\ngo install google.golang.org/protobuf/cmd/protoc-gen-go\ngo install google.golang.org/grpc/cmd/protoc-gen-go-grpc\n</code></pre></li> </ul> Notes The latest version at present is <code>3.15.6</code>, but you should check the above link to find the most current version before running the above steps. </li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#credentials","title":"Credentials","text":"<p>Make sure you have an SSH or GPG key registered in https://github.com to allow seamless cloning of repositories (at present, various setup scripts clone repositories using the <code>https://</code> prefix but this may change to <code>git@</code> in the future).</p>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#getting-the-code-and-documentation","title":"Getting the Code and Documentation","text":"<p>Clone the cacti repository. The code to get a basic test network up and running and test data-sharing interoperation flows lies in the subfolder <code>weaver/tests/network-setups</code>, which should be your starting point, though the setups will rely on other parts of the repository, as you will find out in the instructions given on this page.</p>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#common-structures","title":"Common Structures","text":"<p>The <code>weaver/common/protos</code> folder contains structure definitions in the protobuf format that are used by all the different components. The various <code>weaver/common/protos-*</code> folders are meant to contain compiled protobufs (in different languages).</p> <p>To compile the protobufs for JavaScript, do the following:</p> <ul> <li>Navigate to the <code>weaver/common/protos-js</code> folder.</li> <li>Run the following command:   <pre><code>make build\n</code></pre></li> </ul> <p>To compile the protobufs for Golang, do the following:</p> <ul> <li>Navigate to the <code>weaver/common/protos-go</code> folder.</li> <li>Run the following command:   <pre><code>make build\n</code></pre></li> </ul> <p>To compile the protobufs for Java and Kotlin, do the following:</p> <ul> <li>Navigate to the <code>weaver/common/protos-java-kt</code> folder.</li> <li>Run the following command:   <pre><code>make build\n</code></pre></li> </ul> <p>To compile the protobufs for Solidity, do the following:</p> <ul> <li>Navigate to the <code>weaver/common/protos-sol</code> folder.</li> <li>Run the following command:   <pre><code>make build\n</code></pre></li> </ul> <p>To compile the protobufs for Rust, do the following:</p> <ul> <li>Navigate to the <code>weaver/common/protos-rs</code> folder.</li> <li>Run the following command:   <pre><code>make build\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#securing-components","title":"Securing Components","text":"Notes The relays and drivers corresponding to the different test networks you will encounter below can be run with or without TLS enabled. But the default files used in the demonstrations assume that either all relays and drivers are TLS-enabled or none are. Therefore, you should determine at the outset whether or not you wish to run the entire set of components in TLS-enabled mode, and select appropriate commands in the provided instructions."},{"location":"weaver/getting-started/test-network/setup-local-docker/#hyperledger-fabric-components","title":"Hyperledger Fabric Components","text":"<p>Using the sequence of instructions below, you can start two separate Fabric networks, each with a single channel and application contract (chaincode). You can also start an interoperation contract, a relay and a driver acting on behalf of each network. You can build a Fabric CLI tool with which you can initialize both networks' ledgers with access control policies, foreign networks' security groups (i.e., membership providers' certificate chains), and some sample key-value pairs that can be shared during subsequent interoperation flows.</p>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#fabric-interoperation-node-sdk","title":"Fabric Interoperation Node SDK","text":"<p>A client-layer library (companion to <code>hyperledger/fabric-sdk-node</code>) is defined in the <code>weaver/sdks/fabric/interoperation-node-sdk</code> folder. This contains functions for Fabric Gateway-based applications to exercise interoperation capabilities via relays and also several utility/helper functions. The Fabric-CLI tool, which we will use later, depends on this library.</p> <p>To build the library, do the following:</p> <ul> <li>Navigate to the <code>weaver/sdks/fabric/interoperation-node-sdk</code> folder.</li> <li>Run the following command:   <pre><code>make build-local\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#fabric-network","title":"Fabric Network","text":"<p>The code for this lies in the <code>weaver/tests/network-setups/fabric/</code> folder.</p> <p>This folder contains code to create and launch networks <code>network1</code> and <code>network2</code> of identical specifications:</p> <ul> <li>Network: 1 peer, 1 peer CA, 1 ordering service node, 1 ordering service CA</li> <li>Single channel named <code>mychannel</code></li> <li>One of the following contracts deployed on <code>mychannel</code>, the choice depending on the interoperability mode you wish to test:<ul> <li><code>simplestate</code> (Data Sharing): supports simple transactions (<code>Create</code>, <code>Read</code>, <code>Update</code>, <code>Delete</code>) involving storage and lookup of  pairs. <li><code>simplestatewithacl</code> (Data Sharing): identical to <code>simplestate</code> but with extra security features to ensure that the Weaver infrastructure cannot be bypassed by a malicious client of the network.</li> <li><code>simpleasset</code> (Asset Exchange): supports creation, modification, transfer, and deletion, as well as locking, unlocking, and claiming, of simple bonds and tokens (examples of non-fungible and fungible assets respectively).</li> <li><code>simpleassetandinterop</code> (Asset Exchange): identical to <code>simpleasset</code> but where the locking, unlocking, and claiming logic is imported as a library in the chaincode rather than available in the common Fabric Interoperation Chaincode (a Weaver component).</li> <li><code>simpleassettransfer</code> (Asset Exchange or Asset Transfer): augmentation of <code>simpleasset</code> with asset pledging, claiming, and reclaiming features for cross-network transfers.</li> Notes For new users, we recommend testing the Data Sharing feature first with the <code>simplestate</code> contract. To test the other modes, you can simply tear down the Fabric networks and restart them with the appropriate chaincodes installed. <p>Follow the instructions below to build and launch the networks:</p> <ul> <li>Navigate to the <code>weaver/tests/network-setups/fabric/dev</code> folder.</li> <li>To spin up both network1 and network2 with the interoperation chaincode and the default <code>simplestate</code> chaincode installed, run:   <pre><code>make start-interop-local\n</code></pre></li> <li>To launch the networks with a different application chaincode from the above list, run:   <pre><code>make start-interop-local CHAINCODE_NAME=&lt;chaincode-name&gt;\n</code></pre></li> <li>To launch the networks with 2 organizations, each with a peer (this will enable more variation and experimentation, which you can attempt after testing interoperation protocols across basic network configurations), run:   <pre><code>make start-interop-local PROFILE=\"2-nodes\"\n</code></pre></li> </ul> Notes If you do not wish to test Fabric-Fabric interoperation, you can choose to launch only one of the two networks along with its interoperation chaincode. For <code>network1</code>, run <code>make start-interop-network1-local</code>, and for <code>network2</code>, run <code>make start-interop-network2-local</code> If you wish to enable end-to-end confidentiality by default in the interoperation modules that are deployed during network launch, set the environment variable <code>E2E_CONFIDENTIALITY</code> to <code>true</code> in the command line as follows: <code>E2E_CONFIDENTIALITY=true make start-interop-local</code> <p>For more information, refer to the associated README.</p> <p>Troubleshooting Tips:</p> <ul> <li>If you see any errors during the launches, re-check the prerequisites (software installations and credentials). Ensure your network connection is working. As a safe bet, you can retry after cleanup: kill and remove all Docker containers and associated volumes.</li> <li>If <code>protoc</code> or <code>protoc-gen-go</code> throws an error, reinstall <code>protoc</code> and <code>protoc-gen-go</code> using suggestions made in the Prerequisites section above.</li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#fabric-relay","title":"Fabric Relay","text":"<p>The relay is a module acting on behalf of a network, enabling interoperation flows with other networks by communicating with their relays. The code for this lies in the <code>weaver/core/relay</code> folder. Navigate to the <code>weaver/core/relay</code> folder.</p>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#building-relay-image","title":"Building Relay Image","text":"<p>To build the docker image for relay, run: <pre><code>make build-server-local\n</code></pre></p>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#deployment","title":"Deployment","text":"<ul> <li>The <code>docker-compose.yaml</code> in this folder is minimally configured with default values. To modify it for use with the Fabric testnets, run:   <pre><code>make convert-compose-method2\n</code></pre></li> <li>The <code>.env.n1</code> and <code>.env.n1.tls</code> files in the <code>docker/testnet-envs</code> directory contain environment variables used by the <code>network1</code> relay at startup and runtime. Edit either of these files (depending on whether you wish to start the relay with or without TLS), and update the following value:   <pre><code>DOCKER_IMAGE_NAME=cacti-weaver-relay-server\n</code></pre></li> <li>Repeat the above step for <code>.env.n2</code> or <code>.env.n2.tls</code> in <code>docker/testnet-envs</code> directory, which contain environment variables for the <code>network2</code> relay.</li> <li>To deploy the relay server for <code>network1</code> without TLS, run:   <pre><code>make start-server COMPOSE_ARG='--env-file docker/testnet-envs/.env.n1'\n</code></pre>   Instead, to deploy the relay server with TLS, run:   <pre><code>make start-server COMPOSE_ARG='--env-file docker/testnet-envs/.env.n1.tls'\n</code></pre></li> <li>To deploy the relay server for <code>network2</code> without TLS, run:   <pre><code>make start-server COMPOSE_ARG='--env-file docker/testnet-envs/.env.n2'\n</code></pre>   Instead, to deploy the relay server with TLS, run:   <pre><code>make start-server COMPOSE_ARG='--env-file docker/testnet-envs/.env.n2.tls'\n</code></pre></li> <li>After launching the relay(s), you can revert the <code>docker-compose.yaml</code> changes by running:   <pre><code>make convert-compose-method1\n</code></pre></li> </ul> <p>For more information, see the relay-docker README.</p>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#fabric-driver","title":"Fabric Driver","text":"<p>A driver is a DLT-specific plugin invoked by the relay while channelling external data queries to the local peer network and collecting a response with proofs. The Fabric driver is built as a Fabric client application on the <code>fabric-network</code> NPM package. The code for this lies in the <code>weaver/core/drivers/fabric-driver</code> folder. Navigate to the <code>weaver/core/drivers/fabric-driver</code> folder.</p>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#building","title":"Building","text":"<p>To build the fabric-driver image, run: <pre><code>make build-image-local\n</code></pre></p>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#deployment_1","title":"Deployment","text":"<p>Use the following steps to run Fabric drivers in Docker containers:</p> <ul> <li>The <code>.env.n1</code> and <code>.env.n1.tls</code> files in the <code>docker-testnet-envs</code> directory contain environment variables used by the <code>network1</code> driver at startup and runtime. Edit either of these files (depending on whether you wish to start the relay with or without TLS) as follows:<ul> <li>Replace <code>&lt;PATH-TO-WEAVER&gt;</code> with the absolute path of the <code>weaver</code> folder within your Cacti repository clone.</li> <li>Update the following value:   <pre><code>DOCKER_IMAGE_NAME=cacti-weaver-driver-fabric\n</code></pre></li> </ul> </li> <li>Repeat the above steps for <code>.env.n2</code> or <code>.env.n2.tls</code> in <code>docker-testnet-envs</code> directory, which contain environment variables for the <code>network2</code> driver.</li> <li>To deploy the Fabric driver for <code>network1</code> without TLS, run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet-envs/.env.n1' NETWORK_NAME=$(grep NETWORK_NAME docker-testnet-envs/.env.n1 | cut -d '=' -f 2)\n</code></pre>   Instead, to deploy the driver with TLS, run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet-envs/.env.n1.tls' NETWORK_NAME=$(grep NETWORK_NAME docker-testnet-envs/.env.n1.tls | cut -d '=' -f 2)\n</code></pre></li> <li>To deploy the Fabric driver for <code>network2</code> without TLS, run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet-envs/.env.n2' NETWORK_NAME=$(grep NETWORK_NAME docker-testnet-envs/.env.n2 | cut -d '=' -f 2)\n</code></pre>   Instead, to deploy the driver with TLS, run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet-envs/.env.n2.tls' NETWORK_NAME=$(grep NETWORK_NAME docker-testnet-envs/.env.n2.tls | cut -d '=' -f 2)\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#fabric-iin-agent","title":"Fabric IIN Agent","text":"<p>IIN Agent is a client of a member of a DLT network or security domain with special permissions to update security domain identities and configurations on the ledger via the network's interoperation module. The code for this lies in the <code>weaver/core/identity-management/iin-agent</code> folder. Navigate to the <code>weaver/core/identity-management/iin-agent</code> folder.</p>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#building_1","title":"Building","text":"<p>To build the IIN Agent image, run: <pre><code>make build-image-local\n</code></pre></p>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#deployment_2","title":"Deployment","text":"<p>Use the following steps to run Fabric IIN Agents in Docker containers:</p> <ul> <li>The <code>.env.n1.org1</code> and <code>.env.n1.org1.tls</code> files in the <code>docker-testnet/envs</code> directory contain environment variables used by the iin-agent of <code>org1</code> of <code>network1</code> at startup and runtime. Edit either of these files (depending on whether you wish to start the relay with or without TLS) as follows:<ul> <li>Replace <code>&lt;PATH-TO-WEAVER&gt;</code> with the absolute path of the <code>weaver</code> folder within your Cacti repository clone.</li> <li>Update the following value:   <code>DOCKER_IMAGE_NAME=cacti-weaver-iin-agent</code></li> <li>If Fabric network was started with 1 org, and IIN Agents are to be started with TLS enabled, update the <code>DNS_CONFIG_PATH</code> variable as:   <pre><code>DNS_CONFIG_PATH=./docker-testnet/configs/dnsconfig-tls.json\n</code></pre></li> <li>If Fabric network was started with 2 orgs, and IIN Agents are to be started without TLS, update the <code>DNS_CONFIG_PATH</code> variable as   <pre><code>DNS_CONFIG_PATH=./docker-testnet/configs/dnsconfig-2-nodes.json\n</code></pre></li> <li>If Fabric network was started with 2 orgs and IIN Agents are to be started with TLS enabled, update the <code>DNS_CONFIG_PATH</code> variable as:   <pre><code>DNS_CONFIG_PATH=./docker-testnet/configs/dnsconfig-tls-2-nodes.json\n</code></pre></li> </ul> </li> <li>Repeat the above steps for all other environment variable files (depending upon whether tls is enabled) in <code>docker-testnet/envs</code> directory.</li> <li>To deploy the Fabric IIN Agent for <code>org1</code> of <code>network1</code> without TLS, run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet/envs/.env.n1.org1' DLT_SPECIFIC_DIR=$(grep DLT_SPECIFIC_DIR docker-testnet/envs/.env.n1.org1 | cut -d '=' -f 2)\n</code></pre>   Instead, to deploy the IIN Agent with TLS, run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet/envs/.env.n1.org1.tls' DLT_SPECIFIC_DIR=$(grep DLT_SPECIFIC_DIR docker-testnet/envs/.env.n1.org1.tls | cut -d '=' -f 2)\n</code></pre></li> <li>To deploy the Fabric IIN Agent for <code>org2</code> of <code>network1</code> without TLS (only required if Fabric network was started with 2 orgs), run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet/envs/.env.n1.org2' DLT_SPECIFIC_DIR=$(grep DLT_SPECIFIC_DIR docker-testnet/envs/.env.n1.org2 | cut -d '=' -f 2)\n</code></pre>   Instead, to deploy the IIN Agent with TLS, run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet/envs/.env.n1.org2.tls' DLT_SPECIFIC_DIR=$(grep DLT_SPECIFIC_DIR docker-testnet/envs/.env.n1.org2.tls | cut -d '=' -f 2)\n</code></pre></li> <li>To deploy the Fabric IIN Agent for <code>org1</code> of <code>network2</code> without TLS, run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet/envs/.env.n2.org1' DLT_SPECIFIC_DIR=$(grep DLT_SPECIFIC_DIR docker-testnet/envs/.env.n2.org1 | cut -d '=' -f 2)\n</code></pre>   Instead, to deploy the IIN Agent with TLS, run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet/envs/.env.n2.org1.tls' DLT_SPECIFIC_DIR=$(grep DLT_SPECIFIC_DIR docker-testnet/envs/.env.n2.org1.tls | cut -d '=' -f 2)\n</code></pre></li> <li>To deploy the Fabric IIN Agent for <code>org2</code> of <code>network2</code> without TLS (only required if Fabric network was started with 2 orgs), run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet/envs/.env.n2.org2' DLT_SPECIFIC_DIR=$(grep DLT_SPECIFIC_DIR docker-testnet/envs/.env.n2.org2 | cut -d '=' -f 2)\n</code></pre>   Instead, to deploy the IIN Agent with TLS, run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet/envs/.env.n2.org2.tls' DLT_SPECIFIC_DIR=$(grep DLT_SPECIFIC_DIR docker-testnet/envs/.env.n2.org2.tls | cut -d '=' -f 2)\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#fabric-client-application","title":"Fabric Client (Application)","text":"<p>The CLI is used to interact with a Fabric network, configure it and run chaincode transactions to record data on the channel ledger or query data. It is also used to interact with remote networks through the relay in order to trigger an interoperation flow for data request and acceptance.</p> <p>The <code>fabric-cli</code> Node.js source code is located in the <code>weaver/samples/fabric/fabric-cli</code> folder and the Golang source code in the <code>weaver/samples/fabric/go-cli</code> folder.</p>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#prerequisites_1","title":"Prerequisites","text":"<p>If you are using a Linux system, make sure that lib64 is installed.</p> Notes For the Node.js version of the <code>fabric-cli</code>, the setup and running instructions below were tested with all Node.js versions from v11.14.0 to v14.17.3."},{"location":"weaver/getting-started/test-network/setup-local-docker/#installation","title":"Installation","text":"<p>You can install <code>fabric-cli</code> as follows (for both the Node.js and Golang versions):</p> <ul> <li>Navigate to the <code>weaver/samples/fabric/fabric-cli</code> folder (for the Node.js version) or the <code>weaver/samples/fabric/go-cli</code> (for the Golang version) folder.</li> <li>Run the following to install dependencies (for the Node.js version) or the executable (for the Golang version):   <pre><code>make build-local\n</code></pre></li> <li>Use the <code>fabric-cli</code> executable in the <code>bin</code> folder for subsequent actions.</li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#corda-components","title":"Corda Components","text":"<p>Using the sequence of instructions below, you can start a Corda network and run an application CorDapp on it. You can also run an interoperation CorDapp, a relay and a driver acting on behalf of the network. You can initialize the network's vault with access control policies, foreign networks' security groups (i.e., membership providers' certificate chains), and some sample state values that can be shared during subsequent interoperation flows.</p>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#interoperation-cordapp","title":"Interoperation CorDapp","text":"<p>The interoperation CorDapp is deployed to run as part of any Corda application flow that involves cross-network interoperation.</p> <p>Build the interoperation CorDapp as follows:</p> <ul> <li>Navigate to the <code>weaver/core/network/corda-interop-app</code> folder.</li> <li>Run the following to create the JAR files on which other Corda network components will depend on:   <pre><code>make build-local\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#corda-interoperation-sdk","title":"Corda Interoperation SDK","text":"<p>A client-layer library is defined in the <code>weaver/sdks/corda</code> folder. This contains functions for Corda based client applications to exercise interoperation capabilities via relays and also several utility/helper functions. The Corda Client tool, which we will use later, depends on this library.</p> <p>To build the library, do the following:</p> <ul> <li>Navigate to the <code>weaver/sdks/corda</code> folder.</li> <li>Run the following command (make sure there is no github.properties file present in the directory):   <pre><code>make build\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#corda-simple-application-and-client-application","title":"Corda Simple Application and Client (Application)","text":"<p>This is a simple CorDapp that maintains a state of type <code>SimpleState</code>, which is a set of key-value pairs (of strings). The code for this lies in the <code>weaver/samples/corda/corda-simple-application</code> folder.</p> <p>Build the <code>corda-simple-application</code> CorDapp as follows:</p> <ul> <li>Navigate to the <code>weaver/samples/corda/corda-simple-application</code> folder.</li> <li>Run the following:   <pre><code>make build-local\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#corda-network","title":"Corda Network","text":"<p>The Corda networks' code lies in the <code>weaver/tests/network-setups/corda</code> folder. You can launch two separate Corda networks, namely <code>Corda_Network</code> and <code>Corda_Network2</code>. Each network runs the <code>weaver/samples/corda/corda-simple-application</code> CorDapp by default, which maintains a state named <code>SimpleState</code> containing a set of key-value pairs (of strings).</p> <p>Follow the instructions below to build and launch both networks:</p> <ul> <li>Navigate to the <code>weaver/tests/network-setups/corda</code> folder.</li> <li>To spin up the Corda networks with the Interoperation CorDapps:<ul> <li>Each consisting of 1 node and a notary (for data-transfer), run:   <pre><code>make start-local\n</code></pre></li> <li>Each consisting of 2 nodes and a notary (for asset-exchange/transfer), run:   <pre><code>make start-local PROFILE=\"2-nodes\"\n</code></pre></li> <li>Each consisting of 3 nodes and a notary (for asset-exchange/transfer), run:   <pre><code>make start-local PROFILE=\"3-nodes\"\n</code></pre></li> </ul> </li> </ul> Notes If you do not wish to test Corda-Corda interoperation, you can choose to launch only one of the two networks along with its interoperation CorDapp. For <code>Corda_Network</code>, run <code>make start-network1-local</code>, and for <code>Corda_Network2</code>, run <code>make start-network2-local</code>. <p>You should see the following message in the terminal: <pre><code>Waiting for network node services to start\n</code></pre> The Corda nodes and notary may take a while (several minutes on memory-constrained systems) to start. If they start up successfully, you should something like the following for each network, though the number of node entries will depend on the profile you used to start the network with (replace <code>&lt;network-name&gt;</code> with <code>Corda_Network</code> or <code>Corda_Network2</code>): <pre><code>PartyA node services started for network &lt;network-name&gt;\nPartyB node services started for network &lt;network-name&gt;\nPartyC node services started for network &lt;network-name&gt;\nNotary node services started for network &lt;network-name&gt;\n</code></pre></p>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#corda-relay","title":"Corda Relay","text":"<p>Navigate to the <code>weaver/core/relay</code> folder. Refer here to build the relay image if not already built. Now run a relay for <code>Corda_Network</code> and/or <code>Corda_Network2</code> in Docker container as follows:</p> <ul> <li>The <code>docker-compose.yaml</code> in this folder is minimally configured with default values. To modify it for use with the Fabric testnets, run:   <pre><code>make convert-compose-method2\n</code></pre></li> <li>The <code>.env.corda</code> and <code>.env.corda.tls</code> files in the <code>docker/testnet-envs</code> directory contain environment variables used by the <code>Corda_Network</code> relay at startup and runtime. Edit either of these files (depending on whether you wish to start the relay with or without TLS), and update the following value:   <pre><code>DOCKER_IMAGE_NAME=cacti-weaver-relay-server\n</code></pre></li> <li>Repeat the above step for <code>.env.corda2</code> or <code>.env.corda2.tls</code> in <code>docker/testnet-envs</code> directory, which contain environment variables for the <code>Corda_Network2</code> relay.</li> <li>To deploy the relay server for <code>Corda_Network</code> without TLS, run:   <pre><code>make start-server COMPOSE_ARG='--env-file docker/testnet-envs/.env.corda'\n</code></pre>   Instead, to deploy the relay server with TLS, run:   <pre><code>make start-server COMPOSE_ARG='--env-file docker/testnet-envs/.env.corda.tls'\n</code></pre></li> <li>To deploy the relay server for <code>Corda_Network2</code> without TLS, run:   <pre><code>make start-server COMPOSE_ARG='--env-file docker/testnet-envs/.env.corda2'\n</code></pre>   Instead, to deploy the relay server with TLS, run:   <pre><code>make start-server COMPOSE_ARG='--env-file docker/testnet-envs/.env.corda2.tls'\n</code></pre></li> <li>After launching the relay(s), you can revert the <code>docker-compose.yaml</code> changes by running:   <pre><code>make convert-compose-method1\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#corda-driver","title":"Corda Driver","text":"<p>Navigate to the <code>weaver/core/drivers/corda-driver</code> folder.</p>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#building_2","title":"Building","text":"<p>To build the corda driver docker image, run: <pre><code>make image-local\n</code></pre></p>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#deployment_3","title":"Deployment","text":"<p>Use the following steps to run Corda drivers in Docker containers:</p> <ul> <li>The <code>.env.corda</code> and <code>.env.corda.tls</code> files in the <code>docker-testnet-envs</code> directory contain environment variables used by the <code>Corda_Network</code> driver at startup and runtime. Edit either of these files (depending on whether you wish to start the relay with or without TLS) to update the following value:   <pre><code>DOCKER_IMAGE_NAME=cacti-weaver-driver-corda\n</code></pre></li> <li>Repeat the above steps for <code>.env.corda2</code> or <code>.env.corda2.tls</code> in <code>docker-testnet-envs</code> directory, which contain environment variables for the <code>Corda_Network2</code> driver.</li> <li>To deploy the Corda driver for <code>Corda_Network</code> without TLS, run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet-envs/.env.corda'\n</code></pre>   Instead, to deploy the driver with TLS, run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet-envs/.env.corda.tls'\n</code></pre>   If the driver starts successfully, it should log the following message when you run <code>docker logs driver-corda-Corda_Network</code>:   <pre><code>Corda driver gRPC server started. Listening on port 9099\n</code></pre></li> <li>To deploy the Corda driver for <code>Corda_Network2</code> without TLS, run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet-envs/.env.corda2'\n</code></pre>   Instead, to deploy the driver with TLS, run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet-envs/.env.corda2.tls'\n</code></pre>   If the driver starts successfully, it should log the following message when you run <code>docker logs driver-corda-Corda_Network2</code>:   <pre><code>Corda driver gRPC server started. Listening on port 9098\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#tear-down-the-setup","title":"Tear Down the Setup","text":"<p>Bring down the various components as follows (Navigate to the <code>weaver</code> folder of your clone of the Cacti repository):</p>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#relay","title":"Relay","text":"<p>To bring down the relays (for all 3 networks), run: <pre><code>cd core/relay\nmake convert-compose-method2\nmake stop COMPOSE_ARG='--env-file .env.n1'\nmake stop COMPOSE_ARG='--env-file .env.n2'\nmake stop COMPOSE_ARG='--env-file .env.corda'\nmake stop COMPOSE_ARG='--env-file .env.corda2'\nmake convert-compose-method1\ncd -\n</code></pre></p>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#fabric-driver_1","title":"Fabric Driver","text":"<p>To bring down the fabric drivers (for both networks), run: <pre><code>cd core/drivers/fabric-driver\nmake stop COMPOSE_ARG='--env-file .env.n1'\nmake stop COMPOSE_ARG='--env-file .env.n2'\ncd -\n</code></pre></p>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#corda-driver_1","title":"Corda Driver","text":"<p>To bring down the corda driver, run: <pre><code>cd core/drivers/corda-driver\nmake stop COMPOSE_ARG='--env-file docker-testnet-envs/.env.corda'\nmake stop COMPOSE_ARG='--env-file docker-testnet-envs/.env.corda2'\ncd -\n</code></pre></p>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#corda-network_1","title":"Corda Network","text":"<p>To bring down the Corda network: <pre><code>cd tests/network-setups/corda\nmake clean\ncd -\n</code></pre></p>"},{"location":"weaver/getting-started/test-network/setup-local-docker/#fabric-network_1","title":"Fabric Network","text":"<p>To bring down both of the Fabric networks along with weaver components: <pre><code>cd tests/network-setups/fabric/dev\nmake clean\ncd -\n</code></pre></p>"},{"location":"weaver/getting-started/test-network/setup-local/","title":"Setup with Locally Built Weaver Components","text":"<p>In this document, we detail the steps using which you can bring up networks using the default configuration settings and by building Weaver interoperation modules, SDK libraries, and relay drivers locally from your Cacti clone. To customize these settings (e.g., hostnames, ports), refer to the Advanced Configuration page.</p> Notes The default configuration is for a development setup, therefore all components are run on <code>localhost</code>, many within Docker containers. <p>Follow the instructions below to build and run components followed by interoperation flows. These instructions have been tested on Ubuntu Linux (bash shell) and Mac OS. In general, they should work on any system and shell as long as the various dependenices have been installed and configured.</p>"},{"location":"weaver/getting-started/test-network/setup-local/#prerequisites","title":"Prerequisites","text":""},{"location":"weaver/getting-started/test-network/setup-local/#software","title":"Software","text":"<p>Before starting, make sure you have the following software installed on your host machine:</p> <ul> <li>OpenSSL: install using package manager, like <code>apt</code> on Debian/Ubuntu Linux (specifically packages <code>openssl</code> and <code>libssl-dev</code>)</li> <li>Curl: install using package manager, like <code>apt</code> on Debian/Ubuntu Linux</li> <li>Git: sample instructions</li> <li>Docker: sample instructions (Latest version)</li> <li>Docker-Compose: sample instructions (Version 2 or higher)</li> <li>Golang: sample instructions (Version 1.16 or higher)</li> <li>Java (JDK and JRE): sample instructions (Version 8)</li> <li>Node.js and NPM: sample instructions (Version 16 Supported)</li> <li>Yarn: sample instructions</li> <li>Rust: sample instructions</li> <li>Protoc (Protobuf compiler): Golang should already be installed and configured.<ul> <li>Default method: Run the following with <code>sudo</code> if necessary. This will install both the protobuf compiler and the Go code generator plugins.   <pre><code>apt-get install protobuf-compiler\ngo install google.golang.org/protobuf/cmd/protoc-gen-go\ngo install google.golang.org/grpc/cmd/protoc-gen-go-grpc\n</code></pre></li> <li>If the above method installs an older version of <code>protoc</code> (check using <code>protoc --version</code>), say below 3.12.x, you should download pre-compiled binaries instead. (With an older version, you may see errors while attempting to launch and setup the Fabric networks).   <pre><code>sudo apt-get remove protobuf-compiler\ncurl -LO https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-linux-x86_64.zip\nsudo apt-get install unzip\nunzip protoc-3.15.6-linux-x86_64.zip -d &lt;some-folder-path&gt;\nexport PATH=\"$PATH:&lt;some-folder-path&gt;/bin\"\ngo install google.golang.org/protobuf/cmd/protoc-gen-go\ngo install google.golang.org/grpc/cmd/protoc-gen-go-grpc\n</code></pre></li> </ul> </li> <li> <p>SQLite3 Library:</p> <ul> <li>Sample instruction for Ubuntu:   <pre><code>apt-get install sqlite3 libsqlite3-dev\n</code></pre></li> </ul> Notes The latest version at present is <code>3.15.6</code>, but you should check the above link to find the most current version before running the above steps. </li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local/#credentials","title":"Credentials","text":"<p>Make sure you have an SSH or GPG key registered in https://github.com to allow seamless cloning of repositories (at present, various setup scripts clone repositories using the <code>https://</code> prefix but this may change to <code>git@</code> in the future).</p>"},{"location":"weaver/getting-started/test-network/setup-local/#getting-the-code-and-documentation","title":"Getting the Code and Documentation","text":"<p>Clone the cacti repository. The code to get a basic test network up and running and test data-sharing interoperation flows lies in the subfolder <code>weaver/tests/network-setups</code>, which should be your starting point, though the setups will rely on other parts of the repository, as you will find out in the instructions given on this page.</p>"},{"location":"weaver/getting-started/test-network/setup-local/#common-structures","title":"Common Structures","text":"<p>The <code>weaver/common/protos</code> folder contains structure definitions in the protobuf format that are used by all the different components. The various <code>weaver/common/protos-*</code> folders are meant to contain compiled protobufs (in different languages).</p> <p>To compile the protobufs for JavaScript, do the following:</p> <ul> <li>Navigate to the <code>weaver/common/protos-js</code> folder.</li> <li>Run the following command:   <pre><code>make build\n</code></pre></li> </ul> <p>To compile the protobufs for Golang, do the following:</p> <ul> <li>Navigate to the <code>weaver/common/protos-go</code> folder.</li> <li>Run the following command:   <pre><code>make build\n</code></pre></li> </ul> <p>To compile the protobufs for Java and Kotlin, do the following:</p> <ul> <li>Navigate to the <code>weaver/common/protos-java-kt</code> folder.</li> <li>Run the following command:   <pre><code>make build\n</code></pre></li> </ul> <p>To compile the protobufs for Solidity, do the following:</p> <ul> <li>Navigate to the <code>weaver/common/protos-sol</code> folder.</li> <li>Run the following command:   <pre><code>make build\n</code></pre></li> </ul> <p>To compile the protobufs for Rust, do the following:</p> <ul> <li>Navigate to the <code>weaver/common/protos-rs</code> folder.</li> <li>Run the following command:   <pre><code>make build\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local/#securing-components","title":"Securing Components","text":"Notes The relays and drivers corresponding to the different test networks you will encounter below can be run with or without TLS enabled. But the default files used in the demonstrations assume that either all relays and drivers are TLS-enabled or none are. Therefore, you should determine at the outset whether or not you wish to run the entire set of components in TLS-enabled mode, and select appropriate commands in the provided instructions."},{"location":"weaver/getting-started/test-network/setup-local/#hyperledger-fabric-components","title":"Hyperledger Fabric Components","text":"<p>Using the sequence of instructions below, you can start two separate Fabric networks, each with a single channel and application contract (chaincode). You can also start an interoperation contract, a relay, and a driver acting on behalf of each network. You can build a Fabric CLI tool with which you can initialize both networks' ledgers with access control policies, foreign networks' security groups (i.e., membership providers' certificate chains), and some sample key-value pairs that can be shared during subsequent interoperation flows.</p>"},{"location":"weaver/getting-started/test-network/setup-local/#fabric-interoperation-node-sdk","title":"Fabric Interoperation Node SDK","text":"<p>A client-layer library (companion to <code>hyperledger/fabric-sdk-node</code>) is defined in the <code>weaver/sdks/fabric/interoperation-node-sdk</code> folder. This contains functions for Fabric Gateway-based applications to exercise interoperation capabilities via relays and also several utility/helper functions. The Fabric-CLI tool, which we will use later, depends on this library.</p> <p>To build the library, do the following:</p> <ul> <li>Navigate to the <code>weaver/sdks/fabric/interoperation-node-sdk</code> folder.</li> <li>Run the following command:   <pre><code>make build-local\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local/#fabric-network","title":"Fabric Network","text":"<p>The code for this lies in the <code>weaver/tests/network-setups</code> folder.</p> <p>This folder contains code to create and launch networks <code>network1</code> and <code>network2</code> of identical specifications:</p> <ul> <li>Network: 1 peer, 1 peer CA, 1 ordering service node, 1 ordering service CA</li> <li>Single channel named <code>mychannel</code></li> <li>One of the following contracts deployed on <code>mychannel</code>, the choice depending on the interoperability mode you wish to test:<ul> <li><code>simplestate</code> (Data Sharing): supports simple transactions (<code>Create</code>, <code>Read</code>, <code>Update</code>, <code>Delete</code>) involving storage and lookup of  pairs. <li><code>simplestatewithacl</code> (Data Sharing): identical to <code>simplestate</code> but with extra security features to ensure that the Weaver infrastructure cannot be bypassed by a malicious client of the network.</li> <li><code>simpleasset</code> (Asset Exchange): supports creation, modification, transfer, and deletion, as well as locking, unlocking, and claiming, of simple bonds and tokens (examples of non-fungible and fungible assets respectively).</li> <li><code>simpleassetandinterop</code> (Asset Exchange): identical to <code>simpleasset</code> but where the locking, unlocking, and claiming logic is imported as a library in the chaincode rather than available in the common Fabric Interoperation Chaincode (a Weaver component).</li> <li><code>simpleassettransfer</code> (Asset Exchange or Asset Transfer): augmentation of <code>simpleasset</code> with asset pledging, claiming, and reclaiming features for cross-network transfers.</li> Notes For new users, we recommend testing the Data Sharing feature first with the <code>simplestate</code> contract. To test the other modes, you can simply tear down the Fabric networks and restart them with the appropriate chaincodes installed. <p>Follow the instructions below to build and launch the networks:</p> <ul> <li>Navigate to the <code>weaver/tests/network-setups/fabric/dev</code> folder.</li> <li>To spin up both network1 and network2 with the interoperation chaincode and the default <code>simplestate</code> chaincode installed, run:   <pre><code>make start-interop-local\n</code></pre></li> <li>To launch the networks with a different application chaincode from the above list, run:   <pre><code>make start-interop-local CHAINCODE_NAME=&lt;chaincode-name&gt;\n</code></pre></li> <li>To launch the networks with 2 organizations, each with a peer (this will enable more variation and experimentation, which you can attempt after testing interoperation protocols across basic network configurations), run:   <pre><code>make start-interop-local PROFILE=\"2-nodes\"\n</code></pre></li> </ul> Notes If you do not wish to test Fabric-Fabric interoperation, you can choose to launch only one of the two networks along with its interoperation chaincode. For <code>network1</code>, run <code>make start-interop-network1-local</code>, and for <code>network2</code>, run <code>make start-interop-network2-local</code> If you wish to enable end-to-end confidentiality by default in the interoperation modules that are deployed during network launch, set the environment variable <code>E2E_CONFIDENTIALITY</code> to <code>true</code> in the command line as follows: <code>E2E_CONFIDENTIALITY=true make start-interop-local</code> <p>For more information, refer to the associated README.</p> <p>Troubleshooting Tips:</p> <ul> <li>If you see any errors during the launches, re-check the prerequisites (software installations and credentials). Ensure your network connection is working. As a safe bet, you can retry after cleanup: kill and remove all Docker containers and associated volumes.</li> <li>If <code>protoc</code> or <code>protoc-gen-go</code> throws an error, reinstall <code>protoc</code> and <code>protoc-gen-go</code> using suggestions made in the Prerequisites section above.</li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local/#fabric-client-fabric-cli","title":"Fabric Client (fabric-cli)","text":"<p>The CLI is used to interact with a Fabric network, configure it and run chaincode transactions to record data on the channel ledger or query data. It is also used to interact with remote networks through the relay to trigger an interoperation flow for data request and acceptance.</p> <p>The <code>fabric-cli</code> Node.js source code is located in the <code>weaver/samples/fabric/fabric-cli</code> folder and the Golang source code in the <code>weaver/samples/fabric/go-cli</code> folder.</p>"},{"location":"weaver/getting-started/test-network/setup-local/#prerequisites_1","title":"Prerequisites","text":"<p>If you are using a Linux system, make sure that lib64 is installed.</p> Notes For the Node.js version of the <code>fabric-cli</code>, the setup and running instructions below were tested with all Node.js versions from v11.14.0 to v14.17.3."},{"location":"weaver/getting-started/test-network/setup-local/#installation","title":"Installation","text":"<p>You can install <code>fabric-cli</code> as follows (for both the Node.js and Golang versions):</p> <ul> <li>Navigate to the <code>weaver/samples/fabric/fabric-cli</code> folder (for the Node.js version) or the <code>weaver/samples/fabric/go-cli</code> (for the Golang version) folder.</li> <li>Run the following to install dependencies (for the Node.js version) or the executable (for the Golang version):   <pre><code>make build-local\n</code></pre></li> <li>Use the <code>fabric-cli</code> executable in the <code>bin</code> folder for subsequent actions.</li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local/#fabric-relay","title":"Fabric Relay","text":"<p>The relay is a module acting on behalf of a network, enabling interoperation flows with other networks by communicating with their relays. The code for this lies in the <code>weaver/core/relay</code> folder.</p>"},{"location":"weaver/getting-started/test-network/setup-local/#building","title":"Building","text":"<p>Prerequisite: make sure Rust is already installed and that the <code>cargo</code> executable is in your system path (after installation of Rust, this should be available in <code>$HOME/.cargo/bin</code>); you can also ensure this by running <code>source \"$HOME/.cargo/env\"</code>.</p> <p>Build the generic (i.e., common to all DLTs) relay module as follows:</p> <ul> <li>Navigate to the <code>weaver/core/relay</code> folder.</li> <li>Run the following:   <pre><code>make\n</code></pre></li> <li>If you observe errors during the above compilation, update certain packages (on which the Weaver Relay is dependent) to their latest versions and recompile as follows:   <pre><code>make update-pkgs\nmake\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local/#deployment","title":"Deployment","text":"<p>An instance or a relay can be run using a suitable configuration file. Samples are available in the <code>weaver/core/relay/config</code> folder.</p> <p>Run a relay for <code>network1</code> as follows:</p> <ul> <li>Navigate to the <code>weaver/core/relay</code> folder.</li> <li>To launch the server without TLS, leave the configuration file <code>config/Fabric_Relay.toml</code> in its default state. Otherwise, edit it to set TLS flags for this relay and the other relays and drivers it will connect to in this demonstration as follows:   <pre><code>.\n.\ncert_path=\"credentials/fabric_cert.pem\"\nkey_path=\"credentials/fabric_key\"\ntls=true\n.\n.\n[relays]\n[relays.Corda_Relay]\nhostname=\"localhost\"\nport=\"9081\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n[relays.Corda_Relay2]\nhostname=\"localhost\"\nport=\"9082\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n[relays.Fabric_Relay2]\nhostname=\"localhost\"\nport=\"9083\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n.\n.\n[drivers]\n[drivers.Fabric]\nhostname=\"localhost\"\nport=\"9090\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n.\n.\n</code></pre></li> <li>To launch the server, simply run the following:   <pre><code>RELAY_CONFIG=config/Fabric_Relay.toml cargo run --bin server\n</code></pre></li> </ul> <p>Run a relay for <code>network2</code> as follows (do this only if you have launched both Fabric networks <code>network1</code> and <code>network2</code> and wish to test interoperation between them)</p> <ul> <li>Navigate to the <code>weaver/core/relay</code> folder.</li> <li>To launch the server without TLS, leave the configuration file <code>config/Fabric_Relay2.toml</code> in its default state. Otherwise, edit it to set TLS flags for this relay and the other relays and drivers it will connect to in this demonstration as follows:   <pre><code>.\n.\ncert_path=\"credentials/fabric_cert.pem\"\nkey_path=\"credentials/fabric_key\"\ntls=true\n.\n.\n[relays]\n[relays.Corda_Relay]\nhostname=\"localhost\"\nport=\"9081\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n[relays.Corda_Relay2]\nhostname=\"localhost\"\nport=\"9082\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n[relays.Fabric_Relay]\nhostname=\"localhost\"\nport=\"9080\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n.\n.\n[drivers]\n[drivers.Fabric]\nhostname=\"localhost\"\nport=\"9095\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n.\n.\n</code></pre></li> <li>To launch the server, simply run the following:   <pre><code>RELAY_CONFIG=config/Fabric_Relay2.toml cargo run --bin server\n</code></pre></li> </ul> <p>For more information, see the relay README.</p>"},{"location":"weaver/getting-started/test-network/setup-local/#fabric-driver","title":"Fabric Driver","text":"<p>A driver is a DLT-specific plugin invoked by the relay while conveying external data queries to the local peer network and collecting a response with proofs. The Fabric driver is built as a Fabric client application on the <code>fabric-network</code> NPM package. The code for this lies in the <code>weaver/core/drivers/fabric-driver</code> folder.</p>"},{"location":"weaver/getting-started/test-network/setup-local/#configuring","title":"Configuring","text":"<p>In the <code>weaver/core/drivers/fabric-driver</code> folder, copy <code>.env.template</code> to <code>.env</code> and update <code>CONNECTION_PROFILE</code> to point to the connection profile of the Fabric network (e.g. <code>&lt;PATH-TO-WEAVER&gt;/tests/network-setups/fabric/shared/network1/peerOrganizations/org1.network1.com/connection-org1.json</code>)</p> <p>Configure <code>fabric-driver</code> for <code>network1</code> as follows:</p> <ul> <li>Navigate to the <code>weaver/core/drivers/fabric-driver</code> folder.</li> <li>Create a <code>.env</code> file by copying <code>.env.template</code> and setting suitable parameter values:<ul> <li>The <code>CONNECTION_PROFILE</code> should point to the absolute path of the connection profile for <code>network1</code>.<ul> <li>For this exercise, specify the path <code>&lt;PATH-TO-WEAVER&gt;/tests/network-setups/fabric/shared/network1/peerOrganizations/org1.network1.com/connection-org1.json</code> (you must specify the full absolute path here).</li> <li><code>&lt;PATH-TO-WEAVER&gt;</code> here is the absolute path of the <code>weaver</code> folder within your Cacti repository clone.</li> </ul> </li> <li>If you wish to start the driver without TLS, set the following parameter values:   <pre><code>RELAY_TLS=false\nRELAY_TLSCA_CERT_PATH=\nDRIVER_TLS=false\nDRIVER_TLS_CERT_PATH=\nDRIVER_TLS_KEY_PATH=\n</code></pre>   Otherwise, if you wish to start the driver with TLS enabled, set the following parameter values (replace <code>&lt;PATH-TO-WEAVER&gt;</code> with the absolute path of the <code>weaver</code> folder within your Cacti repository clone):   <pre><code>RELAY_TLS=true\nRELAY_TLSCA_CERT_PATH=&lt;PATH-TO-WEAVER&gt;/core/relay/credentials/fabric_ca_cert.pem\nDRIVER_TLS=true\nDRIVER_TLS_CERT_PATH=&lt;PATH-TO-WEAVER&gt;/core/relay/credentials/fabric_cert.pem\nDRIVER_TLS_KEY_PATH=&lt;PATH-TO-WEAVER&gt;/core/relay/credentials/fabric_key\n</code></pre></li> <li>Leave the default values unchanged for the other parameters. The relay and driver endpoints as well as the network name are already specified in the template.</li> </ul> </li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local/#building_1","title":"Building","text":"<p>Build the Fabric driver module as follows:</p> <ul> <li>Navigate to the <code>weaver/core/drivers/fabric-driver</code> folder.</li> <li>Run the following:   <pre><code>make build-local\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local/#running","title":"Running","text":"<p>Run a Fabric driver for <code>network1</code> as follows:</p> <ul> <li>Navigate to the <code>weaver/core/drivers/fabric-driver</code> folder.</li> <li>Run the following:   <pre><code>npm run dev\n</code></pre></li> </ul> <p>Run a Fabric driver for <code>network2</code> as follows (do this only if you wish to test interoperation between the two Fabric networks <code>network1</code> and <code>network2</code>)</p> <ul> <li>Navigate to the <code>weaver/core/drivers/fabric-driver</code> folder.</li> <li>Run the following (replace <code>&lt;PATH-TO-WEAVER&gt;</code> with the absolute path of the <code>weaver</code> folder within your Cacti repository clone):   <pre><code>CONNECTION_PROFILE=&lt;PATH-TO-WEAVER&gt;/tests/network-setups/fabric/shared/network2/peerOrganizations/org1.network2.com/connection-org1.json NETWORK_NAME=network2 RELAY_ENDPOINT=localhost:9083 DRIVER_ENDPOINT=localhost:9095 npm run dev\n</code></pre></li> </ul> Notes The variables we specified earlier in the <code>.env</code> for <code>network1</code> are now passed in the command line. Alternatively, you can make a copy of the <code>fabric-driver</code> folder with a different  name and create a separate <code>.env</code> file within it that contains links to the connection profile, relay, and driver for <code>network2</code>."},{"location":"weaver/getting-started/test-network/setup-local/#fabric-iin-agent","title":"Fabric IIN Agent","text":"<p>IIN Agent is a client of a member of a DLT network or security domain with special permissions to update security domain identities and configurations on the ledger via the network's interoperation module. The code for this lies in the <code>weaver/core/identity-management/iin-agent</code> folder. Navigate to the <code>weaver/core/identity-management/iin-agent</code> folder.</p>"},{"location":"weaver/getting-started/test-network/setup-local/#building_2","title":"Building","text":"<p>To build the IIN Agent, run: <pre><code>make build-local\n</code></pre></p>"},{"location":"weaver/getting-started/test-network/setup-local/#configuration","title":"Configuration","text":"<p>Ledger config file specifies ledger specific IIN Agent details such as identity and which network and organization to connect to.</p> <ol> <li>To create config file for <code>Org1MSP</code>'s Fabric IIN Agent of <code>network1</code>, follow the steps:<ul> <li>Create copy of template config file for Fabric IIN Agent: <code>src/fabric-ledger/config.json.template</code>, say to location <code>src/fabric-ledger/config-n1-org1.json</code>.</li> <li>Replace <code>&lt;path-to-connection-profile&gt;</code> with <code>&lt;PATH-TO-WEAVER&gt;/tests/network-setups/fabric/shared/network1/peerOrganizations/org1.network1.com/connection-org1.json</code>, where <code>&lt;PATH-TO-WEAVER&gt;</code> should be substituted with the absolute path of the <code>weaver</code> folder within your Cacti repository clone.</li> <li>Set <code>mspId</code> as <code>Org1MSP</code>.</li> <li>Set <code>agent.affiliation</code> as <code>org1.department1</code>.</li> </ul> </li> <li>To create config file for <code>Org2MSP</code>'s Fabric IIN Agent of <code>network1</code>, repeat <code>Step 1</code> with different name for config file, say <code>src/fabric-ledger/config-n1-org2.json</code>, and replace <code>org1</code> with <code>org2</code> and <code>Org1MSP</code> with <code>Org2MSP</code>.</li> <li>To create config file for <code>Org1MSP</code>'s Fabric IIN Agent of <code>network2</code>, repeat <code>Step 1</code> with different name for config file, say <code>src/fabric-ledger/config-n2-org1.json</code>, and replace <code>network1</code> with <code>network2</code>.</li> <li>To create config file for <code>Org2MSP</code>'s Fabric IIN Agent of <code>network2</code>, repeat <code>Step 1</code> with different name for config file, say <code>src/fabric-ledger/config-n2-org2.json</code>, and replace <code>network1</code> with <code>network2</code>, <code>org1</code> with <code>org2</code> and <code>Org1MSP</code> with <code>Org2MSP</code>.</li> </ol>"},{"location":"weaver/getting-started/test-network/setup-local/#security-domain-configuration","title":"Security Domain Configuration","text":"<p>Security Domain config file specifies the scope of security domain, which can be a channel in Fabric networks or list of nodes. File <code>docker-testnet/configs/security-domain-config.json</code> can be used for Weaver testnets.</p>"},{"location":"weaver/getting-started/test-network/setup-local/#dns-configuration","title":"DNS Configuration","text":"<p>To allow an IIN Agent's to be able to discover other IIN Agents, a config file for DNS is required. Create one <code>dnsconfig.json</code> by creating a copy of template <code>dnsconfig.json.template</code>, and replace the values with:</p> <ul> <li> <p>If Fabric networks are started with 1 org, and IIN Agent are to be started without TLS, use following values: <pre><code>{\n    \"network1\": {\n        \"Org1MSP\": {\n            \"endpoint\": \"localhost:9500\",\n            \"tls\": false,\n            \"tlsCACertPath\": \"\"\n        }\n    },\n    \"network2\": {\n        \"Org1MSP\": {\n            \"endpoint\": \"localhost:9501\",\n            \"tls\": false,\n            \"tlsCACertPath\": \"\"\n        }\n    }\n}\n</code></pre></p> </li> <li> <p>If Fabric networks are started with 1 org, and IIN Agent are to be started with TLS, use following values: <pre><code>{\n    \"network1\": {\n        \"Org1MSP\": {\n            \"endpoint\": \"localhost:9500\",\n            \"tls\": true,\n            \"tlsCACertPath\": \"../../relay/credentials/fabric_ca_cert.pem\"\n        }\n    },\n    \"network2\": {\n        \"Org1MSP\": {\n            \"endpoint\": \"localhost:9501\",\n            \"tls\": true,\n            \"tlsCACertPath\": \"../../relay/credentials/fabric_ca_cert.pem\"\n        }\n    }\n}\n</code></pre></p> </li> <li> <p>If Fabric networks are started with 2 orgs, and IIN Agent are to be started without TLS, use following values: <pre><code>{\n    \"network1\": {\n        \"Org1MSP\": {\n            \"endpoint\": \"localhost:9500\",\n            \"tls\": false,\n            \"tlsCACertPath\": \"\"\n        },\n        \"Org2MSP\": {\n            \"endpoint\": \"localhost:9510\",\n            \"tls\": false,\n            \"tlsCACertPath\": \"\"\n        }\n    },\n    \"network2\": {\n        \"Org1MSP\": {\n            \"endpoint\": \"localhost:9501\",\n            \"tls\": false,\n            \"tlsCACertPath\": \"\"\n        },\n        \"Org2MSP\": {\n            \"endpoint\": \"localhost:9511\",\n            \"tls\": false,\n            \"tlsCACertPath\": \"\"\n        }\n    }\n}\n</code></pre></p> </li> <li> <p>If Fabric networks are started with 2 orgs, and IIN Agent are to be started with TLS, use following values: <pre><code>{\n    \"network1\": {\n        \"Org1MSP\": {\n            \"endpoint\": \"localhost:9500\",\n            \"tls\": true,\n            \"tlsCACertPath\": \"../../relay/credentials/fabric_ca_cert.pem\"\n        },\n        \"Org2MSP\": {\n            \"endpoint\": \"localhost:9510\",\n            \"tls\": true,\n            \"tlsCACertPath\": \"../../relay/credentials/fabric_ca_cert.pem\"\n        }\n    },\n    \"network2\": {\n        \"Org1MSP\": {\n            \"endpoint\": \"localhost:9501\",\n            \"tls\": true,\n            \"tlsCACertPath\": \"../../relay/credentials/fabric_ca_cert.pem\"\n        },\n        \"Org2MSP\": {\n            \"endpoint\": \"localhost:9511\",\n            \"tls\": true,\n            \"tlsCACertPath\": \"../../relay/credentials/fabric_ca_cert.pem\"\n        }\n    }\n}\n</code></pre></p> </li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local/#environment-variables","title":"Environment Variables","text":"<p>To configure environment variables for <code>Org1MSP</code>'s Fabric IIN Agent of <code>network1</code>, follow the steps:</p> <ol> <li>Create a copy of <code>.env.template</code> as <code>.env</code>, and update following values based on previous configuration file paths: <pre><code>IIN_AGENT_ENDPOINT=localhost:9500\nMEMBER_ID=Org1MSP\nSECURITY_DOMAIN=network1\nDLT_TYPE=fabric\nCONFIG_PATH=./src/fabric-ledger/config-n1-org1.json\nDNS_CONFIG_PATH=./dnsconfig.json\nSECURITY_DOMAIN_CONFIG_PATH=./docker-testnet/configs/security-domain-config.json\nWEAVER_CONTRACT_ID=interop\nAUTO_SYNC=true\n</code></pre></li> <li>If IIN Agent has to be started with TLS enabled, also update following values: <pre><code>IIN_AGENT_TLS=true\nIIN_AGENT_TLS_CERT_PATH=../../relay/credentials/fabric_cert.pem\nIIN_AGENT_TLS_KEY_PATH=../../relay/credentials/fabric_key\n</code></pre></li> </ol>"},{"location":"weaver/getting-started/test-network/setup-local/#deployment_1","title":"Deployment","text":"<p>Use the following steps to run Fabric IIN Agents in host machine:</p> <ul> <li>To start IIN Agent for <code>Org1MSP</code> of <code>network1</code>, run: <pre><code>npm run dev\n</code></pre></li> <li>To start IIN Agent for <code>Org2MSP</code> of <code>network1</code> (only required if Fabric network was started with 2 orgs), run: <pre><code>IIN_AGENT_ENDPOINT=localhost:9510 MEMBER_ID=Org2MSP CONFIG_PATH=./src/fabric-ledger/config-n1-org2.json npm run dev\n</code></pre></li> <li>To start IIN Agent for <code>Org1MSP</code> of <code>network2</code>, run: <pre><code>IIN_AGENT_ENDPOINT=localhost:9501 SECURITY_DOMAIN=network2 CONFIG_PATH=./src/fabric-ledger/config-n2-org1.json npm run dev\n</code></pre></li> <li>To start IIN Agent for <code>Org2MSP</code> of <code>network2</code> (only required if Fabric network was started with 2 orgs), run: <pre><code>IIN_AGENT_ENDPOINT=localhost:9511 MEMBER_ID=Org2MSP SECURITY_DOMAIN=network2 CONFIG_PATH=./src/fabric-ledger/config-n2-org2.json npm run dev\n</code></pre></li> </ul> Notes The variables we specified earlier in the <code>.env</code> for <code>network1</code> are now passed in the command line. Alternatively, you can make a copy of the <code>fabric-driver</code> folder with a different  name and create a separate <code>.env</code> file within it that contains links to the connection profile, relay, and driver for <code>network2</code>."},{"location":"weaver/getting-started/test-network/setup-local/#corda-components","title":"Corda Components","text":"<p>Using the sequence of instructions below, you can start a Corda network and run an application CorDapp on it. You can also run an interoperation CorDapp, a relay and a driver acting on behalf of the network. You can initialize the network's vault with access control policies, foreign networks' security groups (i.e., membership providers' certificate chains), and some sample state values that can be shared during subsequent interoperation flows.</p>"},{"location":"weaver/getting-started/test-network/setup-local/#interoperation-cordapp","title":"Interoperation CorDapp","text":"<p>The interoperation CorDapp is deployed to run as part of any Corda application flow that involves cross-network interoperation.</p> <p>Build the interoperation CorDapp as follows:</p> <ul> <li>Navigate to the <code>weaver/core/network/corda-interop-app</code> folder.</li> <li>Run the following to create the JAR files on which other Corda network components will depend on:   <pre><code>make build-local\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local/#corda-interoperation-sdk","title":"Corda Interoperation SDK","text":"<p>A client-layer library is defined in the <code>weaver/sdks/corda</code> folder. This contains functions for Corda based client applications to exercise interoperation capabilities via relays and also several utility/helper functions. The Corda Client tool, which we will use later, depends on this library.</p> <p>To build the library, do the following:</p> <ul> <li>Navigate to the <code>weaver/sdks/corda</code> folder.</li> <li>Run the following command (make sure there is no github.properties file present in the directory):   <pre><code>make build\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local/#corda-simple-application-and-client-application","title":"Corda Simple Application and Client (Application)","text":"<p>This is a simple CorDapp that maintains a state of type <code>SimpleState</code>, which is a set of key-value pairs (of strings). The code for this lies in the <code>weaver/samples/corda/corda-simple-application</code> folder.</p> <p>Build the <code>corda-simple-application</code> CorDapp as follows:</p> <ul> <li>Navigate to the <code>weaver/samples/corda/corda-simple-application</code> folder.</li> <li>Run the following:   <pre><code>make build-local\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local/#corda-network","title":"Corda Network","text":"<p>The Corda networks' code lies in the <code>weaver/tests/network-setups/corda</code> folder. You can launch two separate Corda networks, namely <code>Corda_Network</code> and <code>Corda_Network2</code>. Each network runs the <code>weaver/samples/corda/corda-simple-application</code> CorDapp by default, which maintains a state named <code>SimpleState</code> containing a set of key-value pairs (of strings).</p> <p>Follow the instructions below to build and launch both networks:</p> <ul> <li>Navigate to the <code>weaver/tests/network-setups/corda</code> folder.</li> <li>To spin up the Corda networks with the Interoperation CorDapps:<ul> <li>Each consisting of 1 node and a notary (for data-transfer), run:   <pre><code>make start-local\n</code></pre></li> <li>Each consisting of 2 nodes and a notary (for asset-exchange/transfer), run:   <pre><code>make start-local PROFILE=\"2-nodes\"\n</code></pre></li> <li>Each consisting of 3 nodes and a notary (for asset-exchange/transfer), run:   <pre><code>make start-local PROFILE=\"3-nodes\"\n</code></pre></li> </ul> </li> </ul> Notes If you do not wish to test Corda-Corda interoperation, you can choose to launch only one of the two networks along with its interoperation CorDapp. For <code>Corda_Network</code>, run <code>make start-network1-local</code>, and for <code>Corda_Network2</code>, run <code>make start-network2-local</code>. <p>You should see the following message in the terminal: <pre><code>Waiting for network node services to start\n</code></pre> The Corda nodes and notary may take a while (several minutes on memory-constrained systems) to start. If they start up successfully, you should something like the following for each network, though the number of node entries will depend on the profile you used to start the network with (replace <code>&lt;network-name&gt;</code> with <code>Corda_Network</code> or <code>Corda_Network2</code>): <pre><code>PartyA node services started for network &lt;network-name&gt;\nPartyB node services started for network &lt;network-name&gt;\nPartyC node services started for network &lt;network-name&gt;\nNotary node services started for network &lt;network-name&gt;\n</code></pre></p>"},{"location":"weaver/getting-started/test-network/setup-local/#corda-relay","title":"Corda Relay","text":"<p>The relay was built earlier, so you just need to use a different configuration file to start a relay for the Corda network.</p> <p>Run a relay for <code>Corda_Network</code> as follows:</p> <ul> <li>Navigate to the <code>weaver/core/relay</code> folder.</li> <li>(Make sure you've already built the relay by running <code>make</code>.)</li> <li>To launch the server without TLS, leave the configuration file <code>config/Corda_Relay.toml</code> in its default state. Otherwise, edit it to set TLS flags for this relay and the other relays and drivers it will connect to in this demonstration as follows:   <pre><code>.\n.\ncert_path=\"credentials/fabric_cert.pem\"\nkey_path=\"credentials/fabric_key\"\ntls=true\n.\n.\n[relays]\n[relays.Fabric_Relay]\nhostname=\"localhost\"\nport=\"9080\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n[relays.Fabric_Relay2]\nhostname=\"localhost\"\nport=\"9083\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n[relays.Corda_Relay2]\nhostname=\"localhost\"\nport=\"9082\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n.\n.\n[drivers]\n[drivers.Corda]\nhostname=\"localhost\"\nport=\"9099\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n.\n.\n</code></pre></li> <li>To launch the server, simply run the following:   <pre><code>RELAY_CONFIG=config/Corda_Relay.toml cargo run --bin server\n</code></pre></li> </ul> <p>If the relay starts up successfully, the following will be logged on your terminal:</p> <pre><code>Relay Name: \"Corda_Relay\"\nRelayServer listening on [::1]:9081\n</code></pre> <p>Run a relay for <code>Corda_Network2</code> as follows (do this only if you have launched both Corda networks <code>Corda_Network</code> and <code>Corda_Network2</code> and wish to test interoperation between them)</p> <ul> <li>Navigate to the <code>weaver/core/relay</code> folder.</li> <li>To launch the server without TLS, leave the configuration file <code>config/Corda_Relay2.toml</code> in its default state. Otherwise, edit it to set TLS flags for this relay and the other relays and drivers it will connect to in this demonstration as follows:   <pre><code>.\n.\ncert_path=\"credentials/fabric_cert.pem\"\nkey_path=\"credentials/fabric_key\"\ntls=true\n.\n.\n[relays]\n[relays.Fabric_Relay]\nhostname=\"localhost\"\nport=\"9080\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n[relays.Fabric_Relay2]\nhostname=\"localhost\"\nport=\"9083\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n[relays.Corda_Relay]\nhostname=\"localhost\"\nport=\"9081\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n.\n.\n[drivers]\n[drivers.Corda]\nhostname=\"localhost\"\nport=\"9098\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n.\n.\n</code></pre></li> <li>To launch the server, simply run the following:   <pre><code>RELAY_CONFIG=config/Corda_Relay2.toml cargo run --bin server\n</code></pre></li> </ul> <p>If the relay starts up successfully, the following will be logged on your terminal:</p> <pre><code>Relay Name: \"Corda2_Relay\"\nRelayServer listening on [::1]:9082\n</code></pre>"},{"location":"weaver/getting-started/test-network/setup-local/#corda-driver","title":"Corda Driver","text":"<p>The code for this lies in the <code>weaver/core/drivers/corda-driver</code> folder.</p>"},{"location":"weaver/getting-started/test-network/setup-local/#building-corda-driver","title":"Building Corda Driver","text":"<p>Build the Corda driver module as follows:</p> <ul> <li>Navigate to the <code>weaver/core/drivers/corda-driver</code> folder.</li> <li>Run the following:   <pre><code>make build-local\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local/#configuring_1","title":"Configuring","text":"<p>Configure the drivers as follows (you can skip this if you wish to run the drivers without TLS):</p> <ul> <li>Navigate to the <code>weaver/core/drivers/corda-driver</code> folder and create a <code>.env</code> file.</li> <li>To run the drivers without TLS, set the following default values:   <pre><code>RELAY_TLS=false\nRELAY_TLSCA_TRUST_STORE=\nRELAY_TLSCA_TRUST_STORE_PASSWORD=\nRELAY_TLSCA_CERT_PATHS=\n</code></pre></li> <li>To run the drivers with TLS, set the following values (replace <code>&lt;PATH-TO-WEAVER&gt;</code> with the absolute path of the <code>weaver</code> folder within your Cacti repository clone):   <pre><code>RELAY_TLS=true\nRELAY_TLSCA_TRUST_STORE=&lt;PATH-TO-WEAVER&gt;/core/relay/credentials/fabric_trust_store.jks\nRELAY_TLSCA_TRUST_STORE_PASSWORD=trelay\nRELAY_TLSCA_CERT_PATHS=&lt;PATH-TO-WEAVER&gt;/core/relay/credentials/fabric_ca_cert.pem\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local/#running_1","title":"Running","text":"<p>Run a Corda driver as follows:</p> <ul> <li>Navigate to the <code>weaver/core/drivers/corda-driver</code> folder.</li> <li>Run the following to start Corda driver for <code>Corda_Network</code>:   <pre><code>./build/install/driver-corda/bin/driver-corda\n</code></pre>   If the driver starts successfully, it should log the following message on your terminal:   <pre><code>Corda driver gRPC server started. Listening on port 9099\n</code></pre></li> <li>Run the following to start Corda driver for <code>Corda_Network2</code>:   <pre><code>DRIVER_PORT=9098 ./build/install/driver-corda/bin/driver-corda\n</code></pre>   If the driver starts successfully, it should log the following message on your terminal:   <pre><code>Corda driver gRPC server started. Listening on port 9098\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local/#hyperledger-besu-components","title":"Hyperledger Besu Components","text":"<p>Using the sequence of instructions below, you can start two separate Besu networks, each with 4 validator nodes, and EthSigner and application contract. You can also install an interoperation contract in the network. You can build a Besu CLI tool with which you can initialize both networks' ledgers.</p>"},{"location":"weaver/getting-started/test-network/setup-local/#prerequisites_2","title":"Prerequisites","text":"<ul> <li>Java (JDK and JRE): sample instructions (Version 11)   You need to run Besu instructions in a separate environment (separate terminal or machine) than Corda, as Corda requires Java 8. You can also use <code>update-alternatives</code> to switch between java versions.</li> <li>tmux: <code>sudo apt install tmux</code></li> <li>Besu: <ul> <li>Download and unpack the latest https://github.com/hyperledger/besu/releases/latest. You will find it in the link of the form: https://hyperledger.jfrog.io/artifactory/besu-binaries/besu/x.y.z/besu-x.y.z.zip with x.y.z replaced with the version number. For instance, run the following command after updating version number accordingly.   <pre><code>wget https://hyperledger.jfrog.io/artifactory/besu-binaries/besu/21.7.0/besu-21.7.0.zip\n</code></pre></li> <li>Add the path to <code>besu-x.y.z/bin</code> to your system PATH</li> </ul> </li> <li>EthSigner: <ul> <li>Download and unpack the latest from https://cloudsmith.io/~consensys/repos/ethsigner/packages/?q=tag%3Alatest (Requires Java 11 or later)</li> <li>Add the path to <code>ethsigner-x.y.z/bin</code> to your system PATH</li> </ul> </li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local/#besu-interoperation-node-sdk","title":"Besu Interoperation Node SDK","text":"<p>A client-layer library is defined in the <code>weaver/sdks/besu/interoperation-node-sdk</code> folder. This contains functions for Besu web3JS based applications to exercise interoperation capabilities via several utility/helper functions. The Besu-CLI tool, which we will use later, depends on this library.</p> <p>To build the library, do the following:</p> <ul> <li>Navigate to the <code>weaver/sdks/besu/interoperation-node-sdk</code> folder.</li> <li>Run the following command:   <pre><code>make build-local\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local/#besu-network","title":"Besu Network","text":"<p>The code for this lies in the <code>weaver/tests/network-setups/besu</code> folder.</p> <p>This folder contains code to create and launch networks <code>Network1</code> and <code>Network2</code> of identical specifications:</p> <ul> <li>Network: 4 validator nodes, 1 EthSigner node.</li> <li><code>Network1</code> uses <code>8545</code> port for EthSigner while <code>Network2</code> uses <code>9544</code> port for EthSigner.</li> </ul> <p>Follow the instructions below to build and launch the networks:</p> <ul> <li>Navigate to the <code>weaver/tests/network-setups/besu</code> folder.</li> <li>To spin up both Network1 and Network2, run:   <pre><code>make start\n</code></pre></li> </ul> Notes If you do not wish to test Besu-Besu interoperation, you can choose to launch only one of the two networks. For <code>Network1</code>, run <code>make start-network1</code>, and for <code>Network2</code>, run <code>make start-network2</code> <p>For more information, refer to the associated README.</p>"},{"location":"weaver/getting-started/test-network/setup-local/#contracts","title":"Contracts","text":"<ul> <li><code>AssetExchangeContract</code> must be deployed which is present in <code>weaver/core/network/besu/contracts/interop/manageAssetAny.sol</code>. This contract is deployed along with application contract.</li> <li>Application contract <code>simpleasset</code>, located in <code>weaver/samples/besu/simpleasset</code> directory (for Asset Exchange), which supports creation, modification, transfer, and deletion, as well as locking, unlocking, and claiming, of simple <code>AliceERC20</code> and <code>BobERC20</code> tokens (examples of fungible assets), or <code>AliceERC721</code> and <code>BobERC721</code> tokens (example of non-fungible assets), or <code>AliceERC1155</code> and <code>BobERC1155</code> tokens (example of hybrid assets).</li> </ul> <p>To deploy <code>simpleasset</code> with <code>AssetExchangeContract</code> on both Besu networks, navigate to the <code>weaver/samples/besu/simpleasset</code> folder, and run: <pre><code>make deploy-contracts\n</code></pre></p> Notes If you chose to launch only one of the two networks, then for <code>Network1</code>, run <code>make deploy-contract-network1</code>, and for <code>Network2</code>, run <code>deploy-contract-network2</code>"},{"location":"weaver/getting-started/test-network/setup-local/#besu-client-besu-cli","title":"Besu Client (besu-cli)","text":"<p>The CLI is used to interact with a Besu network, configure it and run contract transactions to record data on the ledger or query data.</p> <p>The <code>besu-cli</code> Node.js source code is located in the <code>weaver/samples/besu/besu-cli</code> folder.</p>"},{"location":"weaver/getting-started/test-network/setup-local/#prerequisites_3","title":"Prerequisites","text":"<p>If you are using a Linux system, make sure that lib64 is installed.</p> Notes For the Node.js version of the <code>besu-cli</code>, the setup and running instructions below were tested with all Node.js versions from v11.14.0 to v14.17.3."},{"location":"weaver/getting-started/test-network/setup-local/#installation_1","title":"Installation","text":"<p>You can install <code>besu-cli</code> as follows:</p> <ul> <li>Navigate to the <code>weaver/samples/besu/besu-cli</code> folder.</li> <li>Run the following to install dependencies:   <pre><code>make build-local\n</code></pre></li> <li>Use the <code>besu-cli</code> executable in the <code>bin</code> folder for subsequent actions.</li> </ul>"},{"location":"weaver/getting-started/test-network/setup-local/#tear-down-the-setup","title":"Tear Down the Setup","text":"<p>Bring down the test network's components as follows:</p> <ul> <li>Simply terminate the various relays and drivers, which are running in the foreground in different terminals</li> <li>To bring down the running Corda network:<ul> <li>Navigate to the <code>weaver/tests/network-setups/corda</code> folder.</li> <li>Run the following:   <pre><code>make clean\n</code></pre></li> </ul> </li> <li>To bring down all the running Fabric networks:<ul> <li>Navigate to the <code>weaver/tests/network-setups/fabric/dev</code> folder.</li> <li>Run the following:   <pre><code>make clean\n</code></pre></li> </ul> </li> <li>To bring down all the running Besu networks:<ul> <li>Navigate to the <code>weaver/tests/network-setups/besu</code> folder.</li> <li>Run the following:   <pre><code>make clean\n</code></pre></li> </ul> </li> </ul>"},{"location":"weaver/getting-started/test-network/setup-packages-docker/","title":"Setup with Imported Dockerized Weaver Components","text":"<p>In this document, we detail the steps using which you can bring up networks using the default configuration settings and by fetching pre-built Weaver interoperation modules, SDK libraries, and relay docker image, drivers docker images from GitHub Package repositories. To customize these settings (e.g., hostnames, ports), refer to the Advanced Configuration page.</p> Notes All components are run within Docker containers, except client applications. <p>Follow the instructions below to build and run components followed by interoperation flows. These instructions have been tested on Ubuntu Linux (bash shell) and Mac OS. In general, they should work on any system and shell as long as the various dependencies have been installed and configured.</p>"},{"location":"weaver/getting-started/test-network/setup-packages-docker/#prerequisites","title":"Prerequisites","text":""},{"location":"weaver/getting-started/test-network/setup-packages-docker/#software","title":"Software","text":"<p>Before starting, make sure you have the following software installed on your host machine:</p> <ul> <li>Curl: install using package manager, like <code>apt</code> on Debian/Ubuntu Linux</li> <li>Git: sample instructions</li> <li>Docker: sample instructions (Latest version)</li> <li>Docker-Compose: sample instructions (Version 2 or higher)</li> <li>Golang: sample instructions (Version 1.16 or higher)</li> <li>Java (JDK and JRE): sample instructions (Version 8)</li> <li>Node.js and NPM: sample instructions (Version 11 to Version 16 Supported)</li> <li>Yarn: sample instructions</li> </ul>"},{"location":"weaver/getting-started/test-network/setup-packages-docker/#credentials","title":"Credentials","text":"<p>Make sure you have an SSH or GPG key registered in https://github.com to allow seamless cloning of repositories (at present, various setup scripts clone repositories using the <code>https://</code> prefix but this may change to <code>git@</code> in the future).</p>"},{"location":"weaver/getting-started/test-network/setup-packages-docker/#package-access-token","title":"Package Access Token:","text":"<p>Create a personal access token with <code>read:packages</code> access in GitHub in order to use modules published in GitHub packages. Refer Creating a Personal Access Token for help.</p> <p>Run <code>docker login ghcr.io</code>,  and provide GitHub email id as username and personal access token created above as password. This will allow Docker to fetch images of <code>relay</code>, <code>fabric-driver</code> and <code>corda-driver</code> from <code>hyperledger/cacti</code>.</p>"},{"location":"weaver/getting-started/test-network/setup-packages-docker/#getting-the-code-and-documentation","title":"Getting the Code and Documentation","text":"<p>Clone the cacti repository. The code to get a basic test network up and running and test data-sharing interoperation flows lies in the subfolder <code>weaver/tests/network-setups</code>, which should be your starting point, though the setups will rely on other parts of the repository, as you will find out in the instructions given on this page.</p>"},{"location":"weaver/getting-started/test-network/setup-packages-docker/#securing-components","title":"Securing Components","text":"Notes The relays and drivers corresponding to the different test networks you will encounter below can be run with or without TLS enabled. But the default files used in the demonstrations assume that either all relays and drivers are TLS-enabled or none are. Therefore, you should determine at the outset whether or not you wish to run the entire set of components in TLS-enabled mode, and select appropriate commands in the provided instructions."},{"location":"weaver/getting-started/test-network/setup-packages-docker/#hyperledger-fabric-components","title":"Hyperledger Fabric Components","text":"<p>Using the sequence of instructions below, you can start two separate Fabric networks, each with a single channel and application contract (chaincode). You can also start an interoperation contract, a relay and a driver acting on behalf of each network. You can build a Fabric CLI tool with which you can initialize both networks' ledgers with access control policies, foreign networks' security groups (i.e., membership providers' certificate chains), and some sample key-value pairs that can be shared during subsequent interoperation flows.</p>"},{"location":"weaver/getting-started/test-network/setup-packages-docker/#fabric-network","title":"Fabric Network","text":"<p>The code for this lies in the <code>weaver/tests/network-setups</code> folder.</p> <p>This folder contains code to create and launch networks <code>network1</code> and <code>network2</code> of identical specifications:</p> <ul> <li>Network: 1 peer, 1 peer CA, 1 ordering service node, 1 ordering service CA</li> <li>Single channel named <code>mychannel</code></li> <li>One of the following contracts deployed on <code>mychannel</code>, the choice depending on the interoperability mode you wish to test:<ul> <li><code>simplestate</code> (Data Sharing): supports simple transactions (<code>Create</code>, <code>Read</code>, <code>Update</code>, <code>Delete</code>) involving storage and lookup of  pairs. <li><code>simplestatewithacl</code> (Data Sharing): identical to <code>simplestate</code> but with extra security features to ensure that the Weaver infrastructure cannot be bypassed by a malicious client of the network.</li> <li><code>simpleasset</code> (Asset Exchange): supports creation, modification, transfer, and deletion, as well as locking, unlocking, and claiming, of simple bonds and tokens (examples of non-fungible and fungible assets respectively).</li> <li><code>simpleassetandinterop</code> (Asset Exchange): identical to <code>simpleasset</code> but where the locking, unlocking, and claiming logic is imported as a library in the chaincode rather than available in the common Fabric Interoperation Chaincode (a Weaver component).</li> <li><code>simpleassettransfer</code> (Asset Exchange or Asset Transfer): augmentation of <code>simpleasset</code> with asset pledging, claiming, and reclaiming features for cross-network transfers.</li> Notes For new users, we recommend testing the Data Sharing feature first with the <code>simplestate</code> contract. To test the other modes, you can simply tear down the Fabric networks and restart them with the appropriate chaincodes installed. <p>Follow the instructions below to build and launch the networks:</p> <ul> <li>Navigate to the <code>weaver/tests/network-setups/fabric/dev</code> folder.</li> <li>To spin up both network1 and network2 with the interoperation chaincode and the default <code>simplestate</code> chaincode installed, run:   <pre><code>make start-interop\n</code></pre></li> <li>To launch the networks with a different application chaincode from the above list, run:   <pre><code>make start-interop CHAINCODE_NAME=&lt;chaincode-name&gt;\n</code></pre></li> <li>To launch the networks with 2 organizations, each with a peer (this will enable more variation and experimentation, which you can attempt after testing interoperation protocols across basic network configurations), run:   <pre><code>make start-interop-local PROFILE=\"2-nodes\"\n</code></pre></li> </ul> Notes If you do not wish to test Fabric-Fabric interoperation, you can choose to launch only one of the two networks along with its interoperation chaincode. For <code>network1</code>, run <code>make start-interop-network1</code>, and for <code>network2</code>, run <code>make start-interop-network2</code> If you wish to enable end-to-end confidentiality by default in the interoperation modules that are deployed during network launch, set the environment variable <code>E2E_CONFIDENTIALITY</code> to <code>true</code> in the command line as follows: <code>E2E_CONFIDENTIALITY=true make start-interop</code> <p>For more information, refer to the associated README.</p> <p>Troubleshooting Tips:</p> <ul> <li>If you see any errors during the launches, re-check the prerequisites (software installations and credentials). Ensure your network connection is working. As a safe bet, you can retry after cleanup: kill and remove all Docker containers and associated volumes.</li> </ul>"},{"location":"weaver/getting-started/test-network/setup-packages-docker/#fabric-relay","title":"Fabric Relay","text":"<p>The relay is a module acting on behalf of a network, enabling interoperation flows with other networks by communicating with their relays. The code for this lies in the <code>weaver/core/relay</code> folder.</p> <p>Navigate to the <code>weaver/core/relay</code> folder and run a relay as follows:</p> <ul> <li>The <code>docker-compose.yaml</code> in this folder is minimally configured with default values. To modify it for use with the Fabric testnets, run:   <pre><code>make convert-compose-method2\n</code></pre></li> <li>(The <code>.env.n1</code> and <code>.env.n1.tls</code> files in the <code>docker/testnet-envs</code> directory contain environment variables used by the <code>network1</code> relay at startup and runtime.)</li> <li>(The <code>.env.n2</code> and <code>.env.n2.tls</code> files in the <code>docker/testnet-envs</code> directory contain environment variables used by the <code>network2</code> relay at startup and runtime.)</li> <li>To deploy the relay server for <code>network1</code> without TLS, run:   <pre><code>make start-server COMPOSE_ARG='--env-file docker/testnet-envs/.env.n1'\n</code></pre>   Instead, to deploy the relay server with TLS, run:   <pre><code>make start-server COMPOSE_ARG='--env-file docker/testnet-envs/.env.n1.tls'\n</code></pre></li> <li>To deploy the relay server for <code>network2</code> without TLS, run:   <pre><code>make start-server COMPOSE_ARG='--env-file docker/testnet-envs/.env.n2'\n</code></pre>   Instead, to deploy the relay server with TLS, run:   <pre><code>make start-server COMPOSE_ARG='--env-file docker/testnet-envs/.env.n2.tls'\n</code></pre></li> <li>After launching the relay(s), you can revert the <code>docker-compose.yaml</code> changes by running:   <pre><code>make convert-compose-method1\n</code></pre></li> </ul> <p>For more information, see the relay-docker README.</p>"},{"location":"weaver/getting-started/test-network/setup-packages-docker/#fabric-driver","title":"Fabric Driver","text":"<p>A driver is a DLT-specific plugin invoked by the relay while channelling external data queries to the local peer network and collecting a response with proofs. The Fabric driver is built as a Fabric client application on the <code>fabric-network</code> NPM package. The code for this lies in the <code>weaver/core/drivers/fabric-driver</code> folder.</p> <p>Use the following steps to run Fabric drivers in Docker containers:</p> <ul> <li>Navigate to the <code>weaver/core/drivers/fabric-driver</code> folder.<ul> <li>The <code>.env.n1</code> and <code>.env.n1.tls</code> files in the <code>docker-testnet-envs</code> directory contain environment variables used by the <code>network1</code> driver at startup and runtime. Edit either of these files (depending on whether you wish to start the relay with or without TLS) as follows:<ul> <li>Replace <code>&lt;PATH-TO-WEAVER&gt;</code> with the absolute path of the <code>weaver</code> folder within your Cacti repository clone.</li> </ul> </li> <li>Repeat the above step for <code>.env.n2</code> or <code>.env.n2.tls</code> in <code>docker-testnet-envs</code> directory, which contain environment variables for the <code>network2</code> driver.</li> <li>To deploy the Fabric driver for <code>network1</code> without TLS, run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet-envs/.env.n1' NETWORK_NAME=$(grep NETWORK_NAME docker-testnet-envs/.env.n1 | cut -d '=' -f 2)\n</code></pre>   Instead, to deploy the driver with TLS, run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet-envs/.env.n1.tls' NETWORK_NAME=$(grep NETWORK_NAME docker-testnet-envs/.env.n1.tls | cut -d '=' -f 2)\n</code></pre></li> <li>To deploy the Fabric driver for <code>network2</code> without TLS, run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet-envs/.env.n2' NETWORK_NAME=$(grep NETWORK_NAME docker-testnet-envs/.env.n2 | cut -d '=' -f 2)\n</code></pre>   Instead, to deploy the driver with TLS, run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet-envs/.env.n2.tls' NETWORK_NAME=$(grep NETWORK_NAME docker-testnet-envs/.env.n2.tls | cut -d '=' -f 2)\n</code></pre></li> </ul> </li> </ul>"},{"location":"weaver/getting-started/test-network/setup-packages-docker/#fabric-iin-agent","title":"Fabric IIN Agent","text":"<p>IIN Agent is a client of a member of a DLT network or security domain with special permissions to update security domain identities and configurations on the ledger via the network's interoperation module. The code for this lies in the <code>weaver/core/identity-management/iin-agent</code> folder. Navigate to the <code>weaver/core/identity-management/iin-agent</code> folder.</p>"},{"location":"weaver/getting-started/test-network/setup-packages-docker/#deployment","title":"Deployment","text":"<p>Use the following steps to run Fabric IIN Agents in Docker containers:</p> <ul> <li>The <code>.env.n1.org1</code> and <code>.env.n1.org1.tls</code> files in the <code>docker-testnet/envs</code> directory contain environment variables used by the iin-agent of <code>org1</code> of <code>network1</code> at startup and runtime. Edit either of these files (depending on whether you wish to start the relay with or without TLS) as follows:<ul> <li>Replace <code>&lt;PATH-TO-WEAVER&gt;</code> with the absolute path of the <code>weaver</code> folder within your Cacti repository clone.</li> <li>If Fabric network was started with 1 org, and IIN Agents are to be started with TLS enabled, update the <code>DNS_CONFIG_PATH</code> variable as:   <pre><code>DNS_CONFIG_PATH=./docker-testnet/configs/dnsconfig-tls.json\n</code></pre></li> <li>If Fabric network was started with 2 orgs, and IIN Agents are to be started without TLS, update the <code>DNS_CONFIG_PATH</code> variable as   <pre><code>DNS_CONFIG_PATH=./docker-testnet/configs/dnsconfig-2-nodes.json\n</code></pre></li> <li>If Fabric network was started with 2 orgs and IIN Agents are to be started with TLS enabled, update the <code>DNS_CONFIG_PATH</code> variable as:   <pre><code>DNS_CONFIG_PATH=./docker-testnet/configs/dnsconfig-tls-2-nodes.json\n</code></pre></li> </ul> </li> <li>Repeat the above steps for all other environment variable files (depending upon whether tls is enabled) in <code>docker-testnet/envs</code> directory.</li> <li>To deploy the Fabric IIN Agent for <code>org1</code> of <code>network1</code> without TLS, run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet/envs/.env.n1.org1' DLT_SPECIFIC_DIR=$(grep DLT_SPECIFIC_DIR docker-testnet/envs/.env.n1.org1 | cut -d '=' -f 2)\n</code></pre>   Instead, to deploy the IIN Agent with TLS, run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet/envs/.env.n1.org1.tls' DLT_SPECIFIC_DIR=$(grep DLT_SPECIFIC_DIR docker-testnet/envs/.env.n1.org1.tls | cut -d '=' -f 2)\n</code></pre></li> <li>To deploy the Fabric IIN Agent for <code>org2</code> of <code>network1</code> without TLS (only required if Fabric network was started with 2 orgs), run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet/envs/.env.n1.org2' DLT_SPECIFIC_DIR=$(grep DLT_SPECIFIC_DIR docker-testnet/envs/.env.n1.org2 | cut -d '=' -f 2)\n</code></pre>   Instead, to deploy the IIN Agent with TLS, run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet/envs/.env.n1.org2.tls' DLT_SPECIFIC_DIR=$(grep DLT_SPECIFIC_DIR docker-testnet/envs/.env.n1.org2.tls | cut -d '=' -f 2)\n</code></pre></li> <li>To deploy the Fabric IIN Agent for <code>org1</code> of <code>network2</code> without TLS, run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet/envs/.env.n2.org1' DLT_SPECIFIC_DIR=$(grep DLT_SPECIFIC_DIR docker-testnet/envs/.env.n2.org1 | cut -d '=' -f 2)\n</code></pre>   Instead, to deploy the IIN Agent with TLS, run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet/envs/.env.n2.org1.tls' DLT_SPECIFIC_DIR=$(grep DLT_SPECIFIC_DIR docker-testnet/envs/.env.n2.org1.tls | cut -d '=' -f 2)\n</code></pre></li> <li>To deploy the Fabric IIN Agent for <code>org2</code> of <code>network2</code> without TLS (only required if Fabric network was started with 2 orgs), run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet/envs/.env.n2.org2' DLT_SPECIFIC_DIR=$(grep DLT_SPECIFIC_DIR docker-testnet/envs/.env.n2.org2 | cut -d '=' -f 2)\n</code></pre>   Instead, to deploy the IIN Agent with TLS, run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet/envs/.env.n2.org2.tls' DLT_SPECIFIC_DIR=$(grep DLT_SPECIFIC_DIR docker-testnet/envs/.env.n2.org2.tls | cut -d '=' -f 2)\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/setup-packages-docker/#fabric-client-application","title":"Fabric Client (Application)","text":"<p>The CLI is used to interact with a Fabric network, configure it and run chaincode transactions to record data on the channel ledger or query data. It is also used to interact with remote networks through the relay in order to trigger an interoperation flow for data request and acceptance.</p> <p>The <code>fabric-cli</code> Node.js source code is located in the <code>weaver/samples/fabric/fabric-cli</code> folder and the Golang source code in the <code>weaver/samples/fabric/go-cli</code> folder.</p>"},{"location":"weaver/getting-started/test-network/setup-packages-docker/#prerequisites_1","title":"Prerequisites","text":"<p>If you are using a Linux system, make sure that lib64 is installed.</p> Notes For the Node.js version of the <code>fabric-cli</code>, the setup and running instructions below were tested with all Node.js versions from v11.14.0 to v14.17.3."},{"location":"weaver/getting-started/test-network/setup-packages-docker/#installation","title":"Installation","text":"<p>You can install <code>fabric-cli</code> as follows (for both the Node.js and Golang versions):</p> <ul> <li>Navigate to the <code>weaver/samples/fabric/fabric-cli</code> folder (for the Node.js version) or the <code>weaver/samples/fabric/go-cli</code> folder (for the Golang version).</li> <li>Create <code>.npmrc</code> from template <code>.npmrc.template</code>, by replacing <code>&lt;personal-access-token&gt;</code> with yours created above..</li> <li>Run the following to install dependencies (for the Node.js version) or the executable (for the Golang version):   <pre><code>make build\n</code></pre></li> <li>Use the <code>fabric-cli</code> executable in the <code>bin</code> folder for subsequent actions.</li> </ul>"},{"location":"weaver/getting-started/test-network/setup-packages-docker/#corda-components","title":"Corda Components","text":"<p>Using the sequence of instructions below, you can start a Corda network and run an application CorDapp on it. You can also run an interoperation CorDapp, a relay and a driver acting on behalf of the network. You can initialize the network's vault with access control policies, foreign networks' security groups (i.e., membership providers' certificate chains), and some sample state values that can be shared during subsequent interoperation flows.</p>"},{"location":"weaver/getting-started/test-network/setup-packages-docker/#corda-network","title":"Corda Network","text":"<p>The Corda networks' code lies in the <code>weaver/tests/network-setups/corda</code> folder. You can launch two separate Corda networks, namely <code>Corda_Network</code> and <code>Corda_Network2</code>. Each network runs the <code>weaver/samples/corda/corda-simple-application</code> CorDapp by default, which maintains a state named <code>SimpleState</code> containing a set of key-value pairs (of strings).</p> <p>The following steps will, in addition to launching the network, build the CorDapp and a Corda client in <code>weaver/samples/corda/corda-simple-application/client</code>.</p>"},{"location":"weaver/getting-started/test-network/setup-packages-docker/#running-with-interoperation-cordapp-from-github-packages","title":"Running with Interoperation CorDapp from GitHub Packages","text":"<p>Follow the instructions below to build and launch the network:</p> <ul> <li>Navigate to the <code>weaver/tests/network-setups/corda</code> folder.</li> <li>Create copy of <code>github.properties.template</code> as <code>github.properties</code>.</li> <li>Replace <code>&lt;GITHUB email&gt;</code> with your GitHub email, and <code>&lt;GITHUB Personal Access Token&gt;</code> with the access token created above.</li> <li>To spin up the Corda networks with the Interoperation CorDapps:<ul> <li>Each consisting of 1 node and a notary (for data-transfer), run:   <pre><code>make start\n</code></pre></li> <li>Each consisting of 2 nodes and a notary (for asset-exchange/transfer), run:   <pre><code>make start PROFILE=\"2-nodes\"\n</code></pre></li> <li>Each consisting of 3 nodes and a notary (for asset-exchange/transfer), run:   <pre><code>make start PROFILE=\"3-nodes\"\n</code></pre></li> </ul> </li> </ul> <p>You should see the following message in the terminal: <pre><code>Waiting for network node services to start\n</code></pre> The Corda nodes and notary may take a while (several minutes on memory-constrained systems) to start. If they start up successfully, you should something like the following for each network, though the number of node entries will depend on the profile you used to start the network with (replace <code>&lt;network-name&gt;</code> with <code>Corda_Network</code> or <code>Corda_Network2</code>): <pre><code>PartyA node services started for network &lt;network-name&gt;\nPartyB node services started for network &lt;network-name&gt;\nPartyC node services started for network &lt;network-name&gt;\nNotary node services started for network &lt;network-name&gt;\n</code></pre></p>"},{"location":"weaver/getting-started/test-network/setup-packages-docker/#corda-relay","title":"Corda Relay","text":"<p>Navigate to the <code>weaver/core/relay</code> folder and run a relay for <code>Corda_Network</code> and/or <code>Corda_Network2</code> in Docker container as follows:</p> <ul> <li>The <code>docker-compose.yaml</code> in this folder is minimally configured with default values. To modify it for use with the Fabric testnets, run:   <pre><code>make convert-compose-method2\n</code></pre></li> <li> <p>(The <code>.env.corda</code> and <code>.env.corda.tls</code> files in the <code>docker/testnet-envs</code> directory contain environment variables used by the <code>Corda_Network</code> relay at startup and runtime.)</p> </li> <li> <p>(The <code>.env.corda2</code> and <code>.env.corda2.tls</code> files in the <code>docker/testnet-envs</code> directory contain environment variables used by the <code>Corda_Network2</code> relay at startup and runtime.)</p> </li> <li> <p>To deploy the relay server for <code>Corda_Network</code> without TLS, run:   <pre><code>make start-server COMPOSE_ARG='--env-file docker/testnet-envs/.env.corda'\n</code></pre>   Instead, to deploy the relay server with TLS, run:   <pre><code>make start-server COMPOSE_ARG='--env-file docker/testnet-envs/.env.corda.tls'\n</code></pre></p> </li> <li>To deploy the relay server for <code>Corda_Network2</code> without TLS, run:   <pre><code>make start-server COMPOSE_ARG='--env-file docker/testnet-envs/.env.corda2'\n</code></pre>   Instead, to deploy the relay server with TLS, run:   <pre><code>make start-server COMPOSE_ARG='--env-file docker/testnet-envs/.env.corda2.tls'\n</code></pre></li> <li>After launching the relay(s), you can revert the <code>docker-compose.yaml</code> changes by running:   <pre><code>make convert-compose-method1\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/setup-packages-docker/#corda-driver","title":"Corda Driver","text":"<p>Use the following steps to run Corda drivers in Docker containers:</p> <ul> <li>Navigate to the <code>weaver/core/drivers/corda-driver</code> folder.</li> <li>(The <code>.env.corda</code> and <code>.env.corda.tls</code> files in the <code>docker-testnet-envs</code> contain environment variables used by the <code>Corda_Network</code> driver at startup and runtime.)</li> <li>(The <code>.env.corda2</code> and <code>.env.corda2.tls</code> files in the <code>docker-testnet-envs</code> contain environment variables used by the <code>Corda_Network2</code> driver at startup and runtime.)</li> <li>To deploy the Corda driver for <code>Corda_Network</code> without TLS, run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet-envs/.env.corda'\n</code></pre>   Instead, to deploy the driver with TLS, run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet-envs/.env.corda.tls'\n</code></pre>   If the driver starts successfully, it should log the following message when you run <code>docker logs corda-driver-Corda_Network</code>:   <pre><code>Corda driver gRPC server started. Listening on port 9099\n</code></pre></li> <li>To deploy the Corda driver for <code>Corda_Network2</code> without TLS, run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet-envs/.env.corda2'\n</code></pre>   Instead, to deploy the driver with TLS, run:   <pre><code>make deploy COMPOSE_ARG='--env-file docker-testnet-envs/.env.corda2.tls'\n</code></pre>   If the driver starts successfully, it should log the following message when you run <code>docker logs corda-driver-Corda_Network2</code>:   <pre><code>Corda driver gRPC server started. Listening on port 9098\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/setup-packages-docker/#tear-down-the-setup","title":"Tear Down the Setup","text":"<p>Bring down the various components as follows (Navigate to the <code>weaver</code> folder of your clone of the Cacti repository):</p>"},{"location":"weaver/getting-started/test-network/setup-packages-docker/#relay","title":"Relay","text":"<p>To bring down the relays (for all 3 networks), run: <pre><code>cd core/relay\nmake convert-compose-method2\nmake stop COMPOSE_ARG='--env-file docker/testnet-envs/.env.n1'\nmake stop COMPOSE_ARG='--env-file docker/testnet-envs/.env.n2'\nmake stop COMPOSE_ARG='--env-file docker/testnet-envs/.env.corda'\nmake stop COMPOSE_ARG='--env-file docker/testnet-envs/.env.corda2'\nmake convert-compose-method1\ncd -\n</code></pre></p>"},{"location":"weaver/getting-started/test-network/setup-packages-docker/#fabric-driver_1","title":"Fabric Driver","text":"<p>To bring down the fabric drivers (for both networks), run: <pre><code>cd core/drivers/fabric-driver\nmake stop COMPOSE_ARG='--env-file docker-testnet-envs/.env.n1'\nmake stop COMPOSE_ARG='--env-file docker-testnet-envs/.env.n2'\ncd -\n</code></pre></p>"},{"location":"weaver/getting-started/test-network/setup-packages-docker/#corda-driver_1","title":"Corda Driver","text":"<p>To bring down the corda driver, run: <pre><code>cd core/drivers/corda-driver\nmake stop COMPOSE_ARG='--env-file docker-testnet-envs/.env.corda'\nmake stop COMPOSE_ARG='--env-file docker-testnet-envs/.env.corda2'\ncd -\n</code></pre></p>"},{"location":"weaver/getting-started/test-network/setup-packages-docker/#corda-network_1","title":"Corda Network","text":"<p>To bring down the Corda network: <pre><code>cd tests/network-setups/corda\nmake clean\ncd -\n</code></pre></p>"},{"location":"weaver/getting-started/test-network/setup-packages-docker/#fabric-network_1","title":"Fabric Network","text":"<p>To bring down both of the Fabric networks along with weaver components: <pre><code>cd tests/network-setups/fabric/dev\nmake clean\ncd -\n</code></pre></p>"},{"location":"weaver/getting-started/test-network/setup-packages/","title":"Setup with Imported Weaver Components","text":"<p>In this document, we detail the steps using which you can bring up networks using the default configuration settings and by fetching pre-built Weaver interoperation modules, SDK libraries, and relay drivers from GitHub Package repositories. To customize these settings (e.g., hostnames, ports), refer to the Advanced Configuration page.</p> Notes The default configuration is for a development setup, therefore all components are run on <code>localhost</code>, many within Docker containers. <p>Follow the instructions below to build and run components followed by interoperation flows. These instructions have been tested on Ubuntu Linux (bash shell) and Mac OS. In general, they should work on any system and shell as long as the various dependencies have been installed and configured.</p>"},{"location":"weaver/getting-started/test-network/setup-packages/#prerequisites","title":"Prerequisites","text":""},{"location":"weaver/getting-started/test-network/setup-packages/#software","title":"Software","text":"<p>Before starting, make sure you have the following software installed on your host machine:</p> <ul> <li>Curl: install using package manager, like <code>apt</code> on Debian/Ubuntu Linux</li> <li>Git: sample instructions</li> <li>Docker: sample instructions (Latest version)</li> <li>Docker-Compose: sample instructions (Version 2 or higher)</li> <li>Golang: sample instructions (Version 1.16 or higher)</li> <li>Java (JDK and JRE): sample instructions (Version 8)</li> <li>Node.js and NPM: sample instructions (Version 16 Supported)</li> <li>Yarn: sample instructions</li> <li>Rust: sample instructions<ul> <li>To avoid errors during Weaver Relay compilation, update certain packages (on which the Weaver Relay is dependent) to their latest versions as follows:   <pre><code>cargo update -p nom\ncargo update -p lexical-core\n</code></pre></li> </ul> </li> </ul>"},{"location":"weaver/getting-started/test-network/setup-packages/#credentials","title":"Credentials","text":"<p>Make sure you have an SSH or GPG key registered in https://github.com to allow seamless cloning of repositories (at present, various setup scripts clone repositories using the <code>https://</code> prefix but this may change to <code>git@</code> in the future).</p> <p>Create a personal access token with <code>read:packages</code> access in GitHub in order to use modules published in GitHub packages. Refer Creating a Personal Access Token for help.</p>"},{"location":"weaver/getting-started/test-network/setup-packages/#getting-the-code-and-documentation","title":"Getting the Code and Documentation","text":"<p>Clone the cacti repository. The code to get a basic test network up and running and test data-sharing interoperation flows lies in the subfolder <code>weaver/tests/network-setups</code>, which should be your starting point, though the setups will rely on other parts of the repository, as you will find out in the instructions given on this page.</p>"},{"location":"weaver/getting-started/test-network/setup-packages/#securing-components","title":"Securing Components","text":"Notes The relays and drivers corresponding to the different test networks you will encounter below can be run with or without TLS enabled. But the default files used in the demonstrations assume that either all relays and drivers are TLS-enabled or none are. Therefore, you should determine at the outset whether or not you wish to run the entire set of components in TLS-enabled mode, and select appropriate commands in the provided instructions."},{"location":"weaver/getting-started/test-network/setup-packages/#hyperledger-fabric-components","title":"Hyperledger Fabric Components","text":"<p>Using the sequence of instructions below, you can start two separate Fabric networks, each with a single channel and application contract (chaincode). You can also start an interoperation contract, a relay, and a driver acting on behalf of each network. You can build a Fabric CLI tool with which you can initialize both networks' ledgers with access control policies, foreign networks' security groups (i.e., membership providers' certificate chains), and some sample key-value pairs that can be shared during subsequent interoperation flows.</p>"},{"location":"weaver/getting-started/test-network/setup-packages/#fabric-network","title":"Fabric Network","text":"<p>The code for this lies in the <code>weaver/tests/network-setups</code> folder.</p> <p>This folder contains code to create and launch networks <code>network1</code> and <code>network2</code> of identical specifications:</p> <ul> <li>Network: 1 peer, 1 peer CA, 1 ordering service node, 1 ordering service CA</li> <li>Single channel named <code>mychannel</code></li> <li>One of the following contracts deployed on <code>mychannel</code>, the choice depending on the interoperability mode you wish to test:<ul> <li><code>simplestate</code> (Data Sharing): supports simple transactions (<code>Create</code>, <code>Read</code>, <code>Update</code>, <code>Delete</code>) involving storage and lookup of  pairs. <li><code>simplestatewithacl</code> (Data Sharing): identical to <code>simplestate</code> but with extra security features to ensure that the Weaver infrastructure cannot be bypassed by a malicious client of the network.</li> <li><code>simpleasset</code> (Asset Exchange): supports creation, modification, transfer, and deletion, as well as locking, unlocking, and claiming, of simple bonds and tokens (examples of non-fungible and fungible assets respectively).</li> <li><code>simpleassetandinterop</code> (Asset Exchange): identical to <code>simpleasset</code> but where the locking, unlocking, and claiming logic is imported as a library in the chaincode rather than available in the common Fabric Interoperation Chaincode (a Weaver component).</li> <li><code>simpleassettransfer</code> (Asset Exchange or Asset Transfer): augmentation of <code>simpleasset</code> with asset pledging, claiming, and reclaiming features for cross-network transfers.</li> Notes For new users, we recommend testing the Data Sharing feature first with the <code>simplestate</code> contract. To test the other modes, you can simply tear down the Fabric networks and restart them with the appropriate chaincodes installed. <p>Follow the instructions below to build and launch the networks:</p> <ul> <li>Navigate to the <code>weaver/tests/network-setups/fabric/dev</code> folder.</li> <li>To spin up both network1 and network2 with the interoperation chaincode and the default <code>simplestate</code> chaincode installed, run:   <pre><code>make start-interop\n</code></pre></li> <li>To launch the networks with a different application chaincode from the above list, run:   <pre><code>make start-interop CHAINCODE_NAME=&lt;chaincode-name&gt;\n</code></pre></li> <li>To launch the networks with 2 organizations, each with a peer (this will enable more variation and experimentation, which you can attempt after testing interoperation protocols across basic network configurations), run:   <pre><code>make start-interop-local PROFILE=\"2-nodes\"\n</code></pre></li> </ul> Notes If you do not wish to test Fabric-Fabric interoperation, you can choose to launch only one of the two networks along with its interoperation chaincode. For <code>network1</code>, run <code>make start-interop-network1</code>, and for <code>network2</code>, run <code>make start-interop-network2</code> If you wish to enable end-to-end confidentiality by default in the interoperation modules that are deployed during network launch, set the environment variable <code>E2E_CONFIDENTIALITY</code> to <code>true</code> in the command line as follows: <code>E2E_CONFIDENTIALITY=true make start-interop</code> <p>For more information, refer to the associated README.</p> <p>Troubleshooting Tips:</p> <ul> <li>If you see any errors during the launches, re-check the prerequisites (software installations and credentials). Ensure your network connection is working. As a safe bet, you can retry after cleanup: kill and remove all Docker containers and associated volumes.</li> </ul>"},{"location":"weaver/getting-started/test-network/setup-packages/#fabric-client-fabric-cli","title":"Fabric Client (fabric-cli)","text":"<p>The CLI is used to interact with a Fabric network, configure it and run chaincode transactions to record data on the channel ledger or query data. It is also used to interact with remote networks through the relay to trigger an interoperation flow for data request and acceptance.</p> <p>The <code>fabric-cli</code> Node.js source code is located in the <code>weaver/samples/fabric/fabric-cli</code> folder and the Golang source code in the <code>weaver/samples/fabric/go-cli</code> folder.</p>"},{"location":"weaver/getting-started/test-network/setup-packages/#prerequisites_1","title":"Prerequisites","text":"<p>If you are using a Linux system, make sure that lib64 is installed.</p> Notes For the Node.js version of the <code>fabric-cli</code>, the setup and running instructions below were tested with all Node.js versions from v11.14.0 to v14.17.3."},{"location":"weaver/getting-started/test-network/setup-packages/#installation","title":"Installation","text":"<p>You can install <code>fabric-cli</code> as follows (for both the Node.js and Golang versions):</p> <ul> <li>Navigate to the <code>weaver/samples/fabric/fabric-cli</code> folder (for the Node.js version) or the <code>weaver/samples/fabric/go-cli</code> (for the Golang version) folder.</li> <li>Create <code>.npmrc</code> from template <code>.npmrc.template</code>, by replacing <code>&lt;personal-access-token&gt;</code> with yours created above..</li> <li>Run the following to install dependencies (for the Node.js version) or the executable (for the Golang version):   <pre><code>make build\n</code></pre></li> <li>Use the <code>fabric-cli</code> executable in the <code>bin</code> folder for subsequent actions.</li> </ul>"},{"location":"weaver/getting-started/test-network/setup-packages/#fabric-relay","title":"Fabric Relay","text":"<p>The relay is a module acting on behalf of a network, enabling interoperation flows with other networks by communicating with their relays. The code for this lies in the <code>weaver/core/relay</code> folder.</p>"},{"location":"weaver/getting-started/test-network/setup-packages/#building","title":"Building","text":"<p>Prerequisite: make sure Rust is already installed and that the <code>cargo</code> executable is in your system path (after installation of Rust, this should be available in <code>$HOME/.cargo/bin</code>); you can also ensure this by running <code>source \"$HOME/.cargo/env\"</code>.</p> <p>Build the generic (i.e., common to all DLTs) relay module as follows:</p> <ul> <li>Navigate to the <code>weaver/core/relay</code> folder.</li> <li>Run the following:   <pre><code>make\n</code></pre></li> <li>If you observe errors during the above compilation, update certain packages (on which the Weaver Relay is dependent) to their latest versions and recompile as follows:   <pre><code>make update-pkgs\nmake\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/setup-packages/#deployment","title":"Deployment","text":"<p>An instance or a relay can be run using a suitable configuration file. Samples are available in the <code>weaver/core/relay/config</code> folder.</p> <p>Run a relay for <code>network1</code> as follows:</p> <ul> <li>Navigate to the <code>weaver/core/relay</code> folder.</li> <li>To launch the server without TLS, leave the configuration file <code>config/Fabric_Relay.toml</code> in its default state. Otherwise, edit it to set TLS flags for this relay and the other relays and drivers it will connect to in this demonstration as follows:   <pre><code>.\n.\ncert_path=\"credentials/fabric_cert.pem\"\nkey_path=\"credentials/fabric_key\"\ntls=true\n.\n.\n[relays]\n[relays.Corda_Relay]\nhostname=\"localhost\"\nport=\"9081\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n[relays.Corda_Relay2]\nhostname=\"localhost\"\nport=\"9082\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n[relays.Fabric_Relay2]\nhostname=\"localhost\"\nport=\"9083\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n.\n.\n[drivers]\n[drivers.Fabric]\nhostname=\"localhost\"\nport=\"9090\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n.\n.\n</code></pre></li> <li>To launch the server, simply run the following:   <pre><code>RELAY_CONFIG=config/Fabric_Relay.toml cargo run --bin server\n</code></pre></li> </ul> <p>Run a relay for <code>network2</code> as follows (do this only if you have launched both Fabric networks <code>network1</code> and <code>network2</code> and wish to test interoperation between them)</p> <ul> <li>Navigate to the <code>weaver/core/relay</code> folder.</li> <li>To launch the server without TLS, leave the configuration file <code>config/Fabric_Relay2.toml</code> in its default state. Otherwise, edit it to set TLS flags for this relay and the other relays and drivers it will connect to in this demonstration as follows:   <pre><code>.\n.\ncert_path=\"credentials/fabric_cert.pem\"\nkey_path=\"credentials/fabric_key\"\ntls=true\n.\n.\n[relays]\n[relays.Corda_Relay]\nhostname=\"localhost\"\nport=\"9081\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n[relays.Corda_Relay2]\nhostname=\"localhost\"\nport=\"9082\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n[relays.Fabric_Relay]\nhostname=\"localhost\"\nport=\"9080\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n.\n.\n[drivers]\n[drivers.Fabric]\nhostname=\"localhost\"\nport=\"9095\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n.\n.\n</code></pre></li> <li>To launch the server, simply run the following:   <pre><code>RELAY_CONFIG=config/Fabric_Relay2.toml cargo run --bin server\n</code></pre></li> </ul> <p>For more information, see the relay README.</p>"},{"location":"weaver/getting-started/test-network/setup-packages/#fabric-driver","title":"Fabric Driver","text":"<p>A driver is a DLT-specific plugin invoked by the relay while conveying external data queries to the local peer network and collecting a response with proofs. The Fabric driver is built as a Fabric client application on the <code>fabric-network</code> NPM package. The code for this lies in the <code>weaver/core/drivers/fabric-driver</code> folder.</p>"},{"location":"weaver/getting-started/test-network/setup-packages/#configuring","title":"Configuring","text":"<p>In the <code>weaver/core/drivers/fabric-driver</code> folder, copy <code>.env.template</code> to <code>.env</code> and update <code>CONNECTION_PROFILE</code> to point to the connection profile of the Fabric network (e.g. <code>&lt;PATH-TO-WEAVER&gt;/tests/network-setups/fabric/shared/network1/peerOrganizations/org1.network1.com/connection-org1.json</code>)</p> <p>Configure <code>fabric-driver</code> for <code>network1</code> as follows:</p> <ul> <li>Navigate to the <code>weaver/core/drivers/fabric-driver</code> folder.</li> <li>Create a <code>.env</code> file by copying <code>.env.template</code> and setting suitable parameter values:<ul> <li>The <code>CONNECTION_PROFILE</code> should point to the absolute path of the connection profile for <code>network1</code>.<ul> <li>For this exercise, specify the path <code>&lt;PATH-TO-WEAVER&gt;/tests/network-setups/fabric/shared/network1/peerOrganizations/org1.network1.com/connection-org1.json</code> (you must specify the full absolute path here).</li> <li><code>&lt;PATH-TO-WEAVER&gt;</code> here is the absolute path of the <code>weaver</code> folder within your Cacti repository clone.</li> </ul> </li> <li>If you wish to start the driver without TLS, set the following parameter values:   <pre><code>RELAY_TLS=false\nRELAY_TLSCA_CERT_PATH=\nDRIVER_TLS=false\nDRIVER_TLS_CERT_PATH=\nDRIVER_TLS_KEY_PATH=\n</code></pre>   Otherwise, if you wish to start the driver with TLS enabled, set the following parameter values (replace <code>&lt;PATH-TO-WEAVER&gt;</code> with the absolute path of the <code>weaver</code> folder within your Cacti repository clone):   <pre><code>RELAY_TLS=true\nRELAY_TLSCA_CERT_PATH=&lt;PATH-TO-WEAVER&gt;/core/relay/credentials/fabric_ca_cert.pem\nDRIVER_TLS=true\nDRIVER_TLS_CERT_PATH=&lt;PATH-TO-WEAVER&gt;/core/relay/credentials/fabric_cert.pem\nDRIVER_TLS_KEY_PATH=&lt;PATH-TO-WEAVER&gt;/core/relay/credentials/fabric_key\n</code></pre></li> <li>Leave the default values unchanged for the other parameters. The relay and driver endpoints as well as the network name are already specified.</li> </ul> </li> </ul>"},{"location":"weaver/getting-started/test-network/setup-packages/#building_1","title":"Building","text":"<p>Build the Fabric driver module as follows:</p> <ul> <li>Navigate to the <code>weaver/core/drivers/fabric-driver</code> folder.</li> <li>Create <code>.npmrc</code> from template <code>.npmrc.template</code>, by replacing <code>&lt;personal-access-token&gt;</code> with yours created above.</li> <li>Run the following:   <pre><code>make build\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/setup-packages/#running","title":"Running","text":"<p>Run a Fabric driver for <code>network1</code> as follows:</p> <ul> <li>Navigate to the <code>weaver/core/drivers/fabric-driver</code> folder.</li> <li>Run the following:   <pre><code>npm run dev\n</code></pre></li> </ul> <p>Run a Fabric driver for <code>network2</code> as follows (do this only if you wish to test interoperation between the two Fabric networks <code>network1</code> and <code>network2</code>)</p> <ul> <li>Navigate to the <code>weaver/core/drivers/fabric-driver</code> folder.</li> <li>Run the following:   <pre><code>CONNECTION_PROFILE=&lt;PATH-TO-WEAVER&gt;/tests/network-setups/fabric/shared/network2/peerOrganizations/org1.network2.com/connection-org1.json NETWORK_NAME=network2 RELAY_ENDPOINT=localhost:9083 DRIVER_ENDPOINT=localhost:9095 npm run dev\n</code></pre></li> </ul> Notes The variables we specified earlier in the <code>.env</code> for <code>network1</code> are now passed in the command line. Alternatively, you can make a copy of the <code>fabric-driver</code> folder with a different  name and create a separate <code>.env</code> file within it that contains links to the connection profile, relay, and driver for <code>network2</code>."},{"location":"weaver/getting-started/test-network/setup-packages/#fabric-iin-agent","title":"Fabric IIN Agent","text":"<p>IIN Agent is a client of a member of a DLT network or security domain with special permissions to update security domain identities and configurations on the ledger via the network's interoperation module. The code for this lies in the <code>weaver/core/identity-management/iin-agent</code> folder. Navigate to the <code>weaver/core/identity-management/iin-agent</code> folder.</p>"},{"location":"weaver/getting-started/test-network/setup-packages/#building_2","title":"Building","text":"<p>Build the IIN Agent as follows:</p> <ul> <li>Navigate to the <code>weaver/core/drivers/fabric-driver</code> folder.</li> <li>Create <code>.npmrc</code> from template <code>.npmrc.template</code>, by replacing <code>&lt;personal-access-token&gt;</code> with yours created above.</li> <li>Run the following:   <pre><code>make build\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/setup-packages/#configuration","title":"Configuration","text":"<p>Ledger config file specifies ledger specific IIN Agent details such as identity and which network and organization to connect to.</p> <ol> <li> <p>To create config file for <code>Org1MSP</code>'s Fabric IIN Agent of <code>network1</code>, follow the steps:</p> <ul> <li>Create copy of template config file for Fabric IIN Agent: <code>src/fabric-ledger/config.json.template</code>, say to location <code>src/fabric-ledger/config-n1-org1.json</code>.</li> <li>Replace <code>&lt;path-to-connection-profile&gt;</code> with <code>&lt;PATH-TO-WEAVER&gt;/tests/network-setups/fabric/shared/network1/peerOrganizations/org1.network1.com/connection-org1.json</code>, where replace <code>&lt;PATH-TO-WEAVER&gt;</code> with the absolute path of the <code>weaver</code> folder within your Cacti repository clone.</li> <li>Set <code>mspId</code> as <code>Org1MSP</code>.</li> <li>Set <code>agent.affiliation</code> as <code>org1.department1</code>.</li> </ul> </li> <li> <p>To create config file for <code>Org2MSP</code>'s Fabric IIN Agent of <code>network1</code>, repeat <code>Step 1</code> with different name for config file, say <code>src/fabric-ledger/config-n1-org2.json</code>, and replace <code>org1</code> with <code>org2</code> and <code>Org1MSP</code> with <code>Org2MSP</code>.</p> </li> <li>To create config file for <code>Org1MSP</code>'s Fabric IIN Agent of <code>network2</code>, repeat <code>Step 1</code> with different name for config file, say <code>src/fabric-ledger/config-n2-org1.json</code>, and replace <code>network1</code> with <code>network2</code>.</li> <li>To create config file for <code>Org2MSP</code>'s Fabric IIN Agent of <code>network2</code>, repeat <code>Step 1</code> with different name for config file, say <code>src/fabric-ledger/config-n2-org2.json</code>, and replace <code>network1</code> with <code>network2</code>, <code>org1</code> with <code>org2</code> and <code>Org1MSP</code> with <code>Org2MSP</code>.</li> </ol>"},{"location":"weaver/getting-started/test-network/setup-packages/#security-domain-configuration","title":"Security Domain Configuration","text":"<p>Security Domain config file specifies the scope of security domain, which can be a channel in Fabric networks or list of nodes. File <code>docker-testnet/configs/security-domain-config.json</code> can be used for Weaver testnets.</p>"},{"location":"weaver/getting-started/test-network/setup-packages/#dns-configuration","title":"DNS Configuration","text":"<p>To allow an IIN Agent's to be able to discover other IIN Agents, a config file for DNS is required. Create one <code>dnsconfig.json</code> by creating a copy of template <code>dnsconfig.json.template</code>, and replace the values with:</p> <ul> <li> <p>If Fabric networks are started with 1 org, and IIN Agent are to be started without TLS, use following values: <pre><code>{\n    \"network1\": {\n        \"Org1MSP\": {\n            \"endpoint\": \"localhost:9500\",\n            \"tls\": false,\n            \"tlsCACertPath\": \"\"\n        }\n    },\n    \"network2\": {\n        \"Org1MSP\": {\n            \"endpoint\": \"localhost:9501\",\n            \"tls\": false,\n            \"tlsCACertPath\": \"\"\n        }\n    }\n}\n</code></pre></p> </li> <li> <p>If Fabric networks are started with 1 org, and IIN Agent are to be started with TLS, use following values: <pre><code>{\n    \"network1\": {\n        \"Org1MSP\": {\n            \"endpoint\": \"localhost:9500\",\n            \"tls\": true,\n            \"tlsCACertPath\": \"../../relay/credentials/fabric_ca_cert.pem\"\n        }\n    },\n    \"network2\": {\n        \"Org1MSP\": {\n            \"endpoint\": \"localhost:9501\",\n            \"tls\": true,\n            \"tlsCACertPath\": \"../../relay/credentials/fabric_ca_cert.pem\"\n        }\n    }\n}\n</code></pre></p> </li> <li> <p>If Fabric networks are started with 2 orgs, and IIN Agent are to be started without TLS, use following values: <pre><code>{\n    \"network1\": {\n        \"Org1MSP\": {\n            \"endpoint\": \"localhost:9500\",\n            \"tls\": false,\n            \"tlsCACertPath\": \"\"\n        },\n        \"Org2MSP\": {\n            \"endpoint\": \"localhost:9510\",\n            \"tls\": false,\n            \"tlsCACertPath\": \"\"\n        }\n    },\n    \"network2\": {\n        \"Org1MSP\": {\n            \"endpoint\": \"localhost:9501\",\n            \"tls\": false,\n            \"tlsCACertPath\": \"\"\n        },\n        \"Org2MSP\": {\n            \"endpoint\": \"localhost:9511\",\n            \"tls\": false,\n            \"tlsCACertPath\": \"\"\n        }\n    }\n}\n</code></pre></p> </li> <li> <p>If Fabric networks are started with 2 orgs, and IIN Agent are to be started with TLS, use following values: <pre><code>{\n    \"network1\": {\n        \"Org1MSP\": {\n            \"endpoint\": \"localhost:9500\",\n            \"tls\": true,\n            \"tlsCACertPath\": \"../../relay/credentials/fabric_ca_cert.pem\"\n        },\n        \"Org2MSP\": {\n            \"endpoint\": \"localhost:9510\",\n            \"tls\": true,\n            \"tlsCACertPath\": \"../../relay/credentials/fabric_ca_cert.pem\"\n        }\n    },\n    \"network2\": {\n        \"Org1MSP\": {\n            \"endpoint\": \"localhost:9501\",\n            \"tls\": true,\n            \"tlsCACertPath\": \"../../relay/credentials/fabric_ca_cert.pem\"\n        },\n        \"Org2MSP\": {\n            \"endpoint\": \"localhost:9511\",\n            \"tls\": true,\n            \"tlsCACertPath\": \"../../relay/credentials/fabric_ca_cert.pem\"\n        }\n    }\n}\n</code></pre></p> </li> </ul> Notes The variables we specified earlier in the <code>.env</code> for <code>network1</code> are now passed in the command line. Alternatively, you can make a copy of the <code>fabric-driver</code> folder with a different  name and create a separate <code>.env</code> file within it that contains links to the connection profile, relay, and driver for <code>network2</code>."},{"location":"weaver/getting-started/test-network/setup-packages/#environment-variables","title":"Environment Variables","text":"<p>To configure environment variables for <code>Org1MSP</code>'s Fabric IIN Agent of <code>network1</code>, follow the steps:</p> <ol> <li>Create a copy of <code>.env.template</code> as <code>.env</code>, and update following values based on previous configuration file paths: <pre><code>IIN_AGENT_ENDPOINT=localhost:9500\nMEMBER_ID=Org1MSP\nSECURITY_DOMAIN=network1\nDLT_TYPE=fabric\nCONFIG_PATH=./src/fabric-ledger/config-n1-org1.json\nDNS_CONFIG_PATH=./dnsconfig.json\nSECURITY_DOMAIN_CONFIG_PATH=./docker-testnet/configs/security-domain-config.json\nWEAVER_CONTRACT_ID=interop\nAUTO_SYNC=true\n</code></pre></li> <li>If IIN Agent has to be started with TLS enabled, also update following values: <pre><code>IIN_AGENT_TLS=false\nIIN_AGENT_TLS_CERT_PATH=../../relay/credentials/fabric_cert.pem\nIIN_AGENT_TLS_KEY_PATH=../../relay/credentials/fabric_key\n</code></pre></li> </ol>"},{"location":"weaver/getting-started/test-network/setup-packages/#deployment_1","title":"Deployment","text":"<p>Use the following steps to run Fabric IIN Agents in host machine:</p> <ul> <li>To start IIN Agent for <code>Org1MSP</code> of <code>network1</code>, run: <pre><code>npm run dev\n</code></pre></li> <li>To start IIN Agent for <code>Org2MSP</code> of <code>network1</code> (only required if Fabric network was started with 2 orgs), run: <pre><code>IIN_AGENT_ENDPOINT=localhost:9510 MEMBER_ID=Org2MSP CONFIG_PATH=./src/fabric-ledger/config-n1-org2.json npm run dev\n</code></pre></li> <li>To start IIN Agent for <code>Org1MSP</code> of <code>network2</code>, run: <pre><code>IIN_AGENT_ENDPOINT=localhost:9501 SECURITY_DOMAIN=network2 CONFIG_PATH=./src/fabric-ledger/config-n2-org1.json npm run dev\n</code></pre></li> <li>To start IIN Agent for <code>Org2MSP</code> of <code>network2</code> (only required if Fabric network was started with 2 orgs), run: <pre><code>IIN_AGENT_ENDPOINT=localhost:9511 MEMBER_ID=Org2MSP SECURITY_DOMAIN=network2 CONFIG_PATH=./src/fabric-ledger/config-n2-org2.json npm run dev\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/setup-packages/#corda-components","title":"Corda Components","text":"<p>Using the sequence of instructions below, you can start a Corda network and run an application CorDapp on it. You can also run an interoperation CorDapp, a relay and a driver acting on behalf of the network. You can initialize the network's vault with access control policies, foreign networks' security groups (i.e., membership providers' certificate chains), and some sample state values that can be shared during subsequent interoperation flows.</p>"},{"location":"weaver/getting-started/test-network/setup-packages/#corda-network","title":"Corda Network","text":"<p>The Corda networks' code lies in the <code>weaver/tests/network-setups/corda</code> folder. You can launch two separate Corda networks, namely <code>Corda_Network</code> and <code>Corda_Network2</code>. Each network runs the <code>weaver/samples/corda/corda-simple-application</code> CorDapp by default, which maintains a state named <code>SimpleState</code> containing a set of key-value pairs (of strings).</p> <p>The following steps will, in addition to launching the network, build the CorDapp and a Corda client in <code>weaver/samples/corda/corda-simple-application/client</code>.</p>"},{"location":"weaver/getting-started/test-network/setup-packages/#running-with-interoperation-cordapp-from-github-packages","title":"Running with Interoperation CorDapp from GitHub Packages","text":"<p>Follow the instructions below to build and launch the network:</p> <ul> <li>Navigate to the <code>weaver/tests/network-setups/corda</code> folder.</li> <li>Create a copy of <code>github.properties.template</code> as <code>github.properties</code>.</li> <li>Replace <code>&lt;GITHUB email&gt;</code> with your GitHub email, and <code>&lt;GITHUB Personal Access Token&gt;</code> with the access token created above.</li> <li>To spin up the Corda networks with the Interoperation CorDapps:<ul> <li>Each consisting of 1 node and a notary (for data-transfer), run:   <pre><code>make start\n</code></pre></li> <li>Each consisting of 2 nodes and a notary (for asset-exchange/transfer), run:   <pre><code>make start PROFILE=\"2-nodes\"\n</code></pre></li> <li>Each consisting of 3 nodes and a notary (for asset-exchange/transfer), run:   <pre><code>make start PROFILE=\"3-nodes\"\n</code></pre></li> </ul> </li> </ul> <p>You should see the following message in the terminal: <pre><code>Waiting for network node services to start\n</code></pre> The Corda nodes and notary may take a while (several minutes on memory-constrained systems) to start. If they start up successfully, you should something like the following for each network, though the number of node entries will depend on the profile you used to start the network with (replace <code>&lt;network-name&gt;</code> with <code>Corda_Network</code> or <code>Corda_Network2</code>): <pre><code>PartyA node services started for network &lt;network-name&gt;\nPartyB node services started for network &lt;network-name&gt;\nPartyC node services started for network &lt;network-name&gt;\nNotary node services started for network &lt;network-name&gt;\n</code></pre></p>"},{"location":"weaver/getting-started/test-network/setup-packages/#corda-relay","title":"Corda Relay","text":"<p>The relay was built earlier, so you just need to use a different configuration file to start a relay for the Corda network.</p> <p>Run a relay for <code>Corda_Network</code> as follows:</p> <ul> <li>Navigate to the <code>weaver/core/relay</code> folder.</li> <li>(Make sure you've already built the relay by running <code>make</code>.)</li> <li>To launch the server without TLS, leave the configuration file <code>config/Corda_Relay.toml</code> in its default state. Otherwise, edit it to set TLS flags for this relay and the other relays and drivers it will connect to in this demonstration as follows:   <pre><code>.\n.\ncert_path=\"credentials/fabric_cert.pem\"\nkey_path=\"credentials/fabric_key\"\ntls=true\n.\n.\n[relays]\n[relays.Fabric_Relay]\nhostname=\"localhost\"\nport=\"9080\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n[relays.Fabric_Relay2]\nhostname=\"localhost\"\nport=\"9083\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n[relays.Corda_Relay2]\nhostname=\"localhost\"\nport=\"9082\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n.\n.\n[drivers]\n[drivers.Corda]\nhostname=\"localhost\"\nport=\"9099\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n.\n.\n</code></pre></li> <li>To launch the server, simply run the following:   <pre><code>RELAY_CONFIG=config/Corda_Relay.toml cargo run --bin server\n</code></pre></li> </ul> <p>If the relay starts up successfully, the following will be logged on your terminal:</p> <pre><code>Relay Name: \"Corda_Relay\"\nRelayServer listening on [::1]:9081\n</code></pre> <p>Run a relay for <code>Corda_Network2</code> as follows (do this only if you have launched both Corda networks <code>Corda_Network</code> and <code>Corda_Network2</code> and wish to test interoperation between them)</p> <ul> <li>Navigate to the <code>weaver/core/relay</code> folder.</li> <li>To launch the server without TLS, leave the configuration file <code>config/Corda_Relay2.toml</code> in its default state. Otherwise, edit it to set TLS flags for this relay and the other relays and drivers it will connect to in this demonstration as follows:   <pre><code>.\n.\ncert_path=\"credentials/fabric_cert.pem\"\nkey_path=\"credentials/fabric_key\"\ntls=true\n.\n.\n[relays]\n[relays.Fabric_Relay]\nhostname=\"localhost\"\nport=\"9080\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n[relays.Fabric_Relay2]\nhostname=\"localhost\"\nport=\"9083\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n[relays.Corda_Relay]\nhostname=\"localhost\"\nport=\"9081\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n.\n.\n[drivers]\n[drivers.Corda]\nhostname=\"localhost\"\nport=\"9098\"\ntls=true\ntlsca_cert_path=\"credentials/fabric_ca_cert.pem\"\n.\n.\n</code></pre></li> <li>To launch the server, simply run the following:   <pre><code>RELAY_CONFIG=config/Corda_Relay2.toml cargo run --bin server\n</code></pre></li> </ul> <p>If the relay starts up successfully, the following will be logged on your terminal:</p> <pre><code>Relay Name: \"Corda2_Relay\"\nRelayServer listening on [::1]:9082\n</code></pre>"},{"location":"weaver/getting-started/test-network/setup-packages/#corda-driver","title":"Corda Driver","text":"<p>The code for this lies in the <code>weaver/core/drivers/corda-driver</code> folder.</p>"},{"location":"weaver/getting-started/test-network/setup-packages/#building-corda-driver","title":"Building Corda Driver","text":"<p>Build the Corda driver module as follows:</p> <ul> <li>Navigate to the <code>weaver/core/drivers/corda-driver</code> folder.</li> <li>Create a copy of <code>github.properties.template</code> as <code>github.properties</code>.</li> <li>Replace <code>&lt;GITHUB email&gt;</code> with your GitHub email, and <code>&lt;GITHUB Personal Access Token&gt;</code> with the access token created above.</li> <li>Run the following:   <pre><code>make build\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/setup-packages/#configuring_1","title":"Configuring","text":"<p>Configure the drivers as follows (you can skip this if you wish to run the drivers without TLS):</p> <ul> <li>Navigate to the <code>weaver/core/drivers/corda-driver</code> folder and create a <code>.env</code> file.</li> <li>To run the drivers without TLS, set the following default values:   <pre><code>RELAY_TLS=false\nRELAY_TLSCA_TRUST_STORE=\nRELAY_TLSCA_TRUST_STORE_PASSWORD=\nRELAY_TLSCA_CERT_PATHS=\n</code></pre></li> <li>To run the drivers with TLS, set the following values (replace <code>&lt;PATH-TO-WEAVER&gt;</code> with the absolute path of the <code>weaver</code> folder within your Cacti repository clone):   <pre><code>RELAY_TLS=true\nRELAY_TLSCA_TRUST_STORE=&lt;PATH-TO-WEAVER&gt;/core/relay/credentials/fabric_trust_store.jks\nRELAY_TLSCA_TRUST_STORE_PASSWORD=trelay\nRELAY_TLSCA_CERT_PATHS=&lt;PATH-TO-WEAVER&gt;/core/relay/credentials/fabric_ca_cert.pem\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/setup-packages/#running_1","title":"Running","text":"<p>Run a Corda driver as follows:</p> <ul> <li>Navigate to the <code>weaver/core/drivers/corda-driver</code> folder.</li> <li>Run the following to start Corda driver for <code>Corda_Network</code>:   <pre><code>./build/install/driver-corda/bin/driver-corda\n</code></pre>   If the driver starts successfully, it should log the following message on your terminal:   <pre><code>Corda driver gRPC server started. Listening on port 9099\n</code></pre></li> <li>Run the following to start Corda driver for <code>Corda_Network2</code>:   <pre><code>DRIVER_PORT=9098 ./build/install/driver-corda/bin/driver-corda\n</code></pre>   If the driver starts successfully, it should log the following message on your terminal:   <pre><code>Corda driver gRPC server started. Listening on port 9098\n</code></pre></li> </ul>"},{"location":"weaver/getting-started/test-network/setup-packages/#tear-down-the-setup","title":"Tear Down the Setup","text":"<p>Bring down the test network's components as follows:</p> <ul> <li>Simply terminate the various relays and drivers, which are running in the foreground in different terminals</li> <li>To bring down the running Corda network:<ul> <li>Navigate to the <code>weaver/tests/network-setups/corda</code> folder.</li> <li>Run the following:   <pre><code>make clean\n</code></pre></li> </ul> </li> <li>To bring down all the running Fabric networks:<ul> <li>Navigate to the <code>weaver/tests/network-setups/fabric/dev</code> folder.</li> <li>Run the following:   <pre><code>make clean\n</code></pre></li> </ul> </li> </ul>"},{"location":"weaver/security-model/end-to-end-security/","title":"End-to-End Security","text":""},{"location":"weaver/security-model/end-to-end-security/#relay-security-model","title":"Relay Security Model","text":""},{"location":"weaver/security-model/end-to-end-security/#a-relayer-of-cryptographic-proofs","title":"A Relayer of Cryptographic Proofs","text":"<p>The primary function of the relay is to orchestrate the flow of cyrptographic messages between networks enabling a variety of interoperability modes:</p> <ul> <li>Transfer of data between networks</li> <li>Transfer of assets between networks</li> <li>Exchange of value between networks</li> </ul> <p>These cryptographic messages represent valid state in a distributed ledger and are generated using a range of cryptographic approaches, such as attestation by a set of authoritative nodes, a non-interactive proof of PoW, or a zero-knowledge proof (proof of computational integrity). The mechanisms for deriving such proofs rely on the model of trust provided by the underlying network of nodes. The relay thus plays no direct role in the generation of proofs, removing the need for remote agents (decentralized networks, applications or users) to trust the relay for proof veracity.</p> <p>The relay's message exchange protocol is in a state of development with a view towards supporting multiple interoperability modes. The current implementation however is limited to the transfer of data between networks. Future versions will enable asset and value transfers protocols.</p> <p>NOTE: The security models examined below is limited to the transfer of data where remote queries are initiated by applications.</p>"},{"location":"weaver/security-model/end-to-end-security/#deployment-configurations-and-security-implications","title":"Deployment Configurations and Security Implications","text":"<p>The relay acts as a gateway between networks for enabling cross-chain communication and supports flexible deployment configurations. </p> <p>The configuration in any deployment must statisfy the goals of the parties involved in the message exchange. These goals inform the security policy and the adversarial assumptions. The mechanisms for threat mitigation is based on these assumptions. </p> <p>The configurations described below assume that:</p> <ul> <li>A small fraction of the parties (e.g. f &lt; n - m, where 'm' is the minimum threshold required for agreement) in a group or network might be byzantine. </li> <li>The threat imposed by a byzantine party with priviledges to construct a valid proof is no worse if the party is also in control of a relay.</li> <li>A valid proof is one that satisfies a consumer's proof critieria (policy).</li> </ul>"},{"location":"weaver/security-model/end-to-end-security/#1-confidential-message-exchange-between-groups-of-parties","title":"1. Confidential Message Exchange Between Groups of Parties","text":"<p>Goals </p> <p>A group of parties sharing confidential data agree to share a view of their data to remote group. The system configuration will provide the following properties:</p> <ul> <li>Preserve confidentiality of messages exchanged between the groups involved.</li> <li>Preserve integrity of messages exchanged across the groups.</li> <li>The system must be available for servicing requests.</li> </ul> <p>Threat Assumptions</p> <p>An adversary in this configuration might seek to:</p> <ul> <li>Gain access to the confidential data.</li> <li>Tamper with the integrity of the messages exchanged.</li> <li>Censor messages.</li> <li>Deny service.</li> </ul> <p>Mechanisms for Threat Mitigation</p> <p>A suitable deployment configuration that addresses these threat assumptions:</p> <ul> <li>Relays will only be deployed and operated by organizations with access to the confidential data and privileges to construct valid proofs.</li> <li>A secure channel (mutual TLS) between the relays prevents external adversaries from evesdropping on the communication.</li> <li>The inclusion of a nonce in the proof enables replays of past messages to be detected.</li> <li>The deployment of multiple relays ensures availability and resistance to censorship.</li> </ul> <p>In the following configuration, a group in one network maintains confidential data and have similar goals as above. The data in the providing network is private but visible to all organizations. The relay in the providing network can be operated by any organization with access to the data (the implications of this are examined next).</p> <p></p>"},{"location":"weaver/security-model/end-to-end-security/#2-private-message-exchange-between-networks","title":"2. Private Message Exchange Between Networks","text":"<p>Goals</p> <p>In the following configuration, the data is private to both networks but not confidential to any subset of the members. The system configuration must provide the following properties:</p> <ul> <li>Preserve confidentiality of messages exchanged between the networks.</li> <li>Preserve integrity of messages exchanged across the networks.</li> <li>The system must be available for servicing requests.</li> </ul> <p>Threat Assumptions</p> <p>An adversary in this configuration might seek to:</p> <ul> <li>Gain access to the private data.</li> <li>Tamper with the integrity of the messages exchanged.</li> <li>Censor messages.</li> <li>Deny service.</li> </ul> <p>Mechanisms for Threat Mitigation</p> <p>A suitable deployment configuration that addresses the threat assumptions:</p> <ul> <li>Relays will be deployed and operated by organizations that are members of the network with access to the shared private data and privileges to construct valid proofs.</li> <li>A secure channel (mutual TLS) between the relays prevents external adversaries from evesdropping on the communication.</li> <li>The inclusion of a nonce in the proof enables replays of past messages to be detected.</li> <li>The deployment of multiple relays ensures availability and resistance to censorship.</li> </ul> <p></p>"},{"location":"weaver/security-model/end-to-end-security/#3-public-message-exchange-between-networks","title":"3. Public Message Exchange Between Networks","text":"<p>Goals</p> <p>A private network consumes data from a public permissionless network. The system configuration must provide the following properties:</p> <ul> <li>Preserve confidentiality of messages exchanged between the networks.</li> <li>Preserve integrity of messages exchanged across the networks.</li> <li>The system must be available for servicing requests.</li> </ul> <p>Threat Assumptions</p> <p>An adversary in this configuration might seek to:</p> <ul> <li>Monitor data accessed by the private network.</li> <li>Tamper with the integrity of the messages exchanged.</li> <li>Censor messages.</li> <li>Deny service.</li> </ul> <p>Mechanisms for Threat Mitigation</p> <p>A suitable deployment configuration that addresses the threat assumptions:</p> <ul> <li>Nodes (clients) of the public ledger will be deployed and operated by multiple organizations in the private network (a sufficient distribution to accomodate 'f' faulty nodes)<ul> <li>Nodes modified to sign responses with a valid identity certificate (e.g. Hyperledger Besu as Ethereum mainnet client).</li> </ul> </li> <li>Relays to private and public nodes will be deployed and operated by organizations within the network.</li> <li>The inclusion of a nonce in the proof enables replays of past messages to be detected.</li> <li>The deployment of multiple relays ensures availability and resistance to censorship.</li> </ul> <p></p> <p>The following alternate configuration allows for a public node to be operated by a single organization. The oracle provides trusted meta-data to ensure proofs can be validated correctly (E.g. current validator set used for signing blocks in PoS/BFT sysmtems and block height to verify currency of state. A formal study on mechanisms for proof construction and their short-commings has been deferred).</p> <p></p> <p>In the following configuration an external notary acts as an authoritative source for public ledger data. A secure channel (mutual TLS) between the relays prevents external adversaries from evesdropping on the communication.</p> <p></p>"},{"location":"weaver/security-model/end-to-end-security/#nonces-and-replay-attacks","title":"Nonces and Replay Attacks","text":""},{"location":"weaver/user-stories/financial-markets/","title":"DvP in Financial Markets","text":"<p>In traditional financial markets parties trade assets such as securities and derivatives for cash or other assets. To reduce risk, various clearing and settlement processes and intermediaries are often involved. One form of settlement is a DvP (delivery versus payment) where the transfer of securities is performed only in the event of a corresponding payment. This arrangement reduces principal risk by ensuring that both parties receive their end of the exchange. However, settlement in financial markets are slow and time consuming. It also involves counterparty risks and requires intermediaries.</p> <p>Over the past few years, we have been seeing significant efforts in digitising and tokenising both currencies and securities on Distributed Ledger Technology (DLT) infrastructures. On the one hand we have seen concerted efforts around Central Bank Digital Currencies (CBDC) being added to the landscape of other blockchain based payment networks. On the other hand, we have also seen efforts such as that from the Australian Stock Exchange (ASX) to replace its current settlement system--Clearing House Electronic Subregister System (CHESS) with a DLT based platform by 2021.</p> <p>Against this backdrop, a number of central banks have been exploring the potential of performing DvP settlement across a currency ledger and a securities ledger. In this use case, we use this as a motivating use-case for our discussions. The scenario involves two decentralised ledgers, namely, a currency ledger and a securities ledger, based on different DLT protocols performing a coordinated transfer of assets in their respective ledgers.</p> <p>The figure below depicts this scenario in the context of two organisations--Org-A and Org-B. Org-B wants to purchase some securities owned by Org-A and both organisations have accounts on both ledgers. This scenario is simplified and leaves out a number of additional real world processes. For instance, the buyer and seller for securities need to discover each other and agree on the price and terms of a sale. In addition, an offer to sell securities might be fulfilled by multiple buyers taking smaller portions of the amount for sale. Such capabilities are often offered by centralised exchanges that offer capabilities such as order books and matching engines to address these needs. In this scenario we instead focus on the settlement process that follows such steps, once the parties of an exchange and the price of the exchange for an asset are determined.</p> <p>To effect the settlement of this exchange between Org-A and Org-B, the following two transactions will have to happen atomically across both networks: i) transfer of payment from Org-B's currency account in the CBDC ledger to Org-A while at the same time ii) the entitlements of the designated securities are transferred from Org-A to Org-B. The scenario would need to guarantee that after the transaction execution, either both parties have their end of the exchange or neither does and that this exchange is performed in a timely manner.</p> <p></p> <p>The settlement of the exchange of securities from Org-A to Org-B in the Financial Securities Network for a simultaneous payment from Org-B to Org-A in the CBDC network is coordinated by Weaver using Hashed Time Lock Contracts. This protocol essentially has three phases:</p> <ul> <li>Fund locking: To initialise an asset exchange, it is common for one or both parties to first lock up funds with a fund-withholding party on his or her own blockchain. Temporary fund locking ensures the locked fund cannot be used for other purposes while the exchange is being executed. This scheme is often used with a specified timeout to provide flexibility for reclaiming locked funds if the exchange does not take place.</li> <li>Fund redeeming: In general, the execution requires a pair of transactions to occur on both blockchains, e.g., from Org-A to Org-B on the FSN ledger and from Org-B to Org-A in CBDC ledger. When certain conditions are met, the locked funds can be redeemed by, or paid to the respective users. The execution of the exchange can be carried out by users themselves, or through other trusted third parties. These trusted third parties can be stand-alone parties that are not otherwise involved in both blockchains, or part of either blockchain.\u00a0</li> <li>Refund: For protocols that are initialised with a temporary fund-locking, the locked funds can usually be reclaimed by the initial owner after a specified timeout, if a redemption has not occurred.\u00a0</li> </ul> <p>The process proceeds as follows, and is further illustrated in the figure below:</p> <ol> <li>Org-A locks its securities in FSN ledger: Org-A first creates some secret S, known only to it and locks its securities using the hash of S. The securities are configured to redeemable by Org-B if it presents S within some specified time threshold.</li> <li>Org-B locks payments tokens in CBDC ledger: Org-B, observes that Org-A has locked its securities in the FSN network and does a corresponding lock of its payment tokens with the hash of S, used by Org-A in locking its securities. The payment tokens are redeemable only by Org-A, if it submits a transaction that reveals S within a specified time.</li> <li>Org-A checks Org-B's contract in CBDC ledger: Org-A checks the CBDC network to ensure that the payments tokens are locked by Org-B.</li> <li>Org-A claims payments in CBDC ledger: Org-A submits a transaction to claim the payments tokens, by revealing the secret S.</li> <li>Org-B claims securities in FSN ledger: Org-B observes that the value of S has been revealed in the CBDC network by Org-A in step 4, and submits a transaction to claim the securities in the FSN network using the revealed secret.</li> </ol> <p></p>"},{"location":"weaver/user-stories/global-trade/","title":"Global Trade","text":"<p>The examples in this page cover the global trade application domain and the data sharing pattern.</p>"},{"location":"weaver/user-stories/global-trade/#process-overview","title":"Process Overview","text":"<p>At its simplest, international trade is about a party in one country buying certain goods from a party in another country. Because the goods cross international boundaries, the buyer is called an importer and the seller is called an exporter. For the same reason, this process is not as straightforward as, say, purchasing an item from a retailer.</p> <p>The exporting of goods in most countries is governed by a host of regulatory provisions and authorities, making the very act of clearing the sale and getting the goods ready for shipment a complex one. Further, an exporter must rely on one or more carriers to move the shipment from source to destination while managing all of the risks this entails.</p> <p>But this only covers the shipping logistics. The trading parties, i.e., the exporter and importer, both face what is called counterparty risk, or the hazard of giving something up without a guarantee of receiving something in return. If the exporter ships the goods first, the importer may renege on the payment. And if the importer mmakes the payment first, the exporter may renege on the shipment. To hedge against this risk, sophisticated process of trade finance have evolved over centuries, with banks or other financial institutions providing the sorts of guarantees (in exchange for fees) that enable exporters and importers to safely conduct trades.</p> <p>Permissioned blockchains are a great fit to manage such trade scenarios, involving multiple independent entities and no governing authorities, using smart contracts. Let us now see two kinds of processes in action, each of which can be managed in its own restricted network:</p> <ol> <li>Trade logistics: preparation, clearance, and export of goods</li> <li>Trade finance: payment guarantees and fulfillment</li> </ol>"},{"location":"weaver/user-stories/global-trade/#networks-in-isolation","title":"Networks in Isolation","text":"<p>There exist real business networks in production that manage trade logistics and finance, but they can be very complex. We will present highly simplified versions of these processes, and focus on the aspects that will motivate the need for data sharing across networks.</p> <p>Also, we will henceforth use the terms buyer and seller instead of importer and exporter respectively.</p>"},{"location":"weaver/user-stories/global-trade/#initiating-a-trade","title":"Initiating a Trade","text":"<p>Our trade process begins offline, with buyer and seller negotiating and agreeing on the sale of particular goods for given payment. We will assume that a purchase order is created and contains a unique id we can use as reference in subsequent steps. This is illustrated in the figure below.</p> <p></p>"},{"location":"weaver/user-stories/global-trade/#trade-logistics-network","title":"Trade Logistics Network","text":"<p>The figure below represents a trade logistics network consisting of a seller and a carrier, loosely inspired by the TradeLens network built on Hyperledger Fabric. Think of the seller as a coffee plantation owner is Brazil, for example, and the carrier as a prominent shipping company like Maersk.</p> <p></p> <p>The seller begins by booking a shipping consignment (associated with the purchase order id) and then registering its creation. It then hands the consignment over to the carrier. In a real life export scenario, this process involves a lot of documentation and approval cycles, but we are going to ignore all of those here. The carrier supplies documents certifying its possession of the consignment and the contents within it. The bill of lading (B/L for short) is one of these documents, and though there may be others, like a packing list and a shipping manifest, we only need one to motivate interoperability. So we will keep it simple and assume that the carrier simply uploads a B/L. The seller examines and accepts this document, following which the carrier dispatches the consignment.</p> <p>Note that, at this point, a valid B/L is recorded on the trade logistics network ledger, a fact we will make use of soon enough.</p>"},{"location":"weaver/user-stories/global-trade/#trade-finance-network","title":"Trade Finance Network","text":"<p>The figure below represents a trade finance network consisting of a seller, a buyer, and their respective banks. This is loosely inspired by the We.Trade network built on Hyperledger Fabric and the Marco Polo network built on R3 Corda. Think of the seller as our coffee plantation owner in the logistics network, the buyer as Starbucks, and the banks as Bank of America and HSBC Bank, for example.</p> <p></p> <p>Traders and banks use a variety of mechanisms to mitigate counterparty risk, one of them being open accounting, used in networks like We.Trade. We pick the popular letter of credit (L/C for short) instrument for our trade finance story as this exemplifies the inherent link between logistics and finance (we will see this later). The process begins with the buyer requesting an L/C from its bank for a given trade, referring to the id of the purchase order generated earlier. In simplest terms, an L/C is a promise made by a bank to pay a certain amount to the bearer of certain documents associated with a given export shipment. In our scenario, the buyer's bank issues an L/C promising to pay the seller (through its bank) the amount due to it upon production of a valid B/L. This L/C proposal is recorded on the ledger, and subsequently approved by the seller's bank. After the seller uploads a B/L, the seller's bank is allowed to register a request for payment. This leaves a payment obligation for the buyer's bank on the ledger, which is where we will conclude the scenario, as the actual payment is carried out through a separate process on a different network.</p> <p>Note that the seller is supposed to produce and record a valid B/L in Step 4.</p>"},{"location":"weaver/user-stories/global-trade/#linking-finance-with-logistics","title":"Linking Finance with Logistics","text":"<p>It is obvious that the logistics and finance processes are linked. Both begin with references to a common purchase order id and both involve bills of lading. Let us focus on the B/L, as it exemplifies a common pattern in these kinds of business networks: that of being generated in one network and being used in another. Because thee are two separate networks, the trade finance network depends on the seller to upload a B/L. But here, we encounter another kind of hazard, one we discussed earlier in the challenges section. The seller has an incentive to produce a fake bill of lading in order to get paid for goods it may not have dispatched and may have no intention of dispatching. In the present setup, the trade finance network as a whole, nor the buyer or its bank, has visibility into the trade logistics network's ledger, and hence have to trust the seller's word.</p> <p>This hazard can be avoided if the networks are interoperable, and can share data with each other. Specifically, if the trade logistics network can share a B/L recorded on its ledger institutionally with the trade finance network. To see how this works, see the diagram below, which contains both the networks and merges their flows.</p> <p></p> <p>Step 4 in the isolated trade finance network is now replaced with an interoperation step (Step 10) whereby the trade finance network obtains a B/L from the trade logistics network via a data-sharing protocol. This avoids the hazard of having to depend on an unreliable seller to supply a valid B/L. But it is not enough for the trade logistics network to share B/L data. It must also share some proof or evidence that the B/L is presently on record in its shared ledger.</p> <p>Note: in general, an interoperation mechanism for data sharing must communicate data as well as an associated proof that can be independently verified by every memebr of the receiving network.</p>"},{"location":"weaver/user-stories/global-trade/#extending-the-scenario","title":"Extending the Scenario","text":"<p>The above example conforms to how the logistics and finance processes work today. Letters of credit typically specify bills of lading among the lists of documents that must be supplied to claim a payment. But state-of-the-art blockchain technology and permissioned networks can facilitate a lot more process innovation than earlier technology could.</p> <p>The present trade logistics network allows a consignment to be created and dispatched without any knowledge of how the trade will be financed. But in real life, there is a need to track imports and exports carefully to ensure that no regulations are broken, and secondarily, to avoid wasted effort. Therefore, we can envision trade logistics networks requiring some evidence of the financial arrangements of a trade before it allows a seller and a carrier to carry out with the shipping process.</p> <p>The process augmentation is illustrated in the figure below with the insertion of a new Step 6 between the booking and the creation of a shipping consignment.</p> <p></p> <p>Like Step 11 (Step 10 in the earlier figure), this is a data-sharing interoperation step where the L/C proposed and accepted on the trade finance network's ledger is copied to the trade logistics network's ledger. (As with the B/L sharing, proof of the L/C ledger record must accompany L/C data.) In this new process, the trade logistics network will not waste time processing shipments that do not have a backing L/C guarantee from the trade finance network.</p> <p>Note that in the interoperation steps, the artifact being shared by one network with another (B/L or L/C) does not have to be copied verbatim to the receiving network's ledger. The process incorporates transformations carried out through smart contract transactions occurring through their networks' native consensus mechanisms.</p>"},{"location":"weaver/user-stories/global-trade/#vision-network-of-networks","title":"Vision: Network of Networks","text":"<p>The promise of blockchain was a more decentralized yet trustworthy internet, but as we saw earlier, networks like Bitcoin and Ethereum may not fulfill that promise, largely because they have technical limitations when it comes to performance and scaling, privacy preservation, and auditability. At the same time, private blockchain networks are here to stay, and they do overcome these technical limitations, albeit at smaller scale. In the longer term, a more sustainable and achievable vision will be to allow private networks to exist while possessing the means to interoperate with other private networks. The interlinking of a trade logistics network with a trade finance network was just a sample. There is more aspects to an international trade scenario: more networks and more cross-network dependencies. But as long as we can institute mechanisms to link two networks directly for data-sharing, we can extrapolate our two-network scenario into a network-of-networks scenario.</p> <p>To show how this will work, we will add two more networks to the mix. Business networks exist to track the quality and health of perishable goods from the production source to the end retailer. These networks complement networks like Trade Lens, which manage the long-distance shipping that occurs in the middle but have no visibiity into the goods before consignment creation or after delivery at the destination by the carrier. To track goods at either ends is the function of networks like IBM Food Trust, which would be ideal for the coffee shipment example we used earlier. A separate aspect of our trade scenario is the actual payment a buyer makes to the seller. Our trade finance network ends by recording a payment obligation, but the transfer of money needs to occur on a separate payment network, like, for example, the Stellar Network.</p> <p>The figure below presents our vision for how cross-network data sharing can help smoothen and simplify all aspects of global trade despite the fact that different sub-processes occur on independent private networks.</p> <p></p> <p>The Food Tracking Network is loosely inspired by IBM Food Trust and the Payments Network loosely inspired by Stellar.</p> <ul> <li>The seller and buyer, as the trading parties, belong to the food tracking network. The process in this network begins with a registration of a purchase order, following which perishable goods (think coffee seeds, for example) are tracked from farms to a warehouse where a shipping consignment is created. Whenever the carier delivers the shipment, the fact of delivery is recorded as is the condition of the goods within.</li> <li>The payment network has the buyer's and seller's bank as members. Action in this network is triggered by the buyer's bank making a payment, or a monetary transfer, to the seller's bank. Both banks have accounts in this network and the payment succeeds or fails depending on available account balance.</li> </ul> <p>There are two parallel timelines starting at Step 17:</p> <ul> <li>One involves the trade finance network and the payments network (Steps 17-20). Step 18 contains both \"Make Payment\" and \"Receive Payment\" as these actions are supposed to occur atomically within the payments network. These pertain to the fulfilment of the payment promised to the seller by the buyer.</li> <li>Another involves the trade logistics network and the food tracking network (Steps 17-19). These pertain to the tracking of goods after dispatch and confirmation of their subsequent delivery and condition.</li> </ul> <p>You may notice we have augmented the trade logistics and trade finance processes as follows:</p> <ul> <li>Step 17 in the trade logistics network illustrates a sequence of transactions, each recording the location and condition of the goods in transit at periodic intervals. We assume that this information can be procured using sensors deployed with the consignment.</li> <li>Step 20 in the trade finance network results in the cancelling of the payment obligation recorded by the seller's bank in Step 17 within that network (\"Request Payment\"), thereby concluding the trade instance associated with the purchase order id generated in Step 1.</li> </ul> <p>The data-sharing interoperation steps are as follows:</p> <ul> <li>Step 3: The trade finance network fetches a purchase order from the food tracking network before permitting an L/C request to be made.</li> <li>Step 8: The trade logistics network fetches an L/C from the trade finance network before permitting a consignment to be created.</li> <li>Step 9: The food tracking network fetches a consignment booking record and an associated L/C from the trade logistics network before permitting tracking of goods from the source to the shipping warehouse.</li> <li>Step 11: The trade logistics network fetches tracking information indicating delivery of goods to the warehouse before permitting a consignment to be created.</li> <li>Step 16: The trade finance network fetches a B/L from the trade logistics network before permitting the seller's bank to register a payment request.</li> <li>Step 18: This is a recurring step, in each instance of which the food tracking network fetches location and condition information for a given consignment from the trade logistics network, and does not permit the confirmation of consignment delivery and the integrity of the goods within until the shipment reaches its destination and its condition meets the required standard.</li> <li>Step 19: The trade finance network gets confirmation of payment (from buyer's account to seller's account) from the payments network.</li> </ul> <p>To summarize, internationally traded goods can be tracked from a farm in one country to a retailer in another, the goods can be exported and shipped with all regulations complied with, financial guarantees can be put in place to safeguard the trading parties, and cross-border payments can be processed seamlessly and in a trustworthy manner. But this requires a combination of private blockchain networks willing to share data with each other and also have the ability to verify the authenticity of received data. We hope this scenario makes the motivation for data-sharing interoperation mechanisms perfectly clear.</p>"},{"location":"weaver/user-stories/legacy-integration/","title":"Legacy Integration","text":"<p>A standard for self-contained messages respresenting state in distributed ledgers, along with proofs of validity, enables interoperability with legacy enterprise applications. These messages can be consumed, stored or forwarded by any traditional centralized application.</p> <p></p>"},{"location":"weaver/user-stories/overview/","title":"Overview","text":"<p>In the introduction, we listed various modes (or patterns) of interoperation like asset transfers, asset exchanges, and data sharing. In IT parlance, we can think of this as a horizontal classification of use cases for interoperability. In this section of the documentation, we will discuss the verticals, or application domains, that exemplify the use and necessity of interoperation mechanisms.</p>"},{"location":"weaver/user-stories/overview/#application-domains","title":"Application Domains","text":"<p>Distributed ledger technology has been applied gainfully to several areas where legacy processes were inefficient, cumbersome, and error-prone. With the enablement of interoperation among these networks, they have the potential to take the next step toward a truly decentralized yet trustworthy internet. We call out two prominent focus areas.</p>"},{"location":"weaver/user-stories/overview/#global-trade","title":"Global Trade","text":"<p>Trade when seen from a global and international perspective is highly complex. In the absence of central coordinating and law-enforcing authorities at the world level, various ad hoc processes have been created and refined over centuries by merchants, financiers, and regulators, to manage complex supply-chain logistics and cross-border financing that underpin global trade. These processes exist to ensure that parties can hedge their risks, mitigate possibilities for non-compliance, and ship goods from one location to another while complying with regulatory guidelines.</p> <p>Multiple networks have emerged to handle trade processes limited in scope. There exist networks to handle trade logistics (like TradeLens, built on Hyperledger Fabric), food tracking (IBM Food Trust, built on Hyperledger Fabric), trade finance (like We.Trade, built on Hyperledger Fabric, and Marco Polo, built on R3 Corda), cross-border payments, and know-your-customer, or KYC, processes. An end-to-end trade scenario, involving shipment of goods, financing commitments, documentation, shipping, tracking, and payments, will rely on many or all of these networks. Interoperation will help us overcome this fragmentation and lack of visibility of one network into another, and enable trustworthy and efficient trades at global scale using blockchain technology. See Global Trade for a concrete example.</p>"},{"location":"weaver/user-stories/overview/#financial-markets","title":"Financial Markets","text":"<p>Securities trading is a common and lucrative transaction in financial markets. As with any form of exchange, when a security is sold in exchange for money, the party that gives up its asset first faces a non-compliance risk; i.e., the other party may renege on the deal after it receives an asset. With the advent of blockchain-backed digital currencies maintained by countries' central banks, opportunities now exist to carry out security trades safely and efficiently. But this requires interoperation between networks managing digital currency on behalf of central banks (like private versions of Bitcoin networks with faster commitment times) and networks managing tracking securities and their ownerships. See DvP in Financial Markets for a concrete example.</p>"},{"location":"weaver/user-stories/overview/#other-scenarios","title":"Other Scenarios","text":"<p>There are other domains or verticals we can think of that would benefit from interoperation. Healthcare is one, where different networks may exist: citizens' identity records, employer network, healthcare provider network, insurance companies' network, etc. For efficiency of operation (with privacy preservation guarantees) and to ensure that service and payments occur promptly and accurately, these networks may seek to interoperate. Similarly, interoperation between networks that manage users' academic and professional credentials may help employers and job seekers.</p>"},{"location":"weaver/what-is-interoperability/integration-patterns/","title":"Integration Patterns","text":"<p>Integration patterns are well-known reusable solutions for integrating systems together. A number of patterns exist for addressing various types integration problems. The specific pattern applied in practice depends on the nature of the integration problem, the overall objective of the integration task, trade-offs in alternate approaches, and potential risks.</p>"},{"location":"weaver/what-is-interoperability/integration-patterns/#distributed-ledger-integration-patterns","title":"Distributed Ledger Integration Patterns","text":"<p>Here we present common patterns for integrating distributed ledgers. Not all problems are equal, some approaches to itegrating ledgers are preferred over others depending on the use case, the purpose of the itegration and the risks involved.</p>"},{"location":"weaver/what-is-interoperability/integration-patterns/#consensus-based-integration-between-ledgers","title":"Consensus-based integration between ledgers","text":"<p>Consensus-based integration aims to communicate the consensus view of one network to another. The consensus view is a representation of state on the ledger that is collectively agreed by the members of the network. This form of integration provides the highest assurance on the validity of state. The Weaver framework is designed to address consensus-based integration between ledgers built on different distributed ledger protocols.</p> <p></p>"},{"location":"weaver/what-is-interoperability/integration-patterns/#standard-api-integration-between-applications","title":"Standard API integration between applications","text":"<p>A standard API integration relies on a single party exposing an endpoint for state exchange. The validity of state relies entirely on the trust placed on the party exposing the endpoint.</p> <p></p>"},{"location":"weaver/what-is-interoperability/integration-patterns/#single-enterprise-participating-in-multiple-neworks","title":"Single enterprise participating in multiple neworks","text":"<p>A single enterprise participating in multiple networks can integrate state and contract logic across these networks using off-chain workflows. Unlike the previous pattern, this pattern relies on the enterprise having valid membership credentials on multiple networks. Significant trust must be placed on the organization coordianting the exchange of state across these networks.</p> <p></p>"},{"location":"weaver/what-is-interoperability/integration-patterns/#single-network-deployed-on-multiple-heterogenous-infrastructure","title":"Single network deployed on multiple heterogenous infrastructure","text":"<p>Although not an integration pattern, this pattern demonstrates interoperability at the infrastructure layer. The ability to run nodes on multiple cloud providers, as well as on-prem infrastructure, ensures networks are resilient to failures or censorship by infrastructure providers.</p> <p></p>"},{"location":"weaver/what-is-interoperability/levels-of-interoperability/","title":"Levels of Interoperability","text":"<p>Established models of information systems interoperability stratify interoperability concerns into multiple levels. This includes technical, syntactic, semantic and application levels as shown below. </p> <p>Above the protocol and application levels there are two additional levels that require careful attention when enabling interoperability. These cover governance and policy decisions when communicating state as well as the legal and regulatory implications of networks under different jurisdictions.</p> <p></p> <ul> <li> <p>Technical: The technical level is a low-level concern that focuses on the underlying wire protocol used for communication. Examples of protocols at this level include gRPC, Apache Thrift, ASN.1 and CBOR. Protocols at this level are point-to-point and addresses additional concerns such as version negotiation and message delivery guarantees.</p> </li> <li> <p>Syntactic: The syntactic level is concerned with the structure and format of the messages exchanged. This includes protocol elements such as keywords and types. Examples include protocols defined using Google's Protocol Buffers, JSON-RPC and ASN.1.</p> </li> <li> <p>Semantic: The semantic level provides meaning to the messages exchanged. In the context of cross-chain communication, this includes messages that represent a data transfer or an asset exchange as well as other information such as validity proofs and actors involved.</p> </li> <li> <p>Application: The application level addresses domain or use-case specific concerns. In this level, interoperability deals with industry standard data models (e.g. supply chain standards such as GS1) and business processes. This level is orthogonal to the technology concerns of interoperability.</p> </li> <li> <p>Governance and Policies: The governing members of a ledger play a critical role in extending business processes to external systems. Interoperability necessitates that the governing bodies of the respective systems agree on the nature of their collaboration. The policies enforce these decisions and covers aspects such as access control and conditions for determining the validity of state proofs.</p> </li> <li> <p>Legal and Regulation: Networks residing in different jurisdictions must be comply with existing laws and regulations when communicating state.</p> </li> </ul>"},{"location":"weaver/what-is-interoperability/understanding-interoperability/","title":"Understanding Interoperability","text":"<p>Permissioned DLTs have been gaining significant traction in industry since their inception. They have enabled enterprises to harness the innovation of public blockchains, while adhering to the privacy, confidentiality and regulatory constraints that businesses operate under. Permissioned DLTs offer enterprises an infrastructure for managing inter-firm asset, data and business workflow, without the need for a central intermediary that introduces additional sources of risk. Businesses are able to transact directly while reducing counter-party risk and mitigating the need for costly and time-consuming dispute resolution processes, often involving legal and judicial systems. Thus far, the application of this technology has enabled digitisation and disintermediation of many entrenched industry processes, resulting in significant improvements in efficiency, transparency, risk and fraud.</p> <p>For practical reasons, the adoption of permissioned blockchains has thus far been driven through use-cases. Enterprises have been coalescing into consortia to create specialised networks that address narrowly-scoped use-cases in isolation. This use-case driven approach to blockchain adoption is creating a proliferation of niche and isolated networks that are quickly becoming data and value silos. In addition, these use-cases often represent a slice of a complex end-to-end business process. To deliver real value, permissioned networks need to seamlessly integrate with each other and with existing systems in order to holistically transform industries. This requirement for interoperation is coming to the fore as networks transition to production and scale towards broader adoption.</p> <p>Interoperability in the context of Distributed Ledger Technologies involves enabling the seamless flow of data and value across disparate networks in a manner that preserves their trust and security tenets. This capability can offer a number of benefits such as:</p> <ul> <li>Removing data and value silos</li> <li>Increasing market sizes, liquidity and overall efficiency</li> <li>Improving network effects</li> <li>Enabling orchestration of complex business functionality across networks</li> <li>Enabling scale and groawth of networks</li> <li>Encouraging further adoption of the technology</li> </ul>"},{"location":"weaver/what-is-interoperability/understanding-interoperability/#unique-technical-challenges","title":"Unique Technical Challenges","text":"<p>Enabling interoperation between distributed ledgers presents numerous technical challenges compared to traditional systems integration approaches. This primarily stems from the need to preserve the benefits of decentralised trust beyond the boundaries of a single network. Hence, a naive approach to interoperability based on traditional point-to-point API integration is insufficient for preserving the underlying trust decentralised networks provide. There are two unique challenges present in DLT interoperation:</p>"},{"location":"weaver/what-is-interoperability/understanding-interoperability/#single-party-vs-multi-party-trust","title":"Single-party vs Multi-party Trust","text":"<p>In distributed ledger architectures, the authority over state lies in a collective and the protocol they employ to ensure its integrity. When one network or an entity consumes state from another, it would need to establish the veracity of the state according to the shared consensus view of parties in the network. This requirement is different than traditional integration with centralised systems wherein the trust for the validity of data is placed on the single party providing the data. Establishing the veracity of state in a decentralized network is not trivial. In most cases, a consumer of state might not be able to observe the full ledger of the network itself.\u00a0Hence, a consumer needs to obtain an independently verifiable cryptographic proof on the validity of state according to the consensus rules and policies of the source network.</p> <p></p>"},{"location":"weaver/what-is-interoperability/understanding-interoperability/#data-vs-asset","title":"Data vs Asset","text":"<p>Interoperation should not compromise the invariants enforced by individual networks such as protections against double spends on assets.</p>"},{"location":"weaver/what-is-interoperability/understanding-interoperability/#the-role-of-standards","title":"The Role of Standards","text":"<p>The term \u2018interoperability\u2019 is used rather loosely in many contexts and oftentimes without the same implication. What some call \u2018interoperability\u2019, others refer to as \u2018integration\u2019, \u2018interconnectivity\u2019 or \u2018compatibility\u2019.</p> <p>The primary goal of interoperability is freedom of choice. Interoperability enables users to choose implementations of systems they find suitable for a given problem without constraints on the system\u2019s ability to communicate with other implementations. </p> <p>Implicit in the term interoperability is open standards, which distinguishes it from any form of bespoke integration. Open standards can either be de jure standards ratified by a formal standards organization such as ANSI, IETF, or ISO, or de facto standards proposed and adopted by communities, industries and the market. Open standards enable and encourage implementors to build systems that can work together.</p>"}]}