// Copyright the Hyperledger Fabric contributors. All rights reserved.
//
// SPDX-License-Identifier: Apache-2.0

// @generated by protoc-gen-es v2.2.2 with parameter "target=ts"
// @generated from file orderer/kafka.proto (package orderer, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage } from "@bufbuild/protobuf/codegenv1";
import { enumDesc, fileDesc, messageDesc } from "@bufbuild/protobuf/codegenv1";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file orderer/kafka.proto.
 */
export const file_orderer_kafka: GenFile = /*@__PURE__*/
  fileDesc("ChNvcmRlcmVyL2thZmthLnByb3RvEgdvcmRlcmVyIq8BCgxLYWZrYU1lc3NhZ2USLwoHcmVndWxhchgBIAEoCzIcLm9yZGVyZXIuS2Fma2FNZXNzYWdlUmVndWxhckgAEjUKC3RpbWVfdG9fY3V0GAIgASgLMh4ub3JkZXJlci5LYWZrYU1lc3NhZ2VUaW1lVG9DdXRIABIvCgdjb25uZWN0GAMgASgLMhwub3JkZXJlci5LYWZrYU1lc3NhZ2VDb25uZWN0SABCBgoEVHlwZSK0AQoTS2Fma2FNZXNzYWdlUmVndWxhchIPCgdwYXlsb2FkGAEgASgMEhIKCmNvbmZpZ19zZXEYAiABKAQSMQoFY2xhc3MYAyABKA4yIi5vcmRlcmVyLkthZmthTWVzc2FnZVJlZ3VsYXIuQ2xhc3MSFwoPb3JpZ2luYWxfb2Zmc2V0GAQgASgDIiwKBUNsYXNzEgsKB1VOS05PV04QABIKCgZOT1JNQUwQARIKCgZDT05GSUcQAiItChVLYWZrYU1lc3NhZ2VUaW1lVG9DdXQSFAoMYmxvY2tfbnVtYmVyGAEgASgEIiYKE0thZmthTWVzc2FnZUNvbm5lY3QSDwoHcGF5bG9hZBgBIAEoDCJ+Cg1LYWZrYU1ldGFkYXRhEh0KFWxhc3Rfb2Zmc2V0X3BlcnNpc3RlZBgBIAEoAxImCh5sYXN0X29yaWdpbmFsX29mZnNldF9wcm9jZXNzZWQYAiABKAMSJgoebGFzdF9yZXN1Ym1pdHRlZF9jb25maWdfb2Zmc2V0GAMgASgDQlgKJW9yZy5oeXBlcmxlZGdlci5mYWJyaWMucHJvdG9zLm9yZGVyZXJaL2dpdGh1Yi5jb20vaHlwZXJsZWRnZXIvZmFicmljLXByb3Rvcy1nby9vcmRlcmVyYgZwcm90bzM");

/**
 * KafkaMessage is a wrapper type for the messages
 * that the Kafka-based orderer deals with.
 *
 * @generated from message orderer.KafkaMessage
 */
export type KafkaMessage = Message<"orderer.KafkaMessage"> & {
  /**
   * @generated from oneof orderer.KafkaMessage.Type
   */
  Type: {
    /**
     * @generated from field: orderer.KafkaMessageRegular regular = 1;
     */
    value: KafkaMessageRegular;
    case: "regular";
  } | {
    /**
     * @generated from field: orderer.KafkaMessageTimeToCut time_to_cut = 2;
     */
    value: KafkaMessageTimeToCut;
    case: "timeToCut";
  } | {
    /**
     * @generated from field: orderer.KafkaMessageConnect connect = 3;
     */
    value: KafkaMessageConnect;
    case: "connect";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message orderer.KafkaMessage.
 * Use `create(KafkaMessageSchema)` to create a new message.
 */
export const KafkaMessageSchema: GenMessage<KafkaMessage> = /*@__PURE__*/
  messageDesc(file_orderer_kafka, 0);

/**
 * KafkaMessageRegular wraps a marshalled envelope.
 *
 * @generated from message orderer.KafkaMessageRegular
 */
export type KafkaMessageRegular = Message<"orderer.KafkaMessageRegular"> & {
  /**
   * @generated from field: bytes payload = 1;
   */
  payload: Uint8Array;

  /**
   * @generated from field: uint64 config_seq = 2;
   */
  configSeq: bigint;

  /**
   * @generated from field: orderer.KafkaMessageRegular.Class class = 3;
   */
  class: KafkaMessageRegular_Class;

  /**
   * @generated from field: int64 original_offset = 4;
   */
  originalOffset: bigint;
};

/**
 * Describes the message orderer.KafkaMessageRegular.
 * Use `create(KafkaMessageRegularSchema)` to create a new message.
 */
export const KafkaMessageRegularSchema: GenMessage<KafkaMessageRegular> = /*@__PURE__*/
  messageDesc(file_orderer_kafka, 1);

/**
 * @generated from enum orderer.KafkaMessageRegular.Class
 */
export enum KafkaMessageRegular_Class {
  /**
   * @generated from enum value: UNKNOWN = 0;
   */
  UNKNOWN = 0,

  /**
   * @generated from enum value: NORMAL = 1;
   */
  NORMAL = 1,

  /**
   * @generated from enum value: CONFIG = 2;
   */
  CONFIG = 2,
}

/**
 * Describes the enum orderer.KafkaMessageRegular.Class.
 */
export const KafkaMessageRegular_ClassSchema: GenEnum<KafkaMessageRegular_Class> = /*@__PURE__*/
  enumDesc(file_orderer_kafka, 1, 0);

/**
 * KafkaMessageTimeToCut is used to signal to the orderers
 * that it is time to cut block <block_number>.
 *
 * @generated from message orderer.KafkaMessageTimeToCut
 */
export type KafkaMessageTimeToCut = Message<"orderer.KafkaMessageTimeToCut"> & {
  /**
   * @generated from field: uint64 block_number = 1;
   */
  blockNumber: bigint;
};

/**
 * Describes the message orderer.KafkaMessageTimeToCut.
 * Use `create(KafkaMessageTimeToCutSchema)` to create a new message.
 */
export const KafkaMessageTimeToCutSchema: GenMessage<KafkaMessageTimeToCut> = /*@__PURE__*/
  messageDesc(file_orderer_kafka, 2);

/**
 * KafkaMessageConnect is posted by an orderer upon booting up.
 * It is used to prevent the panic that would be caused if we
 * were to consume an empty partition. It is ignored by all
 * orderers when processing the partition.
 *
 * @generated from message orderer.KafkaMessageConnect
 */
export type KafkaMessageConnect = Message<"orderer.KafkaMessageConnect"> & {
  /**
   * @generated from field: bytes payload = 1;
   */
  payload: Uint8Array;
};

/**
 * Describes the message orderer.KafkaMessageConnect.
 * Use `create(KafkaMessageConnectSchema)` to create a new message.
 */
export const KafkaMessageConnectSchema: GenMessage<KafkaMessageConnect> = /*@__PURE__*/
  messageDesc(file_orderer_kafka, 3);

/**
 * KafkaMetadata is encoded into the ORDERER block to keep track of
 * Kafka-related metadata associated with this block.
 *
 * @generated from message orderer.KafkaMetadata
 */
export type KafkaMetadata = Message<"orderer.KafkaMetadata"> & {
  /**
   * LastOffsetPersisted is the encoded value for the Metadata message
   * which is encoded in the ORDERER block metadata index for the case
   * of the Kafka-based orderer.
   *
   * @generated from field: int64 last_offset_persisted = 1;
   */
  lastOffsetPersisted: bigint;

  /**
   * LastOriginalOffsetProcessed is used to keep track of the newest
   * offset processed if a message is re-validated and re-ordered.
   * This value is used to deduplicate re-submitted messages from
   * multiple orderer so that we don't bother re-processing it again.
   *
   * @generated from field: int64 last_original_offset_processed = 2;
   */
  lastOriginalOffsetProcessed: bigint;

  /**
   * LastResubmittedConfigOffset is used to capture the newest offset of
   * CONFIG kafka message, which is revalidated and resubmitted. By comparing
   * this with LastOriginalOffsetProcessed, we could detemine whether there
   * are still CONFIG messages that have been resubmitted but NOT processed
   * yet. It's used as condition to block ingress messages, so we could reduce
   * the overhead of repeatedly resubmitting messages as config seq keeps
   * advancing.
   *
   * @generated from field: int64 last_resubmitted_config_offset = 3;
   */
  lastResubmittedConfigOffset: bigint;
};

/**
 * Describes the message orderer.KafkaMetadata.
 * Use `create(KafkaMetadataSchema)` to create a new message.
 */
export const KafkaMetadataSchema: GenMessage<KafkaMetadata> = /*@__PURE__*/
  messageDesc(file_orderer_kafka, 4);

